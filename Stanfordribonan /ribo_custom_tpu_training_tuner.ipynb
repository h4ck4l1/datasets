{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h4ck4l1/datasets/blob/main/Stanfordribonan%20/ribo_custom_tpu_training_tuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "بِسْمِ اللهِ الرَّحْمٰنِ الرَّحِيْمِ\n"
          ]
        }
      ],
      "source": [
        "print(\"بِسْمِ اللهِ الرَّحْمٰنِ الرَّحِيْمِ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mwAsQCJESWe",
        "outputId": "a4ef8d53-c2b5-48ca-e723-992e8a0ef305"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os,sys,warnings,time\n",
        "from IPython.display import clear_output\n",
        "warnings.filterwarnings('ignore')\n",
        "os.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iITfC4miGSM9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "if \"COLAB_BACKEND_VERSION\" in os.environ.keys():\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    !gcloud config set project kaggle-406814\n",
        "    !pip install keras-tuner --upgrade\n",
        "    clear_output()\n",
        "elif \"KAGGLE_GCP_ZONE\" in os.environ.keys():\n",
        "    !pip install keras-tuner --upgrade\n",
        "    !pip install -q -U plotly --upgrade\n",
        "    !pip isntall google-cloud-storage\n",
        "    from google.cloud import storage\n",
        "    client = storage.Client(\"kaggle-406814\")\n",
        "    from kaggle_secrets import UserSecretsClient\n",
        "    user_secrets = UserSecretsClient()\n",
        "    user_credential = user_secrets.get_gcloud_credential()\n",
        "    user_secrets.set_tensorflow_credential(user_credential)\n",
        "else:\n",
        "    !gcloud config set project kaggle-406814"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7-gg3Gq3Gh6x"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "import numpy as np\n",
        "from typing import Literal\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.io as pio\n",
        "pio.templates.default = \"plotly_dark\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.sparse import to_dense\n",
        "from tensorflow.io import FixedLenFeature,VarLenFeature,parse_tensor,parse_single_example\n",
        "from tensorflow.data import TFRecordDataset\n",
        "from keras.utils import Progbar\n",
        "from tqdm import tqdm\n",
        "import keras_tuner as kt\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "import re,time,random,math\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaH7QbrgGuyH",
        "outputId": "ebd61f69-5318-4c8f-d54b-7ed58012c8f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: Not connected to TPU runtime using GPU/CPU...\n",
            "Using GPU runtime...\n",
            "<tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy object at 0x7f0ad69f3550>\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    tpu_cluster = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print(\"Running on TPU ADDR: \",tpu_cluster.cluster_spec().as_dict())\n",
        "    tf.config.experimental_connect_to_cluster(tpu_cluster)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu_cluster)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu_cluster)\n",
        "    print(strategy)\n",
        "    print(strategy.num_replicas_in_sync)\n",
        "    tpu_present = True\n",
        "except ValueError:\n",
        "    print(\"Error: Not connected to TPU runtime using GPU/CPU...\")\n",
        "    tpu_present = False\n",
        "\n",
        "if not tpu_present:\n",
        "    if len(tf.config.list_physical_devices()) > 0:\n",
        "        strategy = tf.distribute.OneDeviceStrategy(\"GPU\")\n",
        "        print(\"Using GPU runtime...\")\n",
        "    else:\n",
        "        strategy = tf.distribute.OneDeviceStrategy(\"CPU\")\n",
        "        print(\"Using CPU runtime...\")\n",
        "        \n",
        "print(strategy)\n",
        "print(strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PcyUh_nSG8t-"
      },
      "outputs": [],
      "source": [
        "PATH = \"gs://stanfordrna/ribo/train_*.tfrecord\"\n",
        "total_files = tf.io.gfile.glob(PATH)\n",
        "train_files = total_files[:25]\n",
        "valid_files = total_files[25:28]\n",
        "test_files = total_files[28:]\n",
        "train_raw_ds = TFRecordDataset(train_files,compression_type=\"GZIP\",num_parallel_reads=tf.data.AUTOTUNE)\n",
        "valid_raw_ds = TFRecordDataset(valid_files,compression_type=\"GZIP\",num_parallel_reads=tf.data.AUTOTUNE)\n",
        "test_raw_ds = TFRecordDataset(test_files,compression_type=\"GZIP\",num_parallel_reads=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7tzt6AndHDRr"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "rna_feature = dict(\n",
        "    seq_id = FixedLenFeature([],tf.string),\n",
        "    seq = VarLenFeature(tf.string),\n",
        "    reads_2a3 = FixedLenFeature([],tf.string),\n",
        "    reads_dms = FixedLenFeature([],tf.string),\n",
        "    signal_to_noise_2a3 = FixedLenFeature([],tf.string),\n",
        "    signal_to_noise_dms = FixedLenFeature([],tf.string),\n",
        "    reactivity_2a3 = VarLenFeature(tf.string),\n",
        "    reactivity_dms = VarLenFeature(tf.string),\n",
        "    reactivity_error_2a3 = VarLenFeature(tf.string),\n",
        "    reactivity_error_dms = VarLenFeature(tf.string),\n",
        "    bpp_matrix = VarLenFeature(tf.string),\n",
        "    bracket_seq = VarLenFeature(tf.string)\n",
        "    )\n",
        "\n",
        "def rna_example(example):\n",
        "    example = parse_single_example(example, rna_feature)\n",
        "\n",
        "    ### Dense Features\n",
        "    example[\"seq_id\"] = parse_tensor(example[\"seq_id\"], out_type=tf.string)\n",
        "    example[\"reads_2a3\"] = parse_tensor(example[\"reads_2a3\"], out_type=tf.float32)\n",
        "    example[\"reads_dms\"] = parse_tensor(example[\"reads_dms\"], out_type=tf.float32)\n",
        "    example[\"signal_to_noise_2a3\"] = parse_tensor(example[\"signal_to_noise_2a3\"], out_type=tf.float32)\n",
        "    example[\"signal_to_noise_dms\"] = parse_tensor(example[\"signal_to_noise_dms\"], out_type=tf.float32)\n",
        "\n",
        "    ### Sparse Features\n",
        "    example[\"seq\"] = parse_tensor(to_dense(example[\"seq\"])[0], out_type=tf.float32)\n",
        "    example[\"reactivity_2a3\"] = parse_tensor(to_dense(example[\"reactivity_2a3\"])[0], out_type=tf.float32)\n",
        "    example[\"reactivity_dms\"] = parse_tensor(to_dense(example[\"reactivity_dms\"])[0], out_type=tf.float32)\n",
        "    example[\"reactivity_error_2a3\"] = parse_tensor(to_dense(example[\"reactivity_error_2a3\"])[0], out_type=tf.float32)\n",
        "    example[\"reactivity_error_dms\"] = parse_tensor(to_dense(example[\"reactivity_error_dms\"])[0], out_type=tf.float32)\n",
        "    example[\"bpp_matrix\"] = parse_tensor(to_dense(example[\"bpp_matrix\"])[0], out_type=tf.float32)\n",
        "    example[\"bracket_seq\"] = parse_tensor(to_dense(example[\"bracket_seq\"])[0], out_type=tf.float32)\n",
        "\n",
        "    return example\n",
        "\n",
        "train_modified_ds = train_raw_ds.map(rna_example,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "valid_modified_ds = valid_raw_ds.map(rna_example,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_modified_ds = test_raw_ds.map(rna_example,num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2XYNN7DgHZy8",
        "outputId": "c0e4871d-5866-4c5f-b87a-709a3192470f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id  :  b'25ce8d5109cd'\n",
            "\n",
            "\n",
            "\n",
            "seq  :  [3. 3. 3. 1. 1. 2. 3. 1. 2. 4. 2. 3. 1. 3. 4. 1. 3. 1. 3. 4.]\n",
            "seq shape : (170,)\n",
            "\n",
            "\n",
            "\n",
            "reads_2a3 :  4647.0\n",
            "\n",
            "\n",
            "\n",
            "reads_dms :  1964.0\n",
            "\n",
            "\n",
            "\n",
            "signal_to_noise_2a3 :  2.347\n",
            "\n",
            "\n",
            "\n",
            "signal_to_noise_dms :  1.848\n",
            "\n",
            "\n",
            "\n",
            "reactivity_2a3  :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "shape of reactivity_2a3 : (206,)\n",
            "\n",
            "\n",
            "\n",
            "reactivity_dms  :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "shape of reactivity_dms : (206,)\n",
            "\n",
            "\n",
            "\n",
            "reactivity_error_2a3 :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "shape of reactivity_error_2a3 (206,)\n",
            "\n",
            "\n",
            "\n",
            "reactivity_error_dms :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "shape of reactivity_error_dms (206,)\n",
            "\n",
            "\n",
            "\n",
            "bpp_matrix : [[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "bpp_matrix shape : (170, 170)\n",
            "\n",
            "\n",
            "\n",
            "bracket_sequence : [1. 1. 9. 9. 9. 1. 1. 1. 1. 1. 1. 9. 9. 9. 9. 9. 2. 2. 2. 2.]\n",
            "bracket_sequence shape : (170,)\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "single_example = train_modified_ds.take(1).get_single_element()\n",
        "print(\"id\",\" : \",single_example[\"seq_id\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"seq\",\" : \",single_example[\"seq\"].numpy()[:20])\n",
        "print(\"seq shape :\",single_example[\"seq\"].numpy().shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"reads_2a3\",\": \",single_example[\"reads_2a3\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"reads_dms\",\": \",single_example[\"reads_dms\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"signal_to_noise_2a3\",\": \",single_example[\"signal_to_noise_2a3\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"signal_to_noise_dms\",\": \",single_example[\"signal_to_noise_dms\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"reactivity_2a3\",\" : \",single_example[\"reactivity_2a3\"].numpy()[:20])\n",
        "print(\"shape of reactivity_2a3 :\",single_example[\"reactivity_2a3\"].shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"reactivity_dms\",\" : \",single_example[\"reactivity_dms\"].numpy()[:20])\n",
        "print(\"shape of reactivity_dms :\",single_example[\"reactivity_dms\"].shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"reactivity_error_2a3\",\": \",single_example[\"reactivity_error_2a3\"].numpy()[:20])\n",
        "print(\"shape of reactivity_error_2a3\",single_example[\"reactivity_error_2a3\"].shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"reactivity_error_dms\",\": \",single_example[\"reactivity_error_dms\"].numpy()[:20])\n",
        "print(\"shape of reactivity_error_dms\",single_example[\"reactivity_error_dms\"].shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"bpp_matrix :\",single_example[\"bpp_matrix\"].numpy()[:5,:5])\n",
        "print(\"bpp_matrix shape :\",single_example[\"bpp_matrix\"].numpy().shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"bracket_sequence :\",single_example[\"bracket_seq\"].numpy()[:20])\n",
        "print('bracket_sequence shape :',single_example[\"bracket_seq\"].numpy().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aQCSg5HfHkNO"
      },
      "outputs": [],
      "source": [
        "K = keras.backend\n",
        "seq_map = {\"A\":1,\"C\":2,\"G\":3,\"U\":4,\"START\":4,\"END\":5,\"EMPTY\":0}\n",
        "bracket_map = {\"(\":1,\")\":2,\"[\":3,\"]\":4,\"{\":5,\"}\":6,\"<\":7,\">\":8,\".\":9,\"START\":10,\"END\":11,\"EMPTY\":0}\n",
        "\n",
        "def convert_and_pad(ex):\n",
        "\n",
        "    l = tf.shape(ex[\"seq\"],tf.int32)[0]\n",
        "\n",
        "    shift = tf.random.uniform(shape=[1],minval=0,maxval=206-l+1,dtype=tf.int32)[0]\n",
        "\n",
        "    # Sequence Processing and Mask Processing\n",
        "    seq = ex[\"seq\"] + 1\n",
        "    seq = tf.pad(seq,[[1,0]],constant_values=seq_map[\"START\"])                               # seq_map[\"START\"]\n",
        "    seq = tf.pad(seq,[[0,1]],constant_values=seq_map[\"END\"])                                 # seq_map[\"END\"]\n",
        "    seq = tf.pad(seq,[[shift,206-l-shift]])                                                 # seq_map[\"EMPTY\"]\n",
        "\n",
        "    # Bracket Processing\n",
        "    brac = ex[\"bracket_seq\"] + 1\n",
        "    brac = tf.pad(brac,[[1,0]],constant_values=bracket_map[\"START\"])                            # bracket_map[\"START\"]\n",
        "    brac = tf.pad(brac,[[0,1]],constant_values=bracket_map[\"END\"])                              # bracket_map[\"END\"]\n",
        "    brac = tf.pad(brac,[[shift,206-l-shift]],constant_values=bracket_map[\"EMPTY\"])             # bracket_map[\"EMPTY\"]\n",
        "\n",
        "    # Reactivity Processing\n",
        "    reac = tf.stack([ex[\"reactivity_2a3\"][:l],ex[\"reactivity_dms\"][:l]],axis=-1)\n",
        "    reac = tf.pad(reac,[[shift+1,206+1-l-shift],[0,0]],constant_values=np.nan)\n",
        "\n",
        "    # BPPMatrix\n",
        "    bppm = ex[\"bpp_matrix\"][:l,:l]\n",
        "    bppm = tf.pad(bppm,[[shift+1,206+1-l-shift],[shift+1,206+1-l-shift]])\n",
        "\n",
        "    return (seq,brac,bppm),reac\n",
        "\n",
        "\n",
        "def shape_set(X,y,batch_size):\n",
        "    (seq,brac,bpp),reac = X,y\n",
        "    seq.set_shape([batch_size,208])\n",
        "    brac.set_shape([batch_size,208])\n",
        "    bpp.set_shape([batch_size,208,208])\n",
        "    reac.set_shape([batch_size,208,2])\n",
        "    return (seq,brac,bpp),reac\n",
        "\n",
        "\n",
        "def create_train_ds(dataset,batch_size):\n",
        "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.ignore_errors()\n",
        "    dataset = dataset.shuffle(10000)\n",
        "    # dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch_size,drop_remainder=True,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(lambda X,y: shape_set(X,y,batch_size),num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "def create_valid_ds(dataset,batch_size):\n",
        "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.ignore_errors()\n",
        "    dataset = dataset.batch(batch_size,drop_remainder=True,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(lambda X,y: shape_set(X,y,batch_size),num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.cache()\n",
        "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "def create_test_ds(dataset,batch_size):\n",
        "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.ignore_errors()\n",
        "    dataset = dataset.batch(batch_size,drop_remainder=True,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(lambda X,y: shape_set(X,y,batch_size),num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "testing_ds = create_train_ds(train_modified_ds,batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h681yFY-Hwp9",
        "outputId": "a1613cf2-30c5-4337-921f-408441d5b71a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seq_input :  (32, 208)\n",
            "bracket_input :  (32, 208)\n",
            "bpp_matrix :  (32, 208, 208)\n",
            "reactivity :  (32, 208, 2)\n"
          ]
        }
      ],
      "source": [
        "X,y = testing_ds.take(1).get_single_element()\n",
        "\n",
        "seq_input = X[0]\n",
        "bracket_input = X[1]\n",
        "bpp_matrix = X[2]\n",
        "reactivity = y\n",
        "\n",
        "print(\"seq_input : \",seq_input.shape)\n",
        "print(\"bracket_input : \",bracket_input.shape)\n",
        "print(\"bpp_matrix : \",bpp_matrix.shape)\n",
        "print(\"reactivity : \",reactivity.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5h_BEZpkIL4Q"
      },
      "outputs": [],
      "source": [
        "class StaticPosEncoding(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "            vocab_size:int,\n",
        "            d_model,\n",
        "            length,\n",
        "            **kwargs):\n",
        "\n",
        "        super(StaticPosEncoding,self).__init__(**kwargs)\n",
        "\n",
        "        assert d_model%2 == 0,\"Depth of model(d_model) should be even\"\n",
        "\n",
        "        d_model = d_model//2\n",
        "        positions = np.arange(length)[:,np.newaxis]\n",
        "        angles = np.arange(d_model)[np.newaxis,:]/d_model\n",
        "        angles = 1/(10000**angles)\n",
        "        angle_rads = positions * angles\n",
        "        encode = tf.concat([tf.sin(angle_rads),tf.cos(angle_rads)],axis=-1)\n",
        "        self.encode = tf.cast(encode,tf.float32)\n",
        "        self.factor = tf.sqrt(tf.cast(d_model,tf.float32))\n",
        "        self.embedding_layer = keras.layers.Embedding(vocab_size,d_model*2,mask_zero=True)\n",
        "\n",
        "    def compute_mask(self, *args,**kwargs):\n",
        "        return self.embedding_layer.compute_mask(*args,**kwargs)\n",
        "\n",
        "    def call(self,x):\n",
        "        x = self.embedding_layer(x)\n",
        "        x *= self.factor\n",
        "        return x + self.encode[tf.newaxis,:208,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttpsW5XlIWVK",
        "outputId": "9f1a8ca5-b5e8-4c28-87b9-0a049adfb177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32, 208, 512)\n",
            "(32, 208, 512)\n"
          ]
        }
      ],
      "source": [
        "seq_pos_encode = StaticPosEncoding(vocab_size=len(seq_map),d_model=512,length=2048)\n",
        "brac_pos_encode = StaticPosEncoding(vocab_size=len(bracket_map),d_model=512,length=2048)\n",
        "seq_pos_encode_output = seq_pos_encode(X[0])\n",
        "brac_pos_encode_output = brac_pos_encode(X[1])\n",
        "print(seq_pos_encode_output.shape)\n",
        "print(brac_pos_encode_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "d8i7lmSxIe01"
      },
      "outputs": [],
      "source": [
        "class ConvolutionLayer(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 n_filters,\n",
        "                 ksize,\n",
        "                 drop_rate,\n",
        "                 **kwargs):\n",
        "        super(ConvolutionLayer,self).__init__(**kwargs)\n",
        "        self.conv_layers = [keras.layers.Conv2D(filters=n_filters,kernel_size=ksize,padding=\"same\",use_bias=False,activation=\"relu\") for _ in range(n_layers)]\n",
        "        self.perm = keras.layers.Permute(dims=[3,1,2])\n",
        "        self.norm = keras.layers.LayerNormalization()\n",
        "        self.drop = keras.layers.Dropout(drop_rate)\n",
        "\n",
        "    def call(self,x):\n",
        "        x = tf.expand_dims(x,axis=-1)\n",
        "        for layer in self.conv_layers:\n",
        "            x = layer(x)\n",
        "        x = self.perm(x)\n",
        "        return self.norm(self.drop(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J_ep-ikIhjz",
        "outputId": "37a4e81b-a986-4bdb-cb92-89f76e5dc450"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 6, 208, 208])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conv = ConvolutionLayer(n_layers=3,n_filters=6,ksize=3,drop_rate=0.1)\n",
        "bpp_conv_ouput = conv(bpp_matrix)\n",
        "bpp_conv_ouput.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "n4QXd-gsIj4H"
      },
      "outputs": [],
      "source": [
        "class ConvolutedAttention(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "            num_heads,\n",
        "            key_dim,\n",
        "            **kwargs):\n",
        "\n",
        "        super(ConvolutedAttention,self).__init__(**kwargs)\n",
        "        self.num_heads = num_heads\n",
        "        self.key_dim = key_dim\n",
        "        self.wq = keras.layers.Dense(num_heads*key_dim,use_bias=False,kernel_initializer=\"glorot_normal\")\n",
        "        self.wv = keras.layers.Dense(num_heads*key_dim,use_bias=False,kernel_initializer=\"glorot_normal\")\n",
        "        self.wk = keras.layers.Dense(num_heads*key_dim,use_bias=False,kernel_initializer=\"glorot_normal\")\n",
        "        self.dense = keras.layers.Dense(key_dim,use_bias=False,kernel_initializer=\"glorot_normal\")\n",
        "        self.first_drop = keras.layers.Dropout(0.1)\n",
        "        self.last_drop = keras.layers.Dropout(0.1)\n",
        "        self.layer_norm = keras.layers.LayerNormalization()\n",
        "        self.factor = tf.math.rsqrt(tf.constant(key_dim,tf.float32))\n",
        "        self.softmax = keras.layers.Softmax()\n",
        "        self.add = keras.layers.Add()\n",
        "\n",
        "\n",
        "    def call(self,query,key,value,convoluted=None,return_attention_scores=False,mask=None):\n",
        "\n",
        "\n",
        "        batch_size = tf.shape(query)[0]\n",
        "        seq_len = tf.shape(query)[1]\n",
        "        q = self.wq(query)\n",
        "        k = self.wk(key)\n",
        "        v = self.wv(value)\n",
        "\n",
        "        q = tf.transpose(tf.reshape(q,shape=[batch_size,-1,self.num_heads,self.key_dim]),perm=[0,2,1,3])\n",
        "        k = tf.transpose(tf.reshape(k,shape=[batch_size,-1,self.num_heads,self.key_dim]),perm=[0,2,1,3])\n",
        "        v = tf.transpose(tf.reshape(v,shape=[batch_size,-1,self.num_heads,self.key_dim]),perm=[0,2,1,3])\n",
        "\n",
        "        attention_score = self.factor * tf.matmul(q,k,transpose_b=True)\n",
        "        attention_score = self.first_drop(self.softmax(attention_score + convoluted))\n",
        "\n",
        "        attention_out = tf.reshape(tf.transpose(tf.matmul(attention_score,v),perm=[0,2,1,3]),shape=[batch_size,seq_len,-1])\n",
        "        attention_out = self.last_drop(self.dense(attention_out))\n",
        "        attention_out = self.layer_norm(self.add([attention_out,query]))\n",
        "\n",
        "        if return_attention_scores:\n",
        "            return attention_out,attention_score\n",
        "        return attention_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRoIfnRLInwt",
        "outputId": "29d71a09-d96d-4f37-82fd-2ca1359672e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 208, 512])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conv_attn = ConvolutedAttention(num_heads=6,key_dim=512)\n",
        "conv_attn_out = conv_attn(query=seq_pos_encode_output,key=seq_pos_encode_output,value=seq_pos_encode_output,convoluted=bpp_conv_ouput)\n",
        "conv_attn_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "zmKTlOvlIqK-"
      },
      "outputs": [],
      "source": [
        "class FeedForward(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "            feed_out_unit,\n",
        "            feed_forward,\n",
        "            feed_forward_drop,\n",
        "            **kwargs):\n",
        "\n",
        "        super(FeedForward,self).__init__(**kwargs)\n",
        "        self.dense_out = keras.layers.Dense(feed_out_unit)\n",
        "        self.feed_forward = keras.layers.Dense(feed_forward)\n",
        "        self.feed_forward_drop = keras.layers.Dropout(feed_forward_drop)\n",
        "        self.norm = keras.layers.LayerNormalization()\n",
        "        self.add = keras.layers.Add()\n",
        "\n",
        "    def call(self,x):\n",
        "\n",
        "        x_copy = x\n",
        "        x = self.feed_forward(x)\n",
        "        x = self.dense_out(x)\n",
        "        x = self.feed_forward_drop(x)\n",
        "        x = self.feed_forward_drop(x)\n",
        "        return self.norm(self.add([x_copy,x]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy4WmgpMI0am",
        "outputId": "669d62d5-f8e6-413d-f446-118f05ab8eda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 208, 512])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feed_forward = FeedForward(feed_out_unit=512,feed_forward=2048,feed_forward_drop=0.2)\n",
        "feed_out = feed_forward(conv_attn_out)\n",
        "feed_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "N-iFInQdI3wU"
      },
      "outputs": [],
      "source": [
        "class BracketEncoderUnit(keras.models.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "            encoder_convolution_layers:int,\n",
        "            encoder_convolution_ksize:int,\n",
        "            encoder_convolution_drop_rate:float,\n",
        "            encoder_convolution_num_heads:int,\n",
        "            encoder_key_dim:int,\n",
        "            encoder_feed_out_units:int,\n",
        "            encoder_feed_forward_units:int,\n",
        "            encoder_feed_forward_drop_rate:float,\n",
        "            **kwargs):\n",
        "\n",
        "\n",
        "        super(BracketEncoderUnit,self).__init__(**kwargs)\n",
        "\n",
        "        self.convolution_layer = ConvolutionLayer(\n",
        "            encoder_convolution_layers,\n",
        "            encoder_convolution_num_heads,\n",
        "            encoder_convolution_ksize,\n",
        "            encoder_convolution_drop_rate,\n",
        "        )\n",
        "\n",
        "        self.convoluted_attention = ConvolutedAttention(\n",
        "            encoder_convolution_num_heads,\n",
        "            encoder_key_dim\n",
        "        )\n",
        "\n",
        "        self.feed_forward = FeedForward(\n",
        "            encoder_feed_out_units,\n",
        "            encoder_feed_forward_units,\n",
        "            encoder_feed_forward_drop_rate\n",
        "        )\n",
        "\n",
        "    def call(self,bracket_encode_out,bpp_matrix):\n",
        "\n",
        "        convolution_out = self.convolution_layer(bpp_matrix)\n",
        "        convoluted_attention_out = self.convoluted_attention(\n",
        "            query = bracket_encode_out,\n",
        "            key = bracket_encode_out,\n",
        "            value = bracket_encode_out,\n",
        "            convoluted = convolution_out\n",
        "        )\n",
        "        feed_out = self.feed_forward(convoluted_attention_out)\n",
        "\n",
        "        return feed_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErdENl2PI7TR",
        "outputId": "9acff469-bc76-4e5e-be0f-55a6cbea8838"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 208, 512])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bracket_seq_encoder = BracketEncoderUnit(\n",
        "    encoder_convolution_layers=3,\n",
        "    encoder_convolution_ksize=3,\n",
        "    encoder_convolution_drop_rate=0.1,\n",
        "    encoder_convolution_num_heads=6,\n",
        "    encoder_key_dim=512,\n",
        "    encoder_feed_forward_drop_rate=0.1,\n",
        "    encoder_feed_forward_units=2048,\n",
        "    encoder_feed_out_units=512\n",
        ")\n",
        "\n",
        "bracket_seq_encoder_out = bracket_seq_encoder(brac_pos_encode_output,bpp_matrix)\n",
        "bracket_seq_encoder_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "w-C9QmqWI9_5"
      },
      "outputs": [],
      "source": [
        "class SequenceEncoderUint(keras.models.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "            encoder_convolution_layers:int,\n",
        "            encoder_convolution_ksize:int,\n",
        "            encoder_convolution_drop_rate:float,\n",
        "            encoder_convolution_num_heads:int,\n",
        "            encoder_cross_attention_num_heads:int,\n",
        "            encoder_key_dim:int,\n",
        "            encoder_feed_out_units:int,\n",
        "            encoder_feed_forward_units:int,\n",
        "            encoder_feed_forward_drop_rate:float,\n",
        "            **kwargs):\n",
        "\n",
        "        super(SequenceEncoderUint,self).__init__(**kwargs)\n",
        "\n",
        "        self.convolution_layer = ConvolutionLayer(\n",
        "            encoder_convolution_layers,\n",
        "            encoder_convolution_num_heads,\n",
        "            encoder_convolution_ksize,\n",
        "            encoder_convolution_drop_rate\n",
        "            )\n",
        "\n",
        "        self.convoluted_attention = ConvolutedAttention(\n",
        "            encoder_convolution_num_heads,\n",
        "            encoder_key_dim\n",
        "            )\n",
        "\n",
        "        self.encoder_cross_attention = keras.layers.MultiHeadAttention(\n",
        "            num_heads=encoder_cross_attention_num_heads,\n",
        "            key_dim=encoder_key_dim\n",
        "            )\n",
        "\n",
        "        self.feed_forward = FeedForward(\n",
        "            encoder_feed_out_units,\n",
        "            encoder_feed_forward_units,\n",
        "            encoder_feed_forward_drop_rate\n",
        "            )\n",
        "\n",
        "    def call(self,sequence_encode_out,bpp_matrix,bracket_encode_out):\n",
        "\n",
        "        convolution_out = self.convolution_layer(bpp_matrix)\n",
        "        convolutedattention_out = self.convoluted_attention(\n",
        "            query=sequence_encode_out,\n",
        "            key=sequence_encode_out,\n",
        "            value=sequence_encode_out,\n",
        "            convoluted=convolution_out\n",
        "            )\n",
        "        crossattention_out = self.encoder_cross_attention(\n",
        "            query=convolutedattention_out,\n",
        "            key=bracket_encode_out,\n",
        "            value=bracket_encode_out\n",
        "            )\n",
        "        feed_out = self.feed_forward(crossattention_out)\n",
        "\n",
        "        return feed_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZGj6JTQJC47",
        "outputId": "41fb83c1-1600-40da-e5ce-8422fe3ee573"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 208, 512])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seq_encoder = SequenceEncoderUint(\n",
        "    encoder_convolution_layers=3,\n",
        "    encoder_convolution_ksize=3,\n",
        "    encoder_convolution_drop_rate=0.1,\n",
        "    encoder_convolution_num_heads=6,\n",
        "    encoder_cross_attention_num_heads=6,\n",
        "    encoder_key_dim=512,\n",
        "    encoder_feed_forward_drop_rate=0.1,\n",
        "    encoder_feed_forward_units=2048,\n",
        "    encoder_feed_out_units=512\n",
        "    )\n",
        "\n",
        "seq_encoder_out = seq_encoder(seq_pos_encode_output,bpp_matrix,bracket_seq_encoder_out)\n",
        "seq_encoder_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "iRX2t1DuJFTA"
      },
      "outputs": [],
      "source": [
        "class Transformer(keras.models.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "\n",
        "            # Seuqence encoder arguments\n",
        "\n",
        "            sequence_encoder_vocab_size=len(seq_map),\n",
        "            sequence_encoder_d_model=256,\n",
        "            sequence_encoder_length=2048,\n",
        "            sequence_encoder_num_layers=3,\n",
        "            sequence_encoder_convolution_layers=3,\n",
        "            sequence_encoder_convolution_ksize=3,\n",
        "            sequence_encoder_convolution_drop_rate=0.1,\n",
        "            sequence_encoder_convolution_num_heads=4,\n",
        "            sequence_encoder_cross_attention_num_heads=4,\n",
        "            sequence_encoder_key_dim=256,\n",
        "            sequence_encoder_feed_out_units=256,\n",
        "            sequence_encoder_feed_forward_units=1024,\n",
        "            sequence_encoder_feed_forward_drop_rate=0.1,\n",
        "\n",
        "            # Bracket Sequence Encoder arguments\n",
        "\n",
        "            bracket_sequence_encoder_vocab_size=len(bracket_map),\n",
        "            bracket_sequence_encoder_d_model=256,\n",
        "            bracket_sequence_encoder_length=2048,\n",
        "            bracket_sequence_encoder_num_layers=3,\n",
        "            bracket_sequence_encoder_convolution_layers=3,\n",
        "            bracket_sequence_encoder_convolution_ksize=3,\n",
        "            bracket_sequence_encoder_convolution_drop_rate=0.1,\n",
        "            bracket_sequence_encoder_num_heads=4,\n",
        "            bracket_sequence_encoder_key_dim=256,\n",
        "            bracket_sequence_encoder_feed_out_units=256,\n",
        "            bracket_sequence_encoder_feed_forward_units=1024,\n",
        "            bracket_sequence_encoder_feed_forward_drop_rate=0.1,\n",
        "\n",
        "            # Out Dense\n",
        "            total_out_units = 2,\n",
        "            **kwargs):\n",
        "\n",
        "\n",
        "        super(Transformer,self).__init__(**kwargs)\n",
        "\n",
        "        self.sequence_pos_encoder = StaticPosEncoding(\n",
        "            sequence_encoder_vocab_size,\n",
        "            sequence_encoder_d_model,\n",
        "            sequence_encoder_length,\n",
        "        )\n",
        "\n",
        "        self.bracket_sequence_pos_encoder = StaticPosEncoding(\n",
        "            bracket_sequence_encoder_vocab_size,\n",
        "            bracket_sequence_encoder_d_model,\n",
        "            bracket_sequence_encoder_length,\n",
        "        )\n",
        "\n",
        "        self.sequence_encoder_units_list = [SequenceEncoderUint(\n",
        "            sequence_encoder_convolution_layers,\n",
        "            sequence_encoder_convolution_ksize,\n",
        "            sequence_encoder_convolution_drop_rate,\n",
        "            sequence_encoder_convolution_num_heads,\n",
        "            sequence_encoder_cross_attention_num_heads,\n",
        "            sequence_encoder_key_dim,\n",
        "            sequence_encoder_feed_out_units,\n",
        "            sequence_encoder_feed_forward_units,\n",
        "            sequence_encoder_feed_forward_drop_rate\n",
        "        ) for _ in range(sequence_encoder_num_layers)]\n",
        "\n",
        "        self.bracket_sequence_encoder_units_list = [BracketEncoderUnit(\n",
        "            bracket_sequence_encoder_convolution_layers,\n",
        "            bracket_sequence_encoder_convolution_ksize,\n",
        "            bracket_sequence_encoder_convolution_drop_rate,\n",
        "            bracket_sequence_encoder_num_heads,\n",
        "            bracket_sequence_encoder_key_dim,\n",
        "            bracket_sequence_encoder_feed_out_units,\n",
        "            bracket_sequence_encoder_feed_forward_units,\n",
        "            bracket_sequence_encoder_feed_forward_drop_rate\n",
        "        ) for _ in range(bracket_sequence_encoder_num_layers)]\n",
        "\n",
        "        self.total_out = keras.layers.Dense(total_out_units,activation=None)\n",
        "\n",
        "\n",
        "    def call(self,X):\n",
        "\n",
        "        sequence,bracket_sequence,bpp_matrix = X\n",
        "        out = self.bracket_sequence_pos_encoder(bracket_sequence)\n",
        "\n",
        "        for layer in self.bracket_sequence_encoder_units_list:\n",
        "            out = layer(out,bpp_matrix)\n",
        "\n",
        "        seq_out = self.sequence_pos_encoder(sequence)\n",
        "\n",
        "        for layer in self.sequence_encoder_units_list:\n",
        "            seq_out = layer(seq_out,bpp_matrix,out)\n",
        "\n",
        "\n",
        "        seq_out = self.total_out(seq_out)\n",
        "\n",
        "        try:\n",
        "            del seq_out._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        return seq_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sx-94spJI6x",
        "outputId": "a69525c0-2b94-4dbd-db27-634085a5266a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 208, 2])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer = Transformer()\n",
        "transformer_out = transformer(X)\n",
        "transformer_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka45OdDKJLJn",
        "outputId": "31cb2ca1-fe02-4629-c089-a65df3c64c3b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│ static_pos_encoding_2           │ ?                         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StaticPosEncoding</span>)             │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ static_pos_encoding_3           │ ?                         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StaticPosEncoding</span>)             │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ sequence_encoder_uint_1         │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,627,812</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SequenceEncoderUint</span>)           │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ sequence_encoder_uint_2         │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,627,812</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SequenceEncoderUint</span>)           │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ sequence_encoder_uint_3         │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,627,812</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SequenceEncoderUint</span>)           │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_1          │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,575,908</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BracketEncoderUnit</span>)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_2          │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,575,908</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BracketEncoderUnit</span>)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_3          │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,575,908</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BracketEncoderUnit</span>)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │\n",
              "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│ static_pos_encoding_2           │ ?                         │      \u001b[38;5;34m1,792\u001b[0m │\n",
              "│ (\u001b[38;5;33mStaticPosEncoding\u001b[0m)             │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ static_pos_encoding_3           │ ?                         │      \u001b[38;5;34m3,072\u001b[0m │\n",
              "│ (\u001b[38;5;33mStaticPosEncoding\u001b[0m)             │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ sequence_encoder_uint_1         │ ?                         │  \u001b[38;5;34m2,627,812\u001b[0m │\n",
              "│ (\u001b[38;5;33mSequenceEncoderUint\u001b[0m)           │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ sequence_encoder_uint_2         │ ?                         │  \u001b[38;5;34m2,627,812\u001b[0m │\n",
              "│ (\u001b[38;5;33mSequenceEncoderUint\u001b[0m)           │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ sequence_encoder_uint_3         │ ?                         │  \u001b[38;5;34m2,627,812\u001b[0m │\n",
              "│ (\u001b[38;5;33mSequenceEncoderUint\u001b[0m)           │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_1          │ ?                         │  \u001b[38;5;34m1,575,908\u001b[0m │\n",
              "│ (\u001b[38;5;33mBracketEncoderUnit\u001b[0m)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_2          │ ?                         │  \u001b[38;5;34m1,575,908\u001b[0m │\n",
              "│ (\u001b[38;5;33mBracketEncoderUnit\u001b[0m)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_3          │ ?                         │  \u001b[38;5;34m1,575,908\u001b[0m │\n",
              "│ (\u001b[38;5;33mBracketEncoderUnit\u001b[0m)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                │ ?                         │        \u001b[38;5;34m514\u001b[0m │\n",
              "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,616,538</span> (48.13 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,616,538\u001b[0m (48.13 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,616,538</span> (48.13 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,616,538\u001b[0m (48.13 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7ugX0tvfJPDO"
      },
      "outputs": [],
      "source": [
        "class CustomMetric2A3(keras.metrics.Metric):\n",
        "\n",
        "    def __init__(self,**kwargs):\n",
        "\n",
        "        super(CustomMetric2A3,self).__init__(**kwargs)\n",
        "        self.mae = self.add_weight(name=\"mae\",initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "\n",
        "        y_true = tf.clip_by_value(y_true[...,0],clip_value_max=1,clip_value_min=0)\n",
        "        y_pred = tf.clip_by_value(y_pred[...,0],clip_value_max=1,clip_value_min=0)\n",
        "        mae = tf.abs(tf.subtract(y_true,y_pred))\n",
        "        mae = tf.reduce_mean(mae[~tf.math.is_nan(mae)])\n",
        "        self.mae.assign_add(mae)\n",
        "\n",
        "\n",
        "    def result(self):\n",
        "        return self.mae\n",
        "\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mae.assign(0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XS2DNHIAJRoK"
      },
      "outputs": [],
      "source": [
        "class CustomMetricDMS(keras.metrics.Metric):\n",
        "\n",
        "    def __init__(self,**kwargs):\n",
        "\n",
        "        super(CustomMetricDMS,self).__init__(**kwargs)\n",
        "        self.mae = self.add_weight(name=\"mae\",initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "\n",
        "        y_true = tf.clip_by_value(y_true[...,1],clip_value_min=0,clip_value_max=1)\n",
        "        y_pred = tf.clip_by_value(y_pred[...,1],clip_value_max=1,clip_value_min=0)\n",
        "        mae = tf.abs(tf.subtract(y_true,y_pred))\n",
        "        mae = tf.reduce_mean(mae[~tf.math.is_nan(mae)])\n",
        "        self.mae.assign_add(mae)\n",
        "\n",
        "    def result(self):\n",
        "        return self.mae\n",
        "\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mae.assign(0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "G5VrstmeJTWK"
      },
      "outputs": [],
      "source": [
        "class CustomLoss(keras.losses.Loss):\n",
        "\n",
        "    def __init__(self,**kwargs):\n",
        "\n",
        "        super(CustomLoss,self).__init__(**kwargs)\n",
        "\n",
        "    def __call__(self,y_true,y_pred,sample_weight=None):\n",
        "\n",
        "        y_true = tf.clip_by_value(y_true,clip_value_max=1,clip_value_min=0)\n",
        "        y_pred = tf.clip_by_value(y_pred,clip_value_max=1,clip_value_min=0)\n",
        "        mae_loss = tf.reduce_mean(tf.abs(tf.subtract(y_true,y_pred)),axis=-1)\n",
        "        return mae_loss[~tf.math.is_nan(mae_loss)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Eu1t6a8JVon",
        "outputId": "0c1cd5ba-e572-4df2-e664-1b58a7c45748"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:        [0.4016784  0.55617905 0.51117903 ... 0.4618883  0.22261198 0.4281115 ]\n",
            "Metric 2A3:  0.27917036\n",
            "Metric DMS:  0.61651343\n"
          ]
        }
      ],
      "source": [
        "cust_loss= CustomLoss()\n",
        "cust_metric_2a3 = CustomMetric2A3()\n",
        "cust_metric_dms = CustomMetricDMS()\n",
        "cust_metric_2a3.update_state(y,transformer_out)\n",
        "cust_metric_dms.update_state(y,transformer_out)\n",
        "print(\"Loss:       \",cust_loss(y,transformer_out).numpy())\n",
        "print(\"Metric 2A3: \",cust_metric_2a3.result().numpy())\n",
        "print(\"Metric DMS: \",cust_metric_dms.result().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "cellView": "form",
        "id": "rTXM61TwNCSV"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "class ExpLR(keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self,factor,**kwargs):\n",
        "\n",
        "        super(ExpLR,self).__init__(**kwargs)\n",
        "        self.factor = factor\n",
        "        self.rates = []\n",
        "        self.losses = []\n",
        "\n",
        "    def on_epoch_begin(self,epoch,logs=None):\n",
        "        self.sum_of_epoch_losses = 0\n",
        "\n",
        "    def on_batch_end(self,batch,logs=None):\n",
        "        mean_epoch_loss = logs[\"loss\"]\n",
        "        new_sum_of_epoch_losses = mean_epoch_loss * (batch+1)\n",
        "        batch_loss = new_sum_of_epoch_losses - self.sum_of_epoch_losses\n",
        "        self.sum_of_epoch_losses = new_sum_of_epoch_losses\n",
        "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
        "        self.losses.append(batch_loss)\n",
        "        K.set_value(self.model.optimizer.learning_rate,self.model.optimizer.learning_rate* self.factor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "cellView": "form",
        "id": "2XIkZbqcNGi4"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "def find_learning_rate(model,ds,iterations,epochs,batch_size,min_rate:float=1e-7,max_rate:float=1):\n",
        "\n",
        "    init_weights = model.get_weights()\n",
        "    total_iterations = iterations * epochs\n",
        "    steps_per_epoch = iterations//batch_size\n",
        "    factor = (max_rate/min_rate) ** (1/total_iterations)\n",
        "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
        "    K.set_value(model.optimizer.learning_rate,min_rate)\n",
        "    exp_lr = ExpLR(factor)\n",
        "    history = model.fit(ds,epochs=epochs,steps_per_epoch=steps_per_epoch,callbacks=[exp_lr])\n",
        "    return exp_lr.rates,exp_lr.losses,init_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "vMq_XQacl-_-"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "steps_per_epoch = 1175\n",
        "num_train_steps = 1175 * BATCH_SIZE\n",
        "validation_steps = 141\n",
        "num_valid_steps = 141 * BATCH_SIZE\n",
        "test_steps = 94"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "FHQunDzxCpc3"
      },
      "outputs": [],
      "source": [
        "class MyHypermodel(kt.HyperModel):\n",
        "    \n",
        "    def build(self,hp):\n",
        "        \n",
        "        "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPusb+ZQFiXt2goQjbsWiuB",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
