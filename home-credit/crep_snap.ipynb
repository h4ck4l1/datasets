{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,warnings,gc\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "from glob import glob\n",
    "from sklearn.metrics import roc_auc_score,auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedGroupKFold,train_test_split\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from typing import Literal\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.Config.set_float_precision(2)\n",
    "pl.Config.set_fmt_float(\"full\")\n",
    "pl.Config.set_tbl_rows(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train = \"/home/sohail/Downloads/credit_risk/train/\"\n",
    "path_to_test = \"/home/sohail/Downloads/credit_risk/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>path</th><th>filename</th></tr><tr><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>31</td><td>&quot;/home/sohail/D…</td><td>&quot;train_applprev…</td></tr><tr><td>13</td><td>&quot;/home/sohail/D…</td><td>&quot;train_applprev…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>7</td><td>&quot;/home/sohail/D…</td><td>&quot;train_base.par…</td></tr><tr><td>11</td><td>&quot;/home/sohail/D…</td><td>&quot;train_credit_b…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌───────┬───────────────────────────────────┬───────────────────────────────────┐\n",
       "│ index ┆ path                              ┆ filename                          │\n",
       "│ ---   ┆ ---                               ┆ ---                               │\n",
       "│ i64   ┆ str                               ┆ str                               │\n",
       "╞═══════╪═══════════════════════════════════╪═══════════════════════════════════╡\n",
       "│ 31    ┆ /home/sohail/Downloads/credit_ri… ┆ train_applprev_1_0.parquet        │\n",
       "│ 13    ┆ /home/sohail/Downloads/credit_ri… ┆ train_applprev_1_1.parquet        │\n",
       "│ …     ┆ …                                 ┆ …                                 │\n",
       "│ 7     ┆ /home/sohail/Downloads/credit_ri… ┆ train_base.parquet                │\n",
       "│ 11    ┆ /home/sohail/Downloads/credit_ri… ┆ train_credit_bureau_a_1_0.parque… │\n",
       "└───────┴───────────────────────────────────┴───────────────────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>path</th><th>filename</th></tr><tr><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>31</td><td>&quot;/home/sohail/D…</td><td>&quot;test_applprev_…</td></tr><tr><td>35</td><td>&quot;/home/sohail/D…</td><td>&quot;test_applprev_…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1</td><td>&quot;/home/sohail/D…</td><td>&quot;test_applprev_…</td></tr><tr><td>33</td><td>&quot;/home/sohail/D…</td><td>&quot;test_base.parq…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌───────┬───────────────────────────────────┬───────────────────────────┐\n",
       "│ index ┆ path                              ┆ filename                  │\n",
       "│ ---   ┆ ---                               ┆ ---                       │\n",
       "│ i64   ┆ str                               ┆ str                       │\n",
       "╞═══════╪═══════════════════════════════════╪═══════════════════════════╡\n",
       "│ 31    ┆ /home/sohail/Downloads/credit_ri… ┆ test_applprev_1_0.parquet │\n",
       "│ 35    ┆ /home/sohail/Downloads/credit_ri… ┆ test_applprev_1_1.parquet │\n",
       "│ …     ┆ …                                 ┆ …                         │\n",
       "│ 1     ┆ /home/sohail/Downloads/credit_ri… ┆ test_applprev_2.parquet   │\n",
       "│ 33    ┆ /home/sohail/Downloads/credit_ri… ┆ test_base.parquet         │\n",
       "└───────┴───────────────────────────────────┴───────────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_train_files = glob(path_to_train+\"/*.parquet\")\n",
    "all_test_files = glob(path_to_test+\"/*.parquet\")\n",
    "train_files_df = pl.DataFrame({\"index\":range(len(all_train_files)),\"path\":all_train_files})\n",
    "test_files_df = pl.DataFrame({\"index\":range(len(all_test_files)),\"path\":all_test_files})\n",
    "train_files_df = (\n",
    "    train_files_df\n",
    "    .with_columns(\n",
    "        (pl.col(\"path\").str.split(\"/\").list.get(-1)).alias(\"filename\")\n",
    "    )\n",
    "    .sort(by=\"filename\")\n",
    ")\n",
    "test_files_df = (\n",
    "    test_files_df\n",
    "    .with_columns(\n",
    "        (pl.col(\"path\").str.split(\"/\").list.get(-1)).alias(\"filename\")\n",
    "    )\n",
    "    .sort(by=\"filename\")\n",
    ")\n",
    "display(train_files_df.head())\n",
    "display(test_files_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base = (\n",
    "    pl.read_parquet(path_to_train+\"/train_base.parquet\")\n",
    "    .select(\n",
    "        pl.col(\"case_id\").cast(pl.UInt32).alias(\"case_id_base\"),\n",
    "        cs.contains(\"date\").str.to_date().alias(\"Date\"),\n",
    "        pl.col(\"WEEK_NUM\").cast(pl.UInt8).alias(\"week_num\"),\n",
    "        pl.col(\"target\").cast(pl.UInt8)\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"Date\").dt.month().alias(\"month\"),\n",
    "        pl.col(\"Date\").dt.weekday().alias(\"weekday\"),\n",
    "        pl.col(\"Date\").dt.week().alias(\"week\"),\n",
    "        (pl.col(\"Date\").dt.year() - 2018).alias(\"year\")\n",
    "    )\n",
    "    .select(~cs.contains(\"target\"),cs.contains(\"target\"))\n",
    ")\n",
    "test_base = (\n",
    "    pl.read_parquet(path_to_test+\"/test_base.parquet\")\n",
    "    .select(\n",
    "        pl.col(\"case_id\").cast(pl.UInt32).alias(\"case_id_base\"),\n",
    "        cs.contains(\"date\").str.to_date().alias(\"Date\"),\n",
    "        pl.col(\"WEEK_NUM\").cast(pl.UInt8).alias(\"week_num\")\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"Date\").dt.month().alias(\"month\"),\n",
    "        pl.col(\"Date\").dt.weekday().alias(\"weekday\"),\n",
    "        pl.col(\"Date\").dt.week().alias(\"week\"),\n",
    "        (pl.col(\"Date\").dt.year() - 2018).alias(\"year\"),\n",
    "        pl.lit(0).cast(pl.UInt8).alias(\"target\")\n",
    "    )\n",
    ")\n",
    "train_case_ids = train_base.select(\"case_id_base\").to_series().to_numpy()\n",
    "test_case_ids = test_base.select(\"case_id_base\").to_series().to_numpy()\n",
    "sub_length = len(test_case_ids)\n",
    "total_base = (\n",
    "    pl.concat(\n",
    "        [\n",
    "            train_base,\n",
    "            test_base\n",
    "        ],\n",
    "        how=\"vertical\"\n",
    "    )\n",
    ")\n",
    "del train_base,test_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_df = (\n",
    "    pl.DataFrame({\n",
    "        \"col_name\":list(\n",
    "            set(\n",
    "                pl.read_parquet(\"/home/sohail/Downloads/lgb_imp.parquet\")\n",
    "                .filter(pl.col(\"index\").str.contains(\"Date\").not_())\n",
    "                .select(pl.col(\"index\"),pl.mean_horizontal(cs.numeric()).alias(\"mean\"))\n",
    "                .sort(by=\"mean\")\n",
    "                .filter(pl.col(\"mean\") > 4000)\n",
    "                [\"index\"].to_list()\n",
    "            ).intersection(set(\n",
    "                pl.read_parquet(\"/home/sohail/Downloads/xgb_imp.parquet\")\n",
    "                .filter(pl.col(\"index\").str.contains(\"Date\").not_())\n",
    "                .select(pl.col(\"index\"),pl.mean_horizontal(cs.numeric()).alias(\"mean\"))\n",
    "                .sort(by=\"mean\")\n",
    "                .filter(pl.col(\"mean\") > 0.0005)\n",
    "                [\"index\"].to_list()\n",
    "            )).intersection(set(\n",
    "                pl.read_parquet(\"/home/sohail/Downloads/cat_imp.parquet\")\n",
    "                .filter(pl.col(\"index\").str.contains(\"Date\").not_())\n",
    "                .select(pl.col(\"index\"),pl.mean_horizontal(cs.numeric()).alias(\"mean\"))\n",
    "                .sort(by=\"mean\")\n",
    "                .filter(pl.col(\"mean\") > 0.02)\n",
    "                [\"index\"].to_list()\n",
    "            )\n",
    "            )\n",
    "        )\n",
    "    })\n",
    "    .with_columns(\n",
    "        pl.col(\"col_name\").str.split_exact(\"_\",2).alias(\"name\")\n",
    "    )\n",
    "    .unnest(\"name\")\n",
    "    .filter(\n",
    "        pl.col(\"field_0\").is_not_null() & pl.col(\"field_1\").is_not_null()\n",
    "    )\n",
    ")\n",
    "\n",
    "def get_columns(type:str,name:str,date:Literal[\"year\",\"month\",\"week\",None]=None):\n",
    "    if date:\n",
    "        return (\n",
    "            col_df\n",
    "            .select(\n",
    "                pl.when(\n",
    "                    pl.col(\"field_0\").str.contains(date)\n",
    "                    &\n",
    "                    pl.col(\"field_2\").str.contains(name)\n",
    "                )\n",
    "                .then(\n",
    "                    pl.col(\"col_name\").str.split(\"_\").list.slice(1).list.join(\"_\")\n",
    "                )\n",
    "            )\n",
    "            .drop_nulls()\n",
    "            .unique()\n",
    "            .sort(by=\"col_name\")\n",
    "            [\"col_name\"].to_list()\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            col_df\n",
    "            .select(\n",
    "                pl.when(\n",
    "                    pl.col(\"field_0\").str.contains(type)\n",
    "                    &\n",
    "                    pl.col(\"field_1\").str.contains(name)\n",
    "                )\n",
    "                .then(\n",
    "                    pl.col(\"col_name\").str.split(\"_\").list.slice(1).list.join(\"_\")\n",
    "                )\n",
    "                .when(\n",
    "                    pl.col(\"field_1\").str.contains(type)\n",
    "                    &\n",
    "                    pl.col(\"field_2\").str.contains(name)\n",
    "                )\n",
    "                .then(\n",
    "                    pl.col(\"col_name\").str.split(\"_\").list.slice(2).list.join(\"_\")\n",
    "                )\n",
    "            )\n",
    "            .drop_nulls()\n",
    "            .unique()\n",
    "            .sort(by=\"col_name\")\n",
    "            [\"col_name\"].to_list()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dtypes(df:pl.DataFrame,name:str):\n",
    "    if name == \"intshallow\":\n",
    "        df = df.rename(\n",
    "            {\n",
    "                \"dpdmaxdatemonth_442T\":\"dpdmaxdatemonth_442D\",\n",
    "                \"dpdmaxdatemonth_89T\":\"dpdmaxdatemonth_89D\",\n",
    "                \"dpdmaxdateyear_596T\":\"dpdmaxdateyear_596D\",\n",
    "                \"dpdmaxdateyear_896T\":\"dpdmaxdateyear_896D\",\n",
    "                \"overdueamountmaxdatemonth_284T\":\"overdueamountmaxdatemonth_284D\",\n",
    "                \"overdueamountmaxdatemonth_365T\":\"overdueamountmaxdatemonth_365D\",\n",
    "                \"overdueamountmaxdateyear_2T\":\"overdueamountmaxdateyear_2D\",\n",
    "                \"overdueamountmaxdateyear_994T\":\"overdueamountmaxdateyear_994D\",\n",
    "            }\n",
    "        )\n",
    "    elif name == \"intdepth\":\n",
    "        df = df.rename(\n",
    "            {\n",
    "                \"pmts_month_158T\":\"pmts_month_158D\",\n",
    "                \"pmts_month_706T\":\"pmts_month_706D\",\n",
    "                \"pmts_year_1139T\":\"pmts_year_1139D\",\n",
    "                \"pmts_year_507T\":\"pmts_year_507D\",\n",
    "            }\n",
    "        )\n",
    "    elif name == \"extshallow\":\n",
    "        df = df.rename(\n",
    "            {\n",
    "                \"dpdmaxdatemonth_804T\":\"dpdmaxdatemonth_804D\",\n",
    "                \"dpdmaxdateyear_742T\":\"dpdmaxdateyear_742D\",\n",
    "                \"overdueamountmaxdatemonth_494T\":\"overdueamountmaxdatemonth_494D\",\n",
    "                \"overdueamountmaxdateyear_432T\":\"overdueamountmaxdateyear_432D\",\n",
    "            }\n",
    "        )\n",
    "    return (\n",
    "        df\n",
    "        .select(\n",
    "            cs.by_name(\"case_id\").cast(pl.UInt32),\n",
    "            cs.contains(\"num_group\").cast(pl.UInt16).prefix(f\"{name}_\"),\n",
    "            cs.ends_with(\"D\").cast(pl.Date).prefix(f\"{name}_\"),\n",
    "            cs.ends_with(\"T\",\"M\").cast(pl.String).prefix(f\"{name}_\"),\n",
    "            cs.ends_with(\"P\",\"A\").cast(pl.Float32).prefix(f\"{name}_\"),\n",
    "            (cs.ends_with(\"L\") & cs.numeric()).cast(pl.Float32).prefix(f\"{name}_\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "def grouping(df:pl.DataFrame,name:str):\n",
    "    return (\n",
    "        df\n",
    "        .group_by(\"case_id\")\n",
    "        .agg(\n",
    "            cs.by_name(get_columns(\"mean\",name)).mean().prefix(\"mean_\"),\n",
    "            cs.by_name(get_columns(\"max\",name)).max().prefix(\"max_\"),\n",
    "            cs.by_name(get_columns(\"var\",name)).var().prefix(\"var_\"),\n",
    "            (cs.string() | cs.boolean()).drop_nulls().mode().first().prefix(\"mode_\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "def date_features(df:pl.DataFrame,name:str):\n",
    "    return (\n",
    "        df\n",
    "        .join(\n",
    "            total_base.select([\"case_id_base\",\"Date\"]),\n",
    "            left_on=\"case_id\",\n",
    "            right_on=\"case_id_base\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "        .with_columns(\n",
    "            (pl.col(pl.Date) - pl.col(\"Date\")).dt.total_days(),\n",
    "            (cs.by_name(get_columns(\"mean\",name,\"year\")).dt.year() - 2018).cast(pl.Int8).prefix(\"year_\"),\n",
    "            cs.by_name(get_columns(\"mean\",name,\"month\")).dt.month().cast(pl.Int8).prefix(\"month_\"),\n",
    "            cs.by_name(get_columns(\"mean\",name,\"week\")).dt.week().cast(pl.Int8).prefix(\"week_\")\n",
    "        )\n",
    "        .drop(\"Date\")\n",
    "    )\n",
    "\n",
    "def select_low_cat_cols(df:pl.DataFrame,thresh=200):\n",
    "    cols = []\n",
    "    for col_name in df.select(pl.col(pl.Categorical)).columns:\n",
    "        if df.select(pl.col(col_name).unique()).shape[0] >= thresh:\n",
    "            cols.append(col_name)\n",
    "        if df.select(pl.col(col_name).unique()).shape[0] <= 1:\n",
    "            cols.append(col_name)\n",
    "    return df.drop(cols)\n",
    "\n",
    "def select_impuatable(df:pl.DataFrame,thresh=0.95):\n",
    "    cols =  (\n",
    "        df\n",
    "        .select(pl.all().is_null().mean())\n",
    "        .transpose(include_header=True)\n",
    "        .filter(pl.col(\"column_0\") < thresh)\n",
    "        [\"column\"].to_list()\n",
    "    )\n",
    "    return df.select(cols)\n",
    "\n",
    "def preprocess(filter_string:str,prefix_string:str):\n",
    "    train_files_list = train_files_df.filter(pl.col(\"filename\").str.contains(filter_string))[\"path\"].to_list()\n",
    "    test_files_list = test_files_df.filter(pl.col(\"filename\").str.contains(filter_string))[\"path\"].to_list()\n",
    "    with pl.StringCache():\n",
    "        train_df = (\n",
    "            pl.concat(\n",
    "                [\n",
    "                    pl.read_parquet(_).pipe(reduce_dtypes,prefix_string).pipe(grouping,prefix_string) for _ in train_files_list\n",
    "                ],\n",
    "                how=\"vertical_relaxed\"\n",
    "            )\n",
    "        )\n",
    "        gc.collect()\n",
    "        test_df = (\n",
    "            pl.concat(\n",
    "                [\n",
    "                    pl.read_parquet(_).pipe(reduce_dtypes,prefix_string).pipe(grouping,prefix_string) for _ in test_files_list\n",
    "                ],\n",
    "                how=\"vertical_relaxed\"\n",
    "            )\n",
    "        )\n",
    "        gc.collect()\n",
    "    return (\n",
    "        pl.concat(\n",
    "            [\n",
    "                train_df,\n",
    "                test_df\n",
    "            ],\n",
    "            how=\"vertical_relaxed\"\n",
    "        )\n",
    "        .pipe(select_impuatable)\n",
    "        .pipe(select_low_cat_cols)\n",
    "        .with_columns(\n",
    "            pl.col(pl.String).cast(pl.Categorical).rank(\"dense\")\n",
    "        )\n",
    "        .pipe(date_features,prefix_string)\n",
    "        .select(pl.all().shrink_dtype())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 1\n",
      "done 2\n"
     ]
    }
   ],
   "source": [
    "total_past_shallow = preprocess(\"applprev_1\", \"pastshallow\")\n",
    "# display(total_past_shallow)\n",
    "print(\"done 1\")\n",
    "\n",
    "total_past_depth = preprocess(\"applprev_2\", \"pastdepth\")\n",
    "# display(total_past_depth)\n",
    "print(\"done 2\")\n",
    "\n",
    "total_static_base = preprocess(\"static_0\",\"staticbase\")\n",
    "# display(total_static_base)\n",
    "print(\"done 3\")\n",
    "\n",
    "\n",
    "total_static_external = (\n",
    "    preprocess(\"static_cb\", \"staticexternal\")\n",
    "    .with_columns(\n",
    "        cs.contains(\"riskassesment_302T\").str.split(\"%\").list.gather([0, 1]).apply(\n",
    "            lambda x: (int(x[0]) + int(x[1].split(\"-\")[1])) / 200\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# display(total_static_external)\n",
    "print(\"done 4\")\n",
    "\n",
    "\n",
    "total_person_shallow = preprocess(\"person_1\", \"personshallow\")\n",
    "# display(total_person_shallow)\n",
    "print(\"done 5\")\n",
    "\n",
    "\n",
    "total_person_depth = preprocess(\"person_2\", \"persondepth\")\n",
    "# display(total_person_depth)\n",
    "print(\"done 6\")\n",
    "\n",
    "\n",
    "total_other_shallow = preprocess(\"other_1\", \"othershallow\")\n",
    "# display(total_other_shallow)\n",
    "print(\"done 7\")\n",
    "\n",
    "\n",
    "total_deposit_shallow = preprocess(\"deposit_1\", \"depositshallow\")\n",
    "# display(total_deposit_shallow)\n",
    "print(\"done 8\")\n",
    "\n",
    "\n",
    "total_debitcard_shallow = preprocess(\"debitcard\", \"cardshallow\")\n",
    "# display(total_debitcard_shallow)\n",
    "print(\"done 9\")\n",
    "\n",
    "\n",
    "total_credit_internal_shallow = preprocess(\"bureau_a_1\", \"intshallow\")\n",
    "# display(total_credit_internal_shallow)\n",
    "print(\"done 10\")\n",
    "\n",
    "\n",
    "total_credit_internal_depth = preprocess(\"bureau_a_2\", \"intdepth\")\n",
    "# display(total_credit_internal_depth)\n",
    "print(\"done 11\")\n",
    "\n",
    "\n",
    "total_credit_external_shallow = preprocess(\"bureau_b_1\", \"extshallow\")\n",
    "# display(total_credit_external_shallow)\n",
    "print(\"done 12\")\n",
    "\n",
    "\n",
    "total_credit_external_depth = preprocess(\"bureau_b_2\", \"extdepth\")\n",
    "# display(total_credit_external_depth)\n",
    "print(\"done 13\")\n",
    "\n",
    "\n",
    "total_registry_a = preprocess(\"registry_a\", \"rega\")\n",
    "# display(total_registry_a)\n",
    "print(\"done 14\")\n",
    "\n",
    "\n",
    "total_registry_b = preprocess(\"registry_b\", \"regb\")\n",
    "# display(total_registry_b)\n",
    "print(\"done 15\")\n",
    "\n",
    "\n",
    "total_registry_c = preprocess(\"registry_c\", \"regc\")\n",
    "# display(total_registry_c)\n",
    "print(\"done 16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df = (\n",
    "    total_base\n",
    "    .join(\n",
    "        total_past_shallow,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_past_depth,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_static_base,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_static_external,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_person_shallow,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_person_depth,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_other_shallow,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_deposit_shallow,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_debitcard_shallow,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_credit_internal_shallow,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_credit_internal_depth,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_credit_external_shallow,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_credit_external_depth,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_registry_a,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_registry_b,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        total_registry_c,\n",
    "        left_on=\"case_id_base\",\n",
    "        right_on=\"case_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .drop(\"Date\")\n",
    ")\n",
    "week_num = total_df.filter(pl.col(\"case_id_base\").is_in(train_case_ids)).select(\"week_num\")\n",
    "train_df = total_df.filter(pl.col(\"case_id_base\").is_in(train_case_ids)).drop(\"case_id_base\")\n",
    "sub_df = total_df.filter(pl.col(\"case_id_base\").is_in(test_case_ids)).drop(\"target\")\n",
    "\n",
    "del train_case_ids,test_case_ids\n",
    "del total_df\n",
    "del train_files_df\n",
    "del test_files_df\n",
    "del total_base\n",
    "del total_past_shallow\n",
    "del total_past_depth\n",
    "del total_static_base\n",
    "del total_static_external\n",
    "del total_person_depth\n",
    "del total_person_shallow\n",
    "del total_other_shallow\n",
    "del total_deposit_shallow\n",
    "del total_debitcard_shallow\n",
    "del total_credit_external_depth\n",
    "del total_credit_external_shallow\n",
    "del total_credit_internal_depth\n",
    "del total_credit_internal_shallow\n",
    "del total_registry_a\n",
    "del total_registry_b\n",
    "del total_registry_c\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_params = {\n",
    "    \"objective\":\"binary\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"metric\":\"auc\",\n",
    "    \"max_depth\": 64,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"n_estimators\": 8000,\n",
    "    \"max_data_per_bin\": 258,\n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"random_state\": 420,\n",
    "    \"reg_alpha\": 0.15,\n",
    "    \"reg_lambda\": 15,\n",
    "    \"extra_trees\": True,\n",
    "    \"num_leaves\": 256,\n",
    "    \"device\": \"gpu\",\n",
    "    \"importance_type\": \"gain\",\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"n_estimators\": 8000,\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"seed\": 420,\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"eta\": 0.005,\n",
    "    \"gamma\": 5,\n",
    "    \"max_depth\": 64,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"lambda\": 10,\n",
    "    \"alpha\": 2,\n",
    "    \"updater\": \"grow_gpu_hist\",\n",
    "    \"grow_policy\": \"depthwise\",\n",
    "    \"max_leaves\": 256,\n",
    "    \"num_parallel_tree\": 1,    \n",
    "    \"sample_type\": \"uniform\",\n",
    "    \"normalize_type\": \"tree\",\n",
    "    \"rate_drop\": 0.15,\n",
    "    \"skip_drop\": 0.9,\n",
    "    \"enable_categorical\": True\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"task_type\": \"GPU\",\n",
    "    \"iterations\": 8000,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"bootstrap_type\": \"Poisson\",\n",
    "    \"random_seed\": 420,\n",
    "    \"l2_leaf_reg\": 15,\n",
    "    \"subsample\": 0.8,\n",
    "    \"depth\": 32,\n",
    "    \"max_leaves\": 64,\n",
    "    \"grow_policy\": \"Lossguide\",\n",
    "    \"od_type\": \"Iter\",\n",
    "    \"od_wait\": 500,\n",
    "    \"verbose\": 500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_ind(df:pl.DataFrame,indexes:np.array):\n",
    "    return (\n",
    "        df\n",
    "        .with_row_index()\n",
    "        .filter(\n",
    "            pl.col(\"index\").is_in(indexes)\n",
    "        )\n",
    "        .drop(\"index\")\n",
    "    )\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sub_length <= 10:\n",
    "    train_df = train_df.with_row_index().filter(pl.col(\"index\").hash(512)%30 == 1).drop(\"index\")\n",
    "    week_num = week_num.with_row_index().filter(pl.col(\"index\").hash(512)%30 == 1).drop(\"index\")\n",
    "    class_params[\"n_estimators\"] = 2000\n",
    "    class_params[\"learning_rate\"] = 0.01\n",
    "    xgb_params[\"n_estimators\"] = 2000\n",
    "    xgb_params[\"eta\"] = 0.01\n",
    "    cat_params[\"iterations\"] = 2000\n",
    "    cat_params[\"learning_rate\"] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self,\n",
    "        sub_df:pl.DataFrame\n",
    "        ):\n",
    "        self.df = sub_df.drop(\"case_id_base\")\n",
    "        self.lgb_pred = []\n",
    "        self.xgb_pred = []\n",
    "        self.cat_pred = []\n",
    "\n",
    "    def _predict_lgb(self,model):\n",
    "        self.lgb_pred.append(model.predict_proba(self.df)[:,1])\n",
    "        gc.collect()\n",
    "\n",
    "    def _predict_xgb(self,model):\n",
    "        self.xgb_pred.append(model.predict_proba(self.df)[:,1])\n",
    "        gc.collect()\n",
    "\n",
    "    def _predict_cat(self,model):\n",
    "        self.cat_pred.append(model.predict_proba(self.df.to_pandas())[:,1])\n",
    "        gc.collect()\n",
    "\n",
    "    def predict_proba(self):\n",
    "        return np.mean(\n",
    "            self.lgb_pred+\\\n",
    "            self.xgb_pred+\\\n",
    "            self.cat_pred,\n",
    "            axis=0\n",
    "        )\n",
    "model = Model(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start for LGBClassifier: 1\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\tvalid_0's auc: 0.806296\n",
      "[1000]\tvalid_0's auc: 0.807089\n",
      "[1500]\tvalid_0's auc: 0.803433\n",
      "Early stopping, best iteration is:\n",
      "[909]\tvalid_0's auc: 0.807739\n",
      "Training start for LGBClassifier: 2\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\tvalid_0's auc: 0.8248\n",
      "[1000]\tvalid_0's auc: 0.824267\n",
      "Early stopping, best iteration is:\n",
      "[643]\tvalid_0's auc: 0.825251\n",
      "Training start for LGBClassifier: 3\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\tvalid_0's auc: 0.830739\n",
      "[1000]\tvalid_0's auc: 0.829862\n",
      "Early stopping, best iteration is:\n",
      "[646]\tvalid_0's auc: 0.831599\n",
      "Training start for LGBClassifier: 4\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\tvalid_0's auc: 0.818799\n",
      "[1000]\tvalid_0's auc: 0.815034\n",
      "Early stopping, best iteration is:\n",
      "[468]\tvalid_0's auc: 0.819632\n",
      "Training start for LGBClassifier: 5\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\tvalid_0's auc: 0.823391\n",
      "[1000]\tvalid_0's auc: 0.824488\n",
      "[1500]\tvalid_0's auc: 0.823216\n",
      "Early stopping, best iteration is:\n",
      "[868]\tvalid_0's auc: 0.824956\n",
      "Training start for XGBClassifier: 1\n",
      "[0]\tvalidation_0-auc:0.65432\n",
      "[500]\tvalidation_0-auc:0.80714\n",
      "[1000]\tvalidation_0-auc:0.80897\n",
      "[1374]\tvalidation_0-auc:0.80897\n",
      "Training start for XGBClassifier: 2\n",
      "[0]\tvalidation_0-auc:0.67897\n",
      "[500]\tvalidation_0-auc:0.81091\n",
      "[1000]\tvalidation_0-auc:0.81325\n",
      "[1384]\tvalidation_0-auc:0.81325\n",
      "Training start for XGBClassifier: 3\n",
      "[0]\tvalidation_0-auc:0.66314\n",
      "[500]\tvalidation_0-auc:0.81511\n",
      "[1000]\tvalidation_0-auc:0.81845\n",
      "[1401]\tvalidation_0-auc:0.81845\n",
      "Training start for XGBClassifier: 4\n",
      "[0]\tvalidation_0-auc:0.63008\n",
      "[500]\tvalidation_0-auc:0.80835\n",
      "[1000]\tvalidation_0-auc:0.81236\n",
      "[1500]\tvalidation_0-auc:0.81236\n",
      "[1506]\tvalidation_0-auc:0.81236\n",
      "Training start for XGBClassifier: 5\n",
      "[0]\tvalidation_0-auc:0.66436\n",
      "[500]\tvalidation_0-auc:0.80961\n",
      "[1000]\tvalidation_0-auc:0.81479\n",
      "[1383]\tvalidation_0-auc:0.81479\n",
      "Training start for CatBoostClassifier: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.5904708\tbest: 0.5904708 (0)\ttotal: 80.7ms\tremaining: 2m 41s\n",
      "500:\ttest: 0.8079814\tbest: 0.8080245 (495)\ttotal: 9.44s\tremaining: 28.2s\n",
      "1000:\ttest: 0.8094037\tbest: 0.8100091 (862)\ttotal: 19.1s\tremaining: 19.1s\n",
      "bestTest = 0.8100091219\n",
      "bestIteration = 862\n",
      "Shrink model to first 863 iterations.\n",
      "Training start for CatBoostClassifier: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.5561447\tbest: 0.5561447 (0)\ttotal: 19.2ms\tremaining: 38.4s\n",
      "500:\ttest: 0.8236493\tbest: 0.8236493 (500)\ttotal: 9.43s\tremaining: 28.2s\n",
      "1000:\ttest: 0.8285884\tbest: 0.8289168 (965)\ttotal: 19s\tremaining: 19s\n",
      "1500:\ttest: 0.8276383\tbest: 0.8292733 (1357)\ttotal: 28.6s\tremaining: 9.52s\n",
      "bestTest = 0.8292733431\n",
      "bestIteration = 1357\n",
      "Shrink model to first 1358 iterations.\n",
      "Training start for CatBoostClassifier: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.5957471\tbest: 0.5957471 (0)\ttotal: 18ms\tremaining: 36s\n",
      "500:\ttest: 0.8189771\tbest: 0.8189771 (500)\ttotal: 9.18s\tremaining: 27.5s\n",
      "1000:\ttest: 0.8234265\tbest: 0.8240911 (787)\ttotal: 18.7s\tremaining: 18.7s\n",
      "bestTest = 0.8240910769\n",
      "bestIteration = 787\n",
      "Shrink model to first 788 iterations.\n",
      "Training start for CatBoostClassifier: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.5650345\tbest: 0.5650345 (0)\ttotal: 17.8ms\tremaining: 35.7s\n",
      "500:\ttest: 0.8161178\tbest: 0.8161525 (498)\ttotal: 9.3s\tremaining: 27.8s\n",
      "1000:\ttest: 0.8154657\tbest: 0.8178689 (623)\ttotal: 18.8s\tremaining: 18.8s\n",
      "bestTest = 0.817868948\n",
      "bestIteration = 623\n",
      "Shrink model to first 624 iterations.\n",
      "Training start for CatBoostClassifier: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6304987\tbest: 0.6304987 (0)\ttotal: 19.2ms\tremaining: 38.5s\n",
      "500:\ttest: 0.8201178\tbest: 0.8201178 (500)\ttotal: 9.15s\tremaining: 27.4s\n",
      "1000:\ttest: 0.8254408\tbest: 0.8258091 (979)\ttotal: 18.7s\tremaining: 18.7s\n",
      "1500:\ttest: 0.8259228\tbest: 0.8261347 (1486)\ttotal: 28.5s\tremaining: 9.46s\n",
      "1999:\ttest: 0.8256923\tbest: 0.8265126 (1884)\ttotal: 38.1s\tremaining: 0us\n",
      "bestTest = 0.8265126348\n",
      "bestIteration = 1884\n",
      "Shrink model to first 1885 iterations.\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedGroupKFold(n_splits=5,shuffle=False)\n",
    "\n",
    "for i,(train_ind,valid_ind) in enumerate(\n",
    "    cv.split(train_df,train_df.select(\"target\"),\n",
    "    groups=week_num)):\n",
    "    print(f\"Training start for LGBClassifier: {i+1}\")\n",
    "    if i%2 != 0:\n",
    "        class_params[\"reg_alpha\"] = 0.2\n",
    "        class_params[\"reg_lambda\"] = 2\n",
    "        class_params[\"random_state\"] = 42\n",
    "    lgb_model = lgb.LGBMClassifier(**class_params)\n",
    "    lgb_model.fit(\n",
    "        (\n",
    "            train_df\n",
    "            .drop(\"target\")\n",
    "            .pipe(filter_ind,train_ind)\n",
    "        ),\n",
    "        (\n",
    "            train_df\n",
    "            .select('target')\n",
    "            .pipe(filter_ind,train_ind)\n",
    "        ),\n",
    "        eval_set=[(\n",
    "            (\n",
    "                train_df\n",
    "                .drop(\"target\")\n",
    "                .pipe(filter_ind,valid_ind)\n",
    "            ),\n",
    "            (\n",
    "                train_df\n",
    "                .select(\"target\")\n",
    "                .pipe(filter_ind,valid_ind)\n",
    "            )\n",
    "        )],\n",
    "        callbacks=[lgb.log_evaluation(500),lgb.early_stopping(800)]\n",
    "    )\n",
    "    gc.collect()\n",
    "    model._predict_lgb(lgb_model)\n",
    "\n",
    "del train_ind,valid_ind,lgb_model\n",
    "gc.collect()\n",
    "\n",
    "for i,(train_ind,valid_ind) in enumerate(\n",
    "    cv.split(train_df,train_df.select(\"target\"),\n",
    "    groups=week_num)):\n",
    "    print(f\"Training start for XGBClassifier: {i+1}\")\n",
    "    if i%2 != 0:\n",
    "        xgb_params[\"lambda\"] = 15\n",
    "        xgb_params[\"alpha\"] = 5\n",
    "        xgb_params[\"gamma\"] = 8\n",
    "        xgb_params[\"seed\"] = 42\n",
    "    early_stop = xgb.callback.EarlyStopping(rounds=800)\n",
    "    log_eval = xgb.callback.EvaluationMonitor(period=500)\n",
    "    xgb_model = xgb.XGBClassifier(**xgb_params)\n",
    "    xgb_model.fit(\n",
    "        (\n",
    "            train_df\n",
    "            .drop(\"target\")\n",
    "            .pipe(filter_ind,train_ind)\n",
    "        ),\n",
    "        (\n",
    "            train_df\n",
    "            .select(\"target\")\n",
    "            .pipe(filter_ind,train_ind)\n",
    "        ),\n",
    "        eval_set=[(\n",
    "            (\n",
    "                train_df\n",
    "                .drop(\"target\")\n",
    "                .pipe(filter_ind,valid_ind)\n",
    "            ),\n",
    "            (\n",
    "                train_df\n",
    "                .select(\"target\")\n",
    "                .pipe(filter_ind,valid_ind)\n",
    "            )\n",
    "        )],\n",
    "        callbacks=[early_stop,log_eval],\n",
    "        verbose=False\n",
    "    )\n",
    "    gc.collect()\n",
    "    model._predict_xgb(xgb_model)\n",
    "\n",
    "del xgb_model,train_ind,valid_ind,log_eval,early_stop\n",
    "gc.collect()\n",
    "\n",
    "for i,(train_ind,valid_ind) in enumerate(\n",
    "    cv.split(train_df,train_df.select(\"target\"),\n",
    "    groups=week_num)):\n",
    "    print(f\"Training start for CatBoostClassifier: {i+1}\")\n",
    "    if i%2 != 0:\n",
    "        cat_params[\"l2_leaf_reg\"] = 20\n",
    "        cat_params[\"random_seed\"] = 42\n",
    "    cat_model = cgb.CatBoostClassifier(**cat_params)\n",
    "    cat_model.fit(\n",
    "        (\n",
    "            train_df\n",
    "            .drop(\"target\")\n",
    "            .pipe(filter_ind,train_ind)\n",
    "            .to_pandas()\n",
    "        ),\n",
    "        (\n",
    "            train_df\n",
    "            .select(\"target\")\n",
    "            .pipe(filter_ind,train_ind)\n",
    "            .to_pandas()\n",
    "        ),\n",
    "        eval_set=[(\n",
    "            (\n",
    "                train_df\n",
    "                .drop(\"target\")\n",
    "                .pipe(filter_ind,valid_ind)\n",
    "                .to_pandas()\n",
    "            ),\n",
    "            (\n",
    "                train_df\n",
    "                .select(\"target\")\n",
    "                .pipe(filter_ind,valid_ind)\n",
    "                .to_pandas()\n",
    "            )\n",
    "        )]\n",
    "    )\n",
    "    gc.collect()\n",
    "    model._predict_cat(cat_model)\n",
    "\n",
    "del train_df,cat_model,train_ind,valid_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57543</th>\n",
       "      <td>0.241406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57549</th>\n",
       "      <td>0.055360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57551</th>\n",
       "      <td>0.067224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57552</th>\n",
       "      <td>0.025680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57569</th>\n",
       "      <td>0.018475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57630</th>\n",
       "      <td>0.019885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57631</th>\n",
       "      <td>0.022177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57632</th>\n",
       "      <td>0.018504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57633</th>\n",
       "      <td>0.059204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57634</th>\n",
       "      <td>0.043389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            score\n",
       "case_id          \n",
       "57543    0.241406\n",
       "57549    0.055360\n",
       "57551    0.067224\n",
       "57552    0.025680\n",
       "57569    0.018475\n",
       "57630    0.019885\n",
       "57631    0.022177\n",
       "57632    0.018504\n",
       "57633    0.059204\n",
       "57634    0.043389"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.DataFrame({\n",
    "    \"case_id\": sub_df.select(\"case_id_base\").collect(streaming=True).to_series().to_list(),\n",
    "    \"score\": model.predict_proba()\n",
    "}).set_index(\"case_id\")\n",
    "# sub_df.to_csv(\"./submission.csv\")\n",
    "sub_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
