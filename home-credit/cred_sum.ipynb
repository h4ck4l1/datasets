{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_file.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_file.py\n",
    "import os,sys,warnings,time,re,math,gc\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "from sklearn.metrics import roc_auc_score,auc\n",
    "from sklearn.model_selection import train_test_split,StratifiedGroupKFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cgb\n",
    "\n",
    "print(\"scrpit start\")\n",
    "\n",
    "path_to_train = \"/home/sohail/Downloads/credit_risk/train\"\n",
    "path_to_test = \"/home/sohail/Downloads/credit_risk/test\"\n",
    "\n",
    "\n",
    "all_train_files = glob(path_to_train+\"/*.parquet\")\n",
    "all_test_files = glob(path_to_test+\"/*.parquet\")\n",
    "train_files_df = pl.DataFrame({\"index\":range(len(all_train_files)),\"path\":all_train_files})\n",
    "test_files_df = pl.DataFrame({\"index\":range(len(all_test_files)),\"path\":all_test_files})\n",
    "train_files_df = (\n",
    "    train_files_df\n",
    "    .with_columns(\n",
    "        (pl.col(\"path\").str.split(\"/\").list.get(-1)).alias(\"filename\")\n",
    "    )\n",
    "    .sort(by=\"filename\")\n",
    ")\n",
    "test_files_df = (\n",
    "    test_files_df\n",
    "    .with_columns(\n",
    "        (pl.col(\"path\").str.split(\"/\").list.get(-1)).alias(\"filename\")\n",
    "    )\n",
    "    .sort(by=\"filename\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_base = (\n",
    "    pl.read_parquet(path_to_train+\"/train_base.parquet\")\n",
    "    .select(\n",
    "        pl.col(\"case_id\").cast(pl.UInt64),\n",
    "        cs.contains(\"date\").str.to_date().alias(\"Date\"),\n",
    "        pl.col(\"WEEK_NUM\").cast(pl.UInt8).alias(\"week_num\"),\n",
    "        pl.col(\"target\").cast(pl.UInt8)\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"Date\").dt.month().alias(\"month\"),\n",
    "        pl.col(\"Date\").dt.weekday().alias(\"weekday\"),\n",
    "        pl.col(\"Date\").dt.week().alias(\"week\"),\n",
    "        (pl.col(\"Date\").dt.year() - 2018).cast(pl.UInt8).alias(\"year\")\n",
    "    )\n",
    "    .select(~cs.contains(\"target\"),cs.contains(\"target\"))\n",
    ")\n",
    "\n",
    "\n",
    "test_base = (\n",
    "    pl.read_parquet(path_to_test+\"/test_base.parquet\")\n",
    "    .select(\n",
    "        pl.col(\"case_id\").cast(pl.UInt64),\n",
    "        cs.contains(\"date\").str.to_date().alias(\"Date\"),\n",
    "        pl.col(\"WEEK_NUM\").cast(pl.UInt8).alias(\"week_num\")\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"Date\").dt.month().alias(\"month\"),\n",
    "        pl.col(\"Date\").dt.weekday().alias(\"weekday\"),\n",
    "        pl.col(\"Date\").dt.week().alias(\"week\"),\n",
    "        (pl.col(\"Date\").dt.year() - 2018).cast(pl.UInt8).alias(\"year\"),\n",
    "        pl.lit(0).cast(pl.UInt8).alias(\"target\")\n",
    "    )\n",
    "    .select(~cs.contains(\"target\"),cs.contains(\"target\"))\n",
    ")\n",
    "\n",
    "\n",
    "def rename_cols(df:pl.DataFrame,name:str):\n",
    "    if name == \"intshallow\":\n",
    "        return df.rename(\n",
    "            {\n",
    "                \"dpdmaxdatemonth_442T\":\"dpdmaxdatemonth_442D\",\n",
    "                \"dpdmaxdatemonth_89T\":\"dpdmaxdatemonth_89D\",\n",
    "                \"dpdmaxdateyear_596T\":\"dpdmaxdateyear_596D\",\n",
    "                \"dpdmaxdateyear_896T\":\"dpdmaxdateyear_896D\",\n",
    "                \"overdueamountmaxdatemonth_284T\":\"overdueamountmaxdatemonth_284D\",\n",
    "                \"overdueamountmaxdatemonth_365T\":\"overdueamountmaxdatemonth_365D\",\n",
    "                \"overdueamountmaxdateyear_2T\":\"overdueamountmaxdateyear_2D\",\n",
    "                \"overdueamountmaxdateyear_994T\":\"overdueamountmaxdateyear_994D\",\n",
    "            }\n",
    "        )\n",
    "    elif name == \"intdepth\":\n",
    "        return df.rename(\n",
    "            {\n",
    "                \"pmts_month_158T\":\"pmts_month_158D\",\n",
    "                \"pmts_month_706T\":\"pmts_month_706D\",\n",
    "                \"pmts_year_1139T\":\"pmts_year_1139D\",\n",
    "                \"pmts_year_507T\":\"pmts_year_507D\",\n",
    "            }\n",
    "        )\n",
    "    elif name == \"extshallow\":\n",
    "        return df.rename(\n",
    "            {\n",
    "                \"dpdmaxdatemonth_804T\":\"dpdmaxdatemonth_804D\",\n",
    "                \"dpdmaxdateyear_742T\":\"dpdmaxdateyear_742D\",\n",
    "                \"overdueamountmaxdatemonth_494T\":\"overdueamountmaxdatemonth_494D\",\n",
    "                \"overdueamountmaxdateyear_432T\":\"overdueamountmaxdateyear_432D\",\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def convert_dtype(df:pl.DataFrame):\n",
    "    return (\n",
    "        df\n",
    "        .select(\n",
    "            cs.by_name(\"case_id\").cast(pl.UInt64),\n",
    "            cs.contains(\"num_group\").cast(pl.UInt16),\n",
    "            cs.ends_with(\"D\").cast(pl.Date),\n",
    "            (cs.ends_with(\"T\",\"M\") | (cs.ends_with(\"L\") & cs.string())).cast(pl.String),\n",
    "            (cs.ends_with(\"L\") & cs.integer()).cast(pl.Int32),\n",
    "            (cs.ends_with(\"L\") & cs.float()).cast(pl.Float32),\n",
    "            (cs.ends_with(\"P\",\"A\") & cs.unsigned_integer()).cast(pl.UInt32),\n",
    "            (cs.ends_with(\"P\",\"A\") & cs.signed_integer()).cast(pl.Int32),\n",
    "            (cs.ends_with(\"P\",\"A\") & cs.float()).cast(pl.Float32),\n",
    "            pl.col(pl.Boolean)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def grouping(df:pl.DataFrame):\n",
    "    return (\n",
    "        df\n",
    "        .group_by(\"case_id\")\n",
    "        .agg(\n",
    "            cs.numeric().max().prefix(\"max_\"),\n",
    "            cs.numeric().mean().prefix(\"mean_\"),\n",
    "            cs.numeric().first().prefix(\"first_\"),\n",
    "            cs.numeric().last().prefix(\"last_\"),\n",
    "            cs.date().first().prefix(\"first_\"),\n",
    "            cs.date().last().prefix(\"last_\"),\n",
    "            (cs.string() | cs.boolean()).drop_nulls().mode().first().prefix(\"mode_\"),\n",
    "            (cs.string() | cs.boolean()).last().prefix(\"last_\"),\n",
    "            (cs.string() | cs.boolean()).first().prefix(\"first_\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def preprocess(\n",
    "        string_name:str,\n",
    "        prefix_string:str,\n",
    "        train_base_df:pl.DataFrame,\n",
    "        test_base_df:pl.DataFrame,\n",
    "        cat_cols:list,\n",
    "        num_cols:list\n",
    "        ):\n",
    "    train_files_list = train_files_df.filter(pl.col(\"filename\").str.contains(string_name))[\"path\"].to_list()\n",
    "    test_files_list = test_files_df.filter(pl.col(\"filename\").str.contains(string_name))[\"path\"].to_list()\n",
    "    with pl.StringCache():\n",
    "        train_df = (\n",
    "            pl.concat(\n",
    "                [\n",
    "                    pl.read_parquet(train_file)\n",
    "                    .pipe(rename_cols,prefix_string)\n",
    "                    .pipe(convert_dtype)\n",
    "                    .pipe(grouping)\n",
    "                    for train_file in train_files_list\n",
    "                ],\n",
    "                parallel=False,\n",
    "                rechunk=False\n",
    "            )\n",
    "        )\n",
    "        test_schema = {\"_\".join(col_name.split(\"_\")[1:]) if col_name != \"case_id\" else col_name:dtype for col_name,dtype in train_df.schema.items()}\n",
    "        test_columns = {col_name for col_name in test_schema.keys()}\n",
    "        if prefix_string == \"staticexternal\":\n",
    "            train_df = (\n",
    "                train_df\n",
    "                .with_columns(\n",
    "                    cs.contains(\"302T\").str.split(\"%\").list.gather([0,1])\n",
    "                    .map_elements(\n",
    "                        lambda x: (int(x[0]) + int(x[1].strip().split(\" \")[1]))/200,return_dtype=pl.Float32\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        cat_cols += train_df.select((~(cs.numeric() | cs.date())).prefix(f\"{prefix_string}_\")).columns\n",
    "        num_cols += train_df.select((cs.numeric() | cs.date()).exclude(\"case_id\").prefix(f\"{prefix_string}_\")).columns\n",
    "        train_base_df = train_base_df.join(\n",
    "            train_df\n",
    "            .with_columns(pl.col(pl.String).cast(pl.Categorical).rank(\"dense\"))\n",
    "            .select(pl.col(\"case_id\"),pl.all().exclude(\"case_id\").shrink_dtype().prefix(f\"{prefix_string}_\")),\n",
    "            on=\"case_id\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "        test_df = (\n",
    "            pl.concat(\n",
    "                [\n",
    "                    pl.read_parquet(test_file)\n",
    "                    .pipe(rename_cols,prefix_string)\n",
    "                    .select(test_columns)\n",
    "                    .cast(test_schema)\n",
    "                    .pipe(grouping)\n",
    "                    for test_file in test_files_list\n",
    "                ],\n",
    "                parallel=False,\n",
    "                rechunk=False\n",
    "            )\n",
    "        )\n",
    "        if prefix_string == \"staticexternal\":\n",
    "            test_df = (\n",
    "                test_df\n",
    "                .with_columns(\n",
    "                    cs.contains(\"302T\").str.split(\"%\").list.gather([0,1])\n",
    "                    .map_elements(\n",
    "                        lambda x: (int(x[0]) + int(x[1].strip().split(\" \")[1]))/200,return_dtype=pl.Float32\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        test_base_df = test_base_df.join(\n",
    "            test_df\n",
    "            .with_columns(pl.col(pl.String).cast(pl.Categorical).rank(\"dense\"))\n",
    "            .select(pl.col(\"case_id\"),pl.all().exclude(\"case_id\").shrink_dtype().prefix(f\"{prefix_string}_\")),\n",
    "            on=\"case_id\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "    return train_base_df,test_base_df,cat_cols,num_cols\n",
    "\n",
    "\n",
    "string_list = [\"applprev_1\",\"applprev_2\",\"static_0\",\"static_cb\",\"person_1\",\"person_2\",\"other_1\",\"deposit_1\",\"debitcard\",\"bureau_a_1\",\"bureau_a_2\",\"bureau_b_1\",\"bureau_b_2\",\"registry_a\",\"registry_b\",\"registry_b\"]\n",
    "prefix_string_list = [\"pastshallow\",\"pastdepth\",\"staticbase\",\"staticexternal\",\"personshallow\",\"persondepth\",\"othershallow\",\"depositshallow\",\"cardshallow\",\"intshallow\",\"intdepth\",\"extshallow\",\"extdepth\",\"rega\",\"regb\",\"regc\"]\n",
    "\n",
    "\n",
    "cat_cols = []\n",
    "num_cols = []\n",
    "count = 0\n",
    "for string_name,prefix_name in zip(string_list,prefix_string_list):\n",
    "    train_base,test_base,cat_cols,num_cols = preprocess(string_name,prefix_name,train_base,test_base,cat_cols,num_cols)\n",
    "    print(f\"done: {count+1} for {prefix_name}\")\n",
    "    count += 1\n",
    "    gc.collect()\n",
    "\n",
    "(\n",
    "    train_base\n",
    "    .with_columns(\n",
    "        (pl.col(pl.Date) - pl.col(\"Date\")).dt.total_days(),\n",
    "        pl.col(pl.Date).exclude(\"Date\").dt.weekday().prefix(\"weekdaydate_\"),\n",
    "        pl.col(pl.Date).exclude(\"Date\").dt.month().prefix(\"monthdate_\"),\n",
    "        pl.col(pl.Date).exclude(\"Date\").dt.week().prefix(\"weekdate_\")\n",
    "    )\n",
    "    .drop(\"Date\",\"case_id\")\n",
    "    .with_columns(pl.col(pl.Boolean).cast(pl.UInt8))\n",
    "    .write_parquet(\"/home/sohail/train_df.parquet\")\n",
    ")\n",
    "\n",
    "all_date_cols = train_base.select(cs.contains([\"weekdaydate\",\"monthdate\",\"weekdate\"])).columns\n",
    "cat_cols += [\"week\",\"year\",\"month\",\"weekday\"]\n",
    "cat_cols += all_date_cols\n",
    "\n",
    "(\n",
    "    test_base\n",
    "    .with_columns(\n",
    "        (pl.col(pl.Date) - pl.col(\"Date\")).dt.total_days(),\n",
    "        pl.col(pl.Date).exclude(\"Date\").dt.weekday().prefix(\"weekdaydate_\"),\n",
    "        pl.col(pl.Date).exclude(\"Date\").dt.month().prefix(\"monthdate_\"),\n",
    "        pl.col(pl.Date).exclude(\"Date\").dt.week().prefix(\"weekdate_\")\n",
    "    )\n",
    "    .drop(\"Date\")\n",
    "    .with_columns(pl.col(pl.Boolean).cast(pl.UInt8))\n",
    "    .write_parquet(\"/home/sohail/test_df.parquet\")\n",
    ")\n",
    "\n",
    "joblib.dump((cat_cols,num_cols),\"/home/sohail/cols.pkl\")\n",
    "print(\"first scrip done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrpit start\n",
      "done: 1 for pastshallow\n",
      "done: 2 for pastdepth\n",
      "done: 3 for staticbase\n",
      "done: 4 for staticexternal\n",
      "done: 5 for personshallow\n",
      "done: 6 for persondepth\n",
      "done: 7 for othershallow\n",
      "done: 8 for depositshallow\n",
      "done: 9 for cardshallow\n",
      "done: 10 for intshallow\n",
      "done: 11 for intdepth\n",
      "done: 12 for extshallow\n",
      "done: 13 for extdepth\n",
      "done: 14 for rega\n",
      "done: 15 for regb\n",
      "done: 16 for regc\n",
      "first scrip done\n"
     ]
    }
   ],
   "source": [
    "!python data_file.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import joblib\n",
    "\n",
    "print(\"scrpit start\")\n",
    "\n",
    "cat_cols,num_cols = joblib.load(\"/home/sohail/cols.pkl\")\n",
    "\n",
    "train_df = (\n",
    "    pl.scan_parquet(\"/home/sohail/train_df.parquet\")\n",
    "    .select(pl.all().shrink_dtype())\n",
    ")\n",
    "\n",
    "num_cols +=  train_df.select(cs.contains([\"weekdaydate\",\"weekdate\",\"monthdate\"])).columns\n",
    "\n",
    "train_df = (\n",
    "    pl.read_parquet(\"/home/sohail/train_df.parquet\")\n",
    "    .select(pl.all().shrink_dtype())\n",
    "    .select(num_cols)\n",
    "    .to_pandas()\n",
    ")\n",
    "gc.collect()\n",
    "\n",
    "base_cols = [\"month\",\"weekday\",\"week\",\"year\"]\n",
    "\n",
    "print(\"Total columns in train:\",len(train_df.columns))\n",
    "\n",
    "cat_cols += base_cols\n",
    "\n",
    "print(f\"Total categorical columns: {len(cat_cols)} and Total numerical columns {len(num_cols)}\")\n",
    "\n",
    "nans_df = train_df.isna()\n",
    "nans_groups={}\n",
    "for col in num_cols:\n",
    "    cur_group = nans_df[col].sum()\n",
    "    try:\n",
    "        nans_groups[cur_group].append(col)\n",
    "    except:\n",
    "        nans_groups[cur_group]=[col]\n",
    "del nans_df; x=gc.collect()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "def reduce_grps(grps):\n",
    "    use = []\n",
    "    for g in grps:\n",
    "        mx = 0; vx = g[0]\n",
    "        for gg in g:\n",
    "            n = train_df[gg].nunique()\n",
    "            if n>mx:\n",
    "                mx = n\n",
    "                vx = gg\n",
    "        use.append(vx)\n",
    "    return use\n",
    "\n",
    "def group_col_by_corr(matrix,thresh=0.8):\n",
    "    correlation_matrix = matrix.corr()\n",
    "    groups = []\n",
    "    remaining_cols = list(matrix.columns)\n",
    "    while remaining_cols:\n",
    "        col = remaining_cols.pop(0)\n",
    "        group = [col]\n",
    "        correlated_cols = [col]\n",
    "        for c in remaining_cols:\n",
    "            if correlation_matrix.loc[col, c] >= thresh:\n",
    "                group.append(c)\n",
    "                correlated_cols.append(c)\n",
    "        groups.append(group)\n",
    "        remaining_cols = [c for c in remaining_cols if c not in correlated_cols]\n",
    "    \n",
    "    return groups\n",
    "\n",
    "uses=[]\n",
    "for k,v in nans_groups.items():\n",
    "    if len(v)>1:\n",
    "            Vs = nans_groups[k]\n",
    "            grps= group_col_by_corr(train_df[Vs], thresh=0.8)\n",
    "            use=reduce_grps(grps)\n",
    "            uses=uses+use\n",
    "    else:\n",
    "        uses=uses+v\n",
    "        \n",
    "print(\"Len of uses\",len(uses))\n",
    "print(\"Total cols\",len(cat_cols+uses))\n",
    "\n",
    "joblib.dump((cat_cols,uses),\"all_cols.pkl\")\n",
    "print(\"second script done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrpit start\n",
      "Total columns in train: 1771\n",
      "Total categorical columns: 344 and Total numerical columns 1771\n",
      "Len of uses 877\n",
      "Total cols 1221\n",
      "second script done\n"
     ]
    }
   ],
   "source": [
    "!python preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training.py\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import lightgbm as lgb\n",
    "import catboost as cgb\n",
    "import xgboost as xgb\n",
    "import joblib,gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "class_params = {\n",
    "    \"objective\":\"binary\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"metric\":\"auc\",\n",
    "    \"max_depth\": 128,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"n_estimators\": 5000,\n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"random_state\": 420,\n",
    "    \"reg_alpha\": 0.15,\n",
    "    \"reg_lambda\": 15,\n",
    "    \"extra_trees\": True,\n",
    "    \"num_leaves\": 256,\n",
    "    \"device\": \"gpu\",\n",
    "    \"importance_type\": \"gain\",\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"n_estimators\": 5000,\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"seed\": 420,\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"eta\": 0.01,\n",
    "    \"gamma\": 5,\n",
    "    \"max_depth\": 128,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"lambda\": 10,\n",
    "    \"alpha\": 2,\n",
    "    \"updater\": \"grow_gpu_hist\",\n",
    "    \"grow_policy\": \"depthwise\",\n",
    "    \"max_leaves\": 256,\n",
    "    \"num_parallel_tree\": 1, \n",
    "    \"enable_categorical\": True\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"task_type\": \"GPU\",\n",
    "    \"iterations\": 5000,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"bootstrap_type\": \"Poisson\",\n",
    "    \"random_seed\": 420,\n",
    "    \"l2_leaf_reg\": 15,\n",
    "    \"subsample\": 0.8,\n",
    "    \"depth\": 32,\n",
    "    \"max_leaves\": 64,\n",
    "    \"grow_policy\": \"Lossguide\",\n",
    "    \"od_type\": \"Iter\",\n",
    "    \"od_wait\": 1000,\n",
    "    \"verbose\": 500\n",
    "}\n",
    "\n",
    "all_cols = joblib.load(\"/home/sohail/all_cols.pkl\")\n",
    "\n",
    "total_df = (\n",
    "    pl.read_parquet(\"/home/sohail/train_df.parquet\")\n",
    "    .select(list(set(all_cols))+[\"target\",\"week_num\"])\n",
    "    .select(pl.all().shrink_dtype())\n",
    ")\n",
    "\n",
    "week_num = total_df[\"week_num\"]\n",
    "\n",
    "total_df = total_df.drop(\"week_num\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "def filter_ind(df:pl.DataFrame,indexes:np.array):\n",
    "    return (\n",
    "        df\n",
    "        .with_row_index()\n",
    "        .filter(\n",
    "            pl.col(\"index\").is_in(indexes)\n",
    "        )\n",
    "        .drop(\"index\")\n",
    "    )\n",
    "\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=5,shuffle=False)\n",
    "lgb_imp = pd.DataFrame(index=total_df.drop(\"target\").columns,columns=[\"gain_1\",\"gain_2\",\"gain_3\",\"gain_4\",\"gain_5\"])\n",
    "\n",
    "for i,(train_ind,valid_ind) in enumerate(\n",
    "    cv.split(total_df,total_df.select(\"target\"),\n",
    "    groups=week_num)):\n",
    "    print(f\"Training start for LGBClassifier: {i+1}\")\n",
    "    lgb_model = lgb.LGBMClassifier(**class_params)\n",
    "    lgb_model.fit(\n",
    "        (\n",
    "            total_df\n",
    "            .drop(\"target\")\n",
    "            .pipe(filter_ind,train_ind)\n",
    "        ),\n",
    "        (\n",
    "            total_df\n",
    "            .select('target')\n",
    "            .pipe(filter_ind,train_ind)\n",
    "            .to_series()\n",
    "            .to_numpy()\n",
    "            .ravel()\n",
    "        ),\n",
    "        eval_set=[(\n",
    "            (\n",
    "                total_df\n",
    "                .drop(\"target\")\n",
    "                .pipe(filter_ind,valid_ind)\n",
    "            ),\n",
    "            (\n",
    "                total_df\n",
    "                .select(\"target\")\n",
    "                .pipe(filter_ind,valid_ind)\n",
    "                .to_series()\n",
    "                .to_numpy()\n",
    "                .ravel()\n",
    "            )\n",
    "        )],\n",
    "        callbacks=[lgb.log_evaluation(500),lgb.early_stopping(800)]\n",
    "    )\n",
    "    for imp,col_name in sorted(zip(lgb_model.feature_importances_,total_df.drop(\"target\").columns)):\n",
    "        lgb_imp.loc[col_name,f\"gain_{i+1}\"] = imp\n",
    "    gc.collect()\n",
    "\n",
    "lgb_imp.reset_index(inplace=True)\n",
    "lgb_imp.to_parquet(\"/home/sohail/Downloads/lgb_imp.parquet\")\n",
    "\n",
    "del train_ind,valid_ind,lgb_model\n",
    "gc.collect()\n",
    "\n",
    "xgb_imp = pd.DataFrame(index=total_df.drop(\"target\").columns,columns=[\"gain_1\",\"gain_2\",\"gain_3\",\"gain_4\",\"gain_5\"])\n",
    "\n",
    "for i,(train_ind,valid_ind) in enumerate(\n",
    "    cv.split(total_df,total_df.select(\"target\"),\n",
    "    groups=week_num)):\n",
    "    print(f\"Training start for XGBClassifier: {i+1}\")\n",
    "    early_stop = xgb.callback.EarlyStopping(rounds=800)\n",
    "    log_eval = xgb.callback.EvaluationMonitor(period=500)\n",
    "    xgb_model = xgb.XGBClassifier(**xgb_params)\n",
    "    xgb_model.fit(\n",
    "        (\n",
    "            total_df\n",
    "            .drop(\"target\")\n",
    "            .pipe(filter_ind,train_ind)\n",
    "        ),\n",
    "        (\n",
    "            total_df\n",
    "            .select(\"target\")\n",
    "            .pipe(filter_ind,train_ind)\n",
    "        ),\n",
    "        eval_set=[(\n",
    "            (\n",
    "                total_df\n",
    "                .drop(\"target\")\n",
    "                .pipe(filter_ind,valid_ind)\n",
    "            ),\n",
    "            (\n",
    "                total_df\n",
    "                .select(\"target\")\n",
    "                .pipe(filter_ind,valid_ind)\n",
    "            )\n",
    "        )],\n",
    "        callbacks=[early_stop,log_eval],\n",
    "        verbose=False\n",
    "    )\n",
    "    for imp,col_name in sorted(zip(xgb_model.feature_importances_,total_df.drop(\"target\").columns)):\n",
    "        xgb_imp.loc[col_name,f\"gain_{i+1}\"] = imp\n",
    "    gc.collect()\n",
    "\n",
    "xgb_imp.reset_index(inplace=True)\n",
    "xgb_imp.to_parquet(\"/home/sohail/Downloads/xgb_imp.parquet\")\n",
    "\n",
    "del xgb_model,train_ind,valid_ind,log_eval,early_stop\n",
    "gc.collect()\n",
    "\n",
    "cat_imp = pd.DataFrame(index=total_df.drop(\"target\").columns,columns=[\"gain_1\",\"gain_2\",\"gain_3\",\"gain_4\",\"gain_5\"])\n",
    "\n",
    "for i,(train_ind,valid_ind) in enumerate(\n",
    "    cv.split(total_df,total_df.select(\"target\"),\n",
    "    groups=week_num)):\n",
    "    print(f\"Training start for CatBoostClassifier: {i+1}\")\n",
    "    cat_model = cgb.CatBoostClassifier(**cat_params)\n",
    "    cat_model.fit(\n",
    "        (\n",
    "            total_df\n",
    "            .drop(\"target\")\n",
    "            .pipe(filter_ind,train_ind)\n",
    "            .to_pandas()\n",
    "        ),\n",
    "        (\n",
    "            total_df\n",
    "            .select(\"target\")\n",
    "            .pipe(filter_ind,train_ind)\n",
    "            .to_pandas()\n",
    "        ),\n",
    "        eval_set=[(\n",
    "            (\n",
    "                total_df\n",
    "                .drop(\"target\")\n",
    "                .pipe(filter_ind,valid_ind)\n",
    "                .to_pandas()\n",
    "            ),\n",
    "            (\n",
    "                total_df\n",
    "                .select(\"target\")\n",
    "                .pipe(filter_ind,valid_ind)\n",
    "                .to_pandas()\n",
    "            )\n",
    "        )]\n",
    "    )\n",
    "    for imp,col_name in sorted(zip(cat_model.feature_importances_,total_df.drop(\"target\").columns)):\n",
    "        cat_imp.loc[col_name,f\"gain_{i+1}\"] = imp\n",
    "    gc.collect()\n",
    "\n",
    "cat_imp.reset_index(inplace=True)\n",
    "cat_imp.to_parquet(\"/home/sohail/Downloads/cat_imp.parquet\")\n",
    "\n",
    "del total_df,cat_model,train_ind,valid_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start for LGBClassifier: 1\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\tvalid_0's auc: 0.845261\n",
      "[1000]\tvalid_0's auc: 0.852373\n",
      "[1500]\tvalid_0's auc: 0.855071\n",
      "[2000]\tvalid_0's auc: 0.856423\n",
      "[2500]\tvalid_0's auc: 0.856905\n",
      "[3000]\tvalid_0's auc: 0.857144\n",
      "[3500]\tvalid_0's auc: 0.857201\n",
      "[4000]\tvalid_0's auc: 0.85722\n",
      "[4500]\tvalid_0's auc: 0.857178\n",
      "Early stopping, best iteration is:\n",
      "[4154]\tvalid_0's auc: 0.857262\n",
      "Training start for LGBClassifier: 2\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\tvalid_0's auc: 0.845697\n",
      "[1000]\tvalid_0's auc: 0.853049\n",
      "[1500]\tvalid_0's auc: 0.855598\n",
      "[2000]\tvalid_0's auc: 0.856855\n",
      "[2500]\tvalid_0's auc: 0.85757\n",
      "[3000]\tvalid_0's auc: 0.857845\n",
      "[3500]\tvalid_0's auc: 0.857978\n",
      "[4000]\tvalid_0's auc: 0.858011\n",
      "[4500]\tvalid_0's auc: 0.857947\n",
      "Early stopping, best iteration is:\n",
      "[4090]\tvalid_0's auc: 0.858029\n",
      "Training start for LGBClassifier: 3\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\tvalid_0's auc: 0.849591\n",
      "[1000]\tvalid_0's auc: 0.857308\n",
      "[1500]\tvalid_0's auc: 0.860191\n",
      "[2000]\tvalid_0's auc: 0.861436\n",
      "[2500]\tvalid_0's auc: 0.862023\n",
      "[3000]\tvalid_0's auc: 0.862353\n",
      "[3500]\tvalid_0's auc: 0.862494\n",
      "[4000]\tvalid_0's auc: 0.862512\n",
      "[4500]\tvalid_0's auc: 0.862383\n",
      "Early stopping, best iteration is:\n",
      "[3933]\tvalid_0's auc: 0.862544\n",
      "Training start for LGBClassifier: 4\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\tvalid_0's auc: 0.849607\n",
      "[1000]\tvalid_0's auc: 0.856805\n",
      "[1500]\tvalid_0's auc: 0.859463\n",
      "[2000]\tvalid_0's auc: 0.860832\n",
      "[2500]\tvalid_0's auc: 0.861375\n",
      "[3000]\tvalid_0's auc: 0.861642\n",
      "[3500]\tvalid_0's auc: 0.86186\n",
      "[4000]\tvalid_0's auc: 0.861901\n",
      "[4500]\tvalid_0's auc: 0.86187\n",
      "[5000]\tvalid_0's auc: 0.861813\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4225]\tvalid_0's auc: 0.861922\n",
      "Training start for LGBClassifier: 5\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\tvalid_0's auc: 0.845085\n",
      "[1000]\tvalid_0's auc: 0.852697\n",
      "[1500]\tvalid_0's auc: 0.855504\n",
      "[2000]\tvalid_0's auc: 0.856755\n",
      "[2500]\tvalid_0's auc: 0.857162\n",
      "[3000]\tvalid_0's auc: 0.857404\n",
      "[3500]\tvalid_0's auc: 0.857531\n",
      "[4000]\tvalid_0's auc: 0.857553\n",
      "[4500]\tvalid_0's auc: 0.857474\n",
      "Early stopping, best iteration is:\n",
      "[3862]\tvalid_0's auc: 0.857585\n",
      "Training start for XGBClassifier: 1\n",
      "/home/sohail/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/home/sohail/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:16:17] WARNING: /workspace/src/common/error_msg.cc:33: You have manually specified the `updater` parameter. The `tree_method` parameter will be ignored. Incorrect sequence of updaters will produce undefined behavior. For common uses, we recommend using `tree_method` parameter instead.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sohail/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:16:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"normalize_type\", \"rate_drop\", \"sample_type\", \"skip_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[0]\tvalidation_0-auc:0.75573\n",
      "[500]\tvalidation_0-auc:0.84360\n",
      "[1000]\tvalidation_0-auc:0.85388\n",
      "[1500]\tvalidation_0-auc:0.85668\n",
      "[2000]\tvalidation_0-auc:0.85668\n",
      "[2261]\tvalidation_0-auc:0.85668\n",
      "Training start for XGBClassifier: 2\n",
      "/home/sohail/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:25:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"normalize_type\", \"rate_drop\", \"sample_type\", \"skip_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[0]\tvalidation_0-auc:0.75132\n",
      "[500]\tvalidation_0-auc:0.84526\n",
      "[1000]\tvalidation_0-auc:0.85477\n",
      "[1500]\tvalidation_0-auc:0.85744\n",
      "[2000]\tvalidation_0-auc:0.85744\n",
      "[2344]\tvalidation_0-auc:0.85744\n",
      "Training start for XGBClassifier: 3\n",
      "/home/sohail/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:34:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"normalize_type\", \"rate_drop\", \"sample_type\", \"skip_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[0]\tvalidation_0-auc:0.76130\n",
      "[500]\tvalidation_0-auc:0.84904\n",
      "[1000]\tvalidation_0-auc:0.85909\n",
      "[1500]\tvalidation_0-auc:0.86212\n",
      "[2000]\tvalidation_0-auc:0.86212\n",
      "[2251]\tvalidation_0-auc:0.86212\n",
      "Training start for XGBClassifier: 4\n",
      "/home/sohail/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:43:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"normalize_type\", \"rate_drop\", \"sample_type\", \"skip_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[0]\tvalidation_0-auc:0.75446\n",
      "[500]\tvalidation_0-auc:0.84889\n",
      "[1000]\tvalidation_0-auc:0.85902\n",
      "[1500]\tvalidation_0-auc:0.86196\n",
      "[2000]\tvalidation_0-auc:0.86196\n",
      "[2278]\tvalidation_0-auc:0.86196\n",
      "Training start for XGBClassifier: 5\n",
      "/home/sohail/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:52:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"normalize_type\", \"rate_drop\", \"sample_type\", \"skip_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[0]\tvalidation_0-auc:0.75272\n",
      "[500]\tvalidation_0-auc:0.84383\n",
      "[1000]\tvalidation_0-auc:0.85476\n",
      "[1500]\tvalidation_0-auc:0.85782\n",
      "[2000]\tvalidation_0-auc:0.85782\n",
      "[2327]\tvalidation_0-auc:0.85782\n",
      "Training start for CatBoostClassifier: 1\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "0:\ttest: 0.7313202\tbest: 0.7313202 (0)\ttotal: 128ms\tremaining: 10m 41s\n",
      "500:\ttest: 0.8426534\tbest: 0.8426534 (500)\ttotal: 38.9s\tremaining: 5m 49s\n",
      "1000:\ttest: 0.8509791\tbest: 0.8509791 (1000)\ttotal: 1m 17s\tremaining: 5m 9s\n",
      "1500:\ttest: 0.8539145\tbest: 0.8539145 (1500)\ttotal: 1m 53s\tremaining: 4m 23s\n",
      "2000:\ttest: 0.8554156\tbest: 0.8554157 (1999)\ttotal: 2m 25s\tremaining: 3m 38s\n",
      "2500:\ttest: 0.8562751\tbest: 0.8562751 (2500)\ttotal: 2m 56s\tremaining: 2m 55s\n",
      "3000:\ttest: 0.8568718\tbest: 0.8568718 (3000)\ttotal: 3m 24s\tremaining: 2m 16s\n",
      "3500:\ttest: 0.8573717\tbest: 0.8573717 (3500)\ttotal: 3m 53s\tremaining: 1m 39s\n",
      "4000:\ttest: 0.8577931\tbest: 0.8577931 (4000)\ttotal: 4m 21s\tremaining: 1m 5s\n",
      "4500:\ttest: 0.8580931\tbest: 0.8580955 (4497)\ttotal: 4m 48s\tremaining: 32s\n",
      "4999:\ttest: 0.8583305\tbest: 0.8583305 (4999)\ttotal: 5m 15s\tremaining: 0us\n",
      "bestTest = 0.8583305478\n",
      "bestIteration = 4999\n",
      "Training start for CatBoostClassifier: 2\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "0:\ttest: 0.7325024\tbest: 0.7325024 (0)\ttotal: 64.9ms\tremaining: 5m 24s\n",
      "500:\ttest: 0.8431950\tbest: 0.8431950 (500)\ttotal: 39.2s\tremaining: 5m 52s\n",
      "1000:\ttest: 0.8512079\tbest: 0.8512079 (1000)\ttotal: 1m 17s\tremaining: 5m 10s\n",
      "1500:\ttest: 0.8543793\tbest: 0.8543793 (1500)\ttotal: 1m 53s\tremaining: 4m 25s\n",
      "2000:\ttest: 0.8558352\tbest: 0.8558352 (2000)\ttotal: 2m 26s\tremaining: 3m 39s\n",
      "2500:\ttest: 0.8567824\tbest: 0.8567824 (2500)\ttotal: 2m 57s\tremaining: 2m 57s\n",
      "3000:\ttest: 0.8573859\tbest: 0.8573894 (2996)\ttotal: 3m 27s\tremaining: 2m 18s\n",
      "3500:\ttest: 0.8578098\tbest: 0.8578120 (3499)\ttotal: 3m 56s\tremaining: 1m 41s\n",
      "4000:\ttest: 0.8581460\tbest: 0.8581465 (3996)\ttotal: 4m 24s\tremaining: 1m 6s\n",
      "4500:\ttest: 0.8584611\tbest: 0.8584611 (4500)\ttotal: 4m 53s\tremaining: 32.5s\n",
      "4999:\ttest: 0.8586741\tbest: 0.8586788 (4979)\ttotal: 5m 20s\tremaining: 0us\n",
      "bestTest = 0.8586788177\n",
      "bestIteration = 4979\n",
      "Shrink model to first 4980 iterations.\n",
      "Training start for CatBoostClassifier: 3\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "0:\ttest: 0.7342157\tbest: 0.7342157 (0)\ttotal: 66.8ms\tremaining: 5m 34s\n",
      "500:\ttest: 0.8478774\tbest: 0.8478774 (500)\ttotal: 39.6s\tremaining: 5m 55s\n",
      "1000:\ttest: 0.8562199\tbest: 0.8562199 (1000)\ttotal: 1m 18s\tremaining: 5m 12s\n",
      "1500:\ttest: 0.8592647\tbest: 0.8592647 (1500)\ttotal: 1m 54s\tremaining: 4m 26s\n",
      "2000:\ttest: 0.8608127\tbest: 0.8608127 (2000)\ttotal: 2m 27s\tremaining: 3m 40s\n",
      "2500:\ttest: 0.8617480\tbest: 0.8617480 (2500)\ttotal: 2m 57s\tremaining: 2m 57s\n",
      "3000:\ttest: 0.8623412\tbest: 0.8623412 (3000)\ttotal: 3m 27s\tremaining: 2m 18s\n",
      "3500:\ttest: 0.8628606\tbest: 0.8628606 (3500)\ttotal: 3m 56s\tremaining: 1m 41s\n",
      "4000:\ttest: 0.8632928\tbest: 0.8632928 (3999)\ttotal: 4m 24s\tremaining: 1m 6s\n",
      "4500:\ttest: 0.8636279\tbest: 0.8636315 (4488)\ttotal: 4m 52s\tremaining: 32.4s\n",
      "4999:\ttest: 0.8638501\tbest: 0.8638540 (4989)\ttotal: 5m 20s\tremaining: 0us\n",
      "bestTest = 0.863853991\n",
      "bestIteration = 4989\n",
      "Shrink model to first 4990 iterations.\n",
      "Training start for CatBoostClassifier: 4\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "0:\ttest: 0.7322249\tbest: 0.7322249 (0)\ttotal: 65.7ms\tremaining: 5m 28s\n",
      "500:\ttest: 0.8477597\tbest: 0.8477597 (500)\ttotal: 42.2s\tremaining: 6m 18s\n",
      "1000:\ttest: 0.8560598\tbest: 0.8560598 (1000)\ttotal: 1m 23s\tremaining: 5m 33s\n",
      "1500:\ttest: 0.8591487\tbest: 0.8591487 (1500)\ttotal: 2m 2s\tremaining: 4m 45s\n",
      "2000:\ttest: 0.8606687\tbest: 0.8606687 (2000)\ttotal: 2m 37s\tremaining: 3m 56s\n",
      "2500:\ttest: 0.8615605\tbest: 0.8615605 (2500)\ttotal: 3m 10s\tremaining: 3m 10s\n",
      "3000:\ttest: 0.8621016\tbest: 0.8621016 (3000)\ttotal: 3m 42s\tremaining: 2m 28s\n",
      "3500:\ttest: 0.8625536\tbest: 0.8625566 (3497)\ttotal: 4m 12s\tremaining: 1m 48s\n",
      "4000:\ttest: 0.8629200\tbest: 0.8629200 (4000)\ttotal: 4m 42s\tremaining: 1m 10s\n",
      "4500:\ttest: 0.8631988\tbest: 0.8631988 (4500)\ttotal: 5m 12s\tremaining: 34.7s\n",
      "4999:\ttest: 0.8634572\tbest: 0.8634589 (4996)\ttotal: 5m 41s\tremaining: 0us\n",
      "bestTest = 0.8634589314\n",
      "bestIteration = 4996\n",
      "Shrink model to first 4997 iterations.\n",
      "Training start for CatBoostClassifier: 5\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "0:\ttest: 0.7328492\tbest: 0.7328492 (0)\ttotal: 71.6ms\tremaining: 5m 58s\n",
      "500:\ttest: 0.8426307\tbest: 0.8426307 (500)\ttotal: 42.1s\tremaining: 6m 18s\n",
      "1000:\ttest: 0.8515626\tbest: 0.8515626 (1000)\ttotal: 1m 23s\tremaining: 5m 35s\n",
      "1500:\ttest: 0.8547552\tbest: 0.8547552 (1500)\ttotal: 2m 2s\tremaining: 4m 46s\n",
      "2000:\ttest: 0.8564004\tbest: 0.8564004 (2000)\ttotal: 2m 38s\tremaining: 3m 56s\n",
      "2500:\ttest: 0.8573785\tbest: 0.8573785 (2500)\ttotal: 3m 11s\tremaining: 3m 11s\n",
      "3000:\ttest: 0.8580202\tbest: 0.8580202 (3000)\ttotal: 3m 43s\tremaining: 2m 28s\n",
      "3500:\ttest: 0.8585982\tbest: 0.8585998 (3499)\ttotal: 4m 13s\tremaining: 1m 48s\n",
      "4000:\ttest: 0.8589346\tbest: 0.8589346 (4000)\ttotal: 4m 43s\tremaining: 1m 10s\n",
      "4500:\ttest: 0.8592331\tbest: 0.8592331 (4500)\ttotal: 5m 13s\tremaining: 34.7s\n",
      "4999:\ttest: 0.8595010\tbest: 0.8595010 (4999)\ttotal: 5m 42s\tremaining: 0us\n",
      "bestTest = 0.8595010042\n",
      "bestIteration = 4999\n"
     ]
    }
   ],
   "source": [
    "!python training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (439, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>mean</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;staticbase_last_lastrejectreas…</td><td>0.030428</td></tr><tr><td>&quot;pastshallow_last_childnum_21L&quot;</td><td>0.030514</td></tr><tr><td>&quot;pastshallow_last_credacc_credl…</td><td>0.030742</td></tr><tr><td>&quot;weekdaydate_intshallow_first_o…</td><td>0.03115</td></tr><tr><td>&quot;pastshallow_mean_credacc_minhi…</td><td>0.031466</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;intdepth_mean_pmts_dpd_303P&quot;</td><td>2.032641</td></tr><tr><td>&quot;pastshallow_mean_maxdpdtoleran…</td><td>2.228307</td></tr><tr><td>&quot;intdepth_mean_pmts_overdue_114…</td><td>2.242436</td></tr><tr><td>&quot;intdepth_mean_pmts_dpd_1073P&quot;</td><td>2.484635</td></tr><tr><td>&quot;staticbase_max_avgdpdtolclosur…</td><td>3.479774</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (439, 2)\n",
       "┌─────────────────────────────────┬──────────┐\n",
       "│ index                           ┆ mean     │\n",
       "│ ---                             ┆ ---      │\n",
       "│ str                             ┆ f64      │\n",
       "╞═════════════════════════════════╪══════════╡\n",
       "│ staticbase_last_lastrejectreas… ┆ 0.030428 │\n",
       "│ pastshallow_last_childnum_21L   ┆ 0.030514 │\n",
       "│ pastshallow_last_credacc_credl… ┆ 0.030742 │\n",
       "│ weekdaydate_intshallow_first_o… ┆ 0.03115  │\n",
       "│ pastshallow_mean_credacc_minhi… ┆ 0.031466 │\n",
       "│ …                               ┆ …        │\n",
       "│ intdepth_mean_pmts_dpd_303P     ┆ 2.032641 │\n",
       "│ pastshallow_mean_maxdpdtoleran… ┆ 2.228307 │\n",
       "│ intdepth_mean_pmts_overdue_114… ┆ 2.242436 │\n",
       "│ intdepth_mean_pmts_dpd_1073P    ┆ 2.484635 │\n",
       "│ staticbase_max_avgdpdtolclosur… ┆ 3.479774 │\n",
       "└─────────────────────────────────┴──────────┘"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "pl.read_parquet(\"/home/sohail/Downloads/cat_imp.parquet\").select(pl.col('index'),pl.mean_horizontal(pl.col(pl.NUMERIC_DTYPES)).alias(\"mean\")).sort(by=\"mean\").filter(pl.col(\"mean\") > 0.03)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
