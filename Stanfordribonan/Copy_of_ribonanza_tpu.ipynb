{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h4ck4l1/datasets/blob/main/Stanfordribonan/Copy_of_ribonanza_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEtUABBt4ed8",
        "outputId": "ada32299-3d8f-4249-e01d-f949da73ea45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os,sys,warnings,time\n",
        "from IPython.display import clear_output\n",
        "warnings.filterwarnings('ignore')\n",
        "os.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oqzT4mF7yot",
        "outputId": "553fe99f-3cf4-4fc4-859a-78b9504637d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "!gcloud config set project kaggle-406814"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hOHkSSICqgJJ"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "import numpy as np\n",
        "from typing import Literal\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.io as pio\n",
        "pio.templates.default = \"plotly_dark\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.sparse import to_dense\n",
        "from tensorflow.io import FixedLenFeature,VarLenFeature,parse_tensor,parse_single_example\n",
        "from tensorflow.data import TFRecordDataset\n",
        "from tensorflow import keras\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "import re,time,random,math\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cnoJ5NzvzpO",
        "outputId": "45e1d31b-fbe9-418f-d908-e18feee91a49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: Not connected to TPU runtime using CPU\n",
            "<tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy object at 0x7cd48af337f0>\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    tpu_cluster = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print(\"Running on TPU ADDR: \",tpu_cluster.cluster_spec().as_dict()['worker'][0])\n",
        "    tf.config.experimental_connect_to_cluster(tpu_cluster)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu_cluster)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu_cluster)\n",
        "    print(strategy)\n",
        "    print(strategy.num_replicas_in_sync)\n",
        "    tpu_present = True\n",
        "except ValueError:\n",
        "    print(\"Error: Not connected to TPU runtime using CPU\")\n",
        "    tpu_present = False\n",
        "\n",
        "if not tpu_present:\n",
        "    strategy = tf.distribute.OneDeviceStrategy(\"CPU\")\n",
        "    print(strategy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oMFKUVuVrVWR"
      },
      "outputs": [],
      "source": [
        "PATH = \"gs://stanfordrna/ribo/train_*.tfrecord\"\n",
        "total_files = tf.io.gfile.glob(PATH)\n",
        "train_files = total_files[:150]\n",
        "valid_files = total_files[150:160]\n",
        "test_files = total_files[160:]\n",
        "train_raw_ds = TFRecordDataset(train_files,compression_type=\"GZIP\",num_parallel_reads=tf.data.AUTOTUNE)\n",
        "valid_raw_ds = TFRecordDataset(valid_files,compression_type=\"GZIP\",num_parallel_reads=tf.data.AUTOTUNE)\n",
        "test_raw_ds = TFRecordDataset(test_files,compression_type=\"GZIP\",num_parallel_reads=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lz9J4pwZ7gx_"
      },
      "outputs": [],
      "source": [
        "rna_feature = dict(\n",
        "    seq_id = FixedLenFeature([],tf.string),\n",
        "    seq = VarLenFeature(tf.string),\n",
        "    dataset_name_2a3 = FixedLenFeature([],tf.string),\n",
        "    dataset_name_dms = FixedLenFeature([],tf.string),\n",
        "    reads_2a3 = FixedLenFeature([],tf.string),\n",
        "    reads_dms = FixedLenFeature([],tf.string),\n",
        "    signal_to_noise_2a3 = FixedLenFeature([],tf.string),\n",
        "    signal_to_noise_dms = FixedLenFeature([],tf.string),\n",
        "    reactivity_2a3 = VarLenFeature(tf.string),\n",
        "    reactivity_dms = VarLenFeature(tf.string),\n",
        "    reactivity_error_2a3 = VarLenFeature(tf.string),\n",
        "    reactivity_error_dms = VarLenFeature(tf.string),\n",
        "    sn_filter_2a3 = FixedLenFeature([],tf.string),\n",
        "    sn_filter_dms = FixedLenFeature([],tf.string),\n",
        "    length = FixedLenFeature([],tf.string),\n",
        "    bpp_matrix = VarLenFeature(tf.string),\n",
        "    bracket_seq = VarLenFeature(tf.string)\n",
        "    )\n",
        "\n",
        "def rna_example(example):\n",
        "    example = parse_single_example(example, rna_feature)\n",
        "\n",
        "    ### Dense Features\n",
        "    example[\"seq_id\"] = parse_tensor(example[\"seq_id\"], out_type=tf.string)\n",
        "    example[\"reads_2a3\"] = parse_tensor(example[\"reads_2a3\"], out_type=tf.float32)\n",
        "    example[\"reads_dms\"] = parse_tensor(example[\"reads_dms\"], out_type=tf.float32)\n",
        "    example[\"sn_filter_2a3\"] = parse_tensor(example[\"sn_filter_2a3\"], out_type=tf.float32)\n",
        "    example[\"sn_filter_dms\"] = parse_tensor(example[\"sn_filter_dms\"], out_type=tf.float32)\n",
        "    example[\"dataset_name_2a3\"] = parse_tensor(example[\"dataset_name_2a3\"], out_type=tf.string)\n",
        "    example[\"dataset_name_dms\"] = parse_tensor(example[\"dataset_name_dms\"], out_type=tf.string)\n",
        "    example[\"signal_to_noise_2a3\"] = parse_tensor(example[\"signal_to_noise_2a3\"], out_type=tf.float32)\n",
        "    example[\"signal_to_noise_dms\"] = parse_tensor(example[\"signal_to_noise_dms\"], out_type=tf.float32)\n",
        "    example[\"length\"] = parse_tensor(example[\"length\"], out_type=tf.float32)\n",
        "\n",
        "    ### Sparse Features\n",
        "    example[\"seq\"] = parse_tensor(to_dense(example[\"seq\"])[0], out_type=tf.float32)\n",
        "    example[\"reactivity_2a3\"] = parse_tensor(to_dense(example[\"reactivity_2a3\"])[0], out_type=tf.float32)\n",
        "    example[\"reactivity_dms\"] = parse_tensor(to_dense(example[\"reactivity_dms\"])[0], out_type=tf.float32)\n",
        "    example[\"reactivity_error_2a3\"] = parse_tensor(to_dense(example[\"reactivity_error_2a3\"])[0], out_type=tf.float32)\n",
        "    example[\"reactivity_error_dms\"] = parse_tensor(to_dense(example[\"reactivity_error_dms\"])[0], out_type=tf.float32)\n",
        "    example[\"bpp_matrix\"] = parse_tensor(to_dense(example[\"bpp_matrix\"])[0], out_type=tf.float32)\n",
        "    example[\"bracket_seq\"] = parse_tensor(to_dense(example[\"bracket_seq\"])[0], out_type=tf.float32)\n",
        "\n",
        "    return example\n",
        "\n",
        "train_modified_ds = train_raw_ds.map(rna_example,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "valid_modified_ds = valid_raw_ds.map(rna_example,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_modified_ds = test_raw_ds.map(rna_example,num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gCRgHPC098EQ",
        "outputId": "2d2ab597-c1af-4c7e-ef8d-ddc7329b9fa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id  :  b'8cdfeef009ea'\n",
            "\n",
            "\n",
            "\n",
            "seq  :  [3. 3. 3. 0. 0. 2. 3. 0. 2. 4. 2. 3. 0. 3. 4. 0. 3. 0. 3. 4.]\n",
            "seq shape : (170,)\n",
            "\n",
            "\n",
            "\n",
            "dataset_name_2a3  :  b'15k_2A3'\n",
            "\n",
            "\n",
            "\n",
            "dataset_name_dms  :  b'15k_DMS'\n",
            "\n",
            "\n",
            "\n",
            "reads_2a3 :  2343.0\n",
            "\n",
            "\n",
            "\n",
            "reads_dms :  1668.0\n",
            "\n",
            "\n",
            "\n",
            "signal_to_noise_2a3 :  0.944\n",
            "\n",
            "\n",
            "\n",
            "signal_to_noise_dms :  0.972\n",
            "\n",
            "\n",
            "\n",
            "reactivity_2a3  :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "shape of reactivity_2a3 : (206,)\n",
            "\n",
            "\n",
            "\n",
            "reactivity_dms  :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "shape of reactivity_dms : (206,)\n",
            "\n",
            "\n",
            "\n",
            "reactivity_error_2a3 :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "shape of reactivity_error_2a3 (206,)\n",
            "\n",
            "\n",
            "\n",
            "reactivity_error_dms :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "shape of reactivity_error_dms (206,)\n",
            "\n",
            "\n",
            "\n",
            "sn_filter_2a3 :  0.0\n",
            "\n",
            "\n",
            "\n",
            "sn_filter_dms :  0.0\n",
            "\n",
            "\n",
            "\n",
            "Lenght : 170.0\n",
            "\n",
            "\n",
            "\n",
            "bpp_matrix : [[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "bpp_matrix shape : (170, 170)\n",
            "\n",
            "\n",
            "\n",
            "bracket_sequence : [8. 8. 8. 8. 8. 0. 0. 0. 0. 0. 0. 8. 8. 8. 8. 8. 1. 1. 1. 1.]\n",
            "bracket_sequence shape : (170,)\n"
          ]
        }
      ],
      "source": [
        "single_example = train_modified_ds.take(1).get_single_element()\n",
        "print(\"id\",\" : \",single_example[\"seq_id\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"seq\",\" : \",single_example[\"seq\"].numpy()[:20])\n",
        "print(\"seq shape :\",single_example[\"seq\"].numpy().shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"dataset_name_2a3\",\" : \",single_example[\"dataset_name_2a3\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"dataset_name_dms\",\" : \",single_example[\"dataset_name_dms\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"reads_2a3\",\": \",single_example[\"reads_2a3\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"reads_dms\",\": \",single_example[\"reads_dms\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"signal_to_noise_2a3\",\": \",single_example[\"signal_to_noise_2a3\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"signal_to_noise_dms\",\": \",single_example[\"signal_to_noise_dms\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"reactivity_2a3\",\" : \",single_example[\"reactivity_2a3\"].numpy()[:20])\n",
        "print(\"shape of reactivity_2a3 :\",single_example[\"reactivity_2a3\"].shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"reactivity_dms\",\" : \",single_example[\"reactivity_dms\"].numpy()[:20])\n",
        "print(\"shape of reactivity_dms :\",single_example[\"reactivity_dms\"].shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"reactivity_error_2a3\",\": \",single_example[\"reactivity_error_2a3\"].numpy()[:20])\n",
        "print(\"shape of reactivity_error_2a3\",single_example[\"reactivity_error_2a3\"].shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"reactivity_error_dms\",\": \",single_example[\"reactivity_error_dms\"].numpy()[:20])\n",
        "print(\"shape of reactivity_error_dms\",single_example[\"reactivity_error_dms\"].shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"sn_filter_2a3\",\": \",single_example[\"sn_filter_2a3\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"sn_filter_dms\",\": \",single_example[\"sn_filter_dms\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"Lenght :\",single_example[\"length\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"bpp_matrix :\",single_example[\"bpp_matrix\"].numpy()[:5,:5])\n",
        "print(\"bpp_matrix shape :\",single_example[\"bpp_matrix\"].numpy().shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"bracket_sequence :\",single_example[\"bracket_seq\"].numpy()[:20])\n",
        "print('bracket_sequence shape :',single_example[\"bracket_seq\"].numpy().shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EivynxKT2u-5"
      },
      "source": [
        "# The\n",
        "\n",
        "## Total number of rows in each dataset is: 821840\n",
        "\n",
        "### Total number of tfrecord files: 164\n",
        "\n",
        "### Total nunber of instances per file: 5005\n",
        "\n",
        "### Total number of steps per epoch: 6420\n",
        "\n",
        "### Total number of steps per epoch for 3 test files: 117\n",
        "\n",
        "\n",
        "\n",
        "## Example sizes of the input sequences\n",
        "- [170, 177, 115, 155, 206]\n",
        "- minimum of reactivity columns : -129.281\n",
        "- maximum of reactivity columns :  129.281\n",
        "- positions upto 26 and from 126 are all nans can be padded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "LcbxuzwBBkmA"
      },
      "outputs": [],
      "source": [
        "K = keras.backend\n",
        "seq_map = {\"A\":1,\"C\":2,\"G\":3,\"U\":4,\"START\":4,\"END\":5,\"EMPTY\":0}\n",
        "bracket_map = {\"(\":1,\")\":2,\"[\":3,\"]\":4,\"{\":5,\"}\":6,\"<\":7,\">\":8,\".\":9,\"START\":10,\"END\":11,\"EMPTY\":0}\n",
        "\n",
        "def convert_and_pad(ex,Lmax:int=206,shift=True,sn_filter:bool=False):\n",
        "\n",
        "    l = tf.shape(ex[\"seq\"],tf.int32)[0]\n",
        "\n",
        "    if not shift:\n",
        "        shift = 0\n",
        "    else:\n",
        "        shift = tf.random.uniform(shape=[1],minval=0,maxval=Lmax-l+1,dtype=tf.int32)[0]\n",
        "\n",
        "    # Sequence Processing and Mask Processing\n",
        "    seq = ex[\"seq\"] + 1\n",
        "    seq = tf.pad(seq,[[1,0]],constant_values=seq_map[\"START\"])                               # seq_map[\"START\"]\n",
        "    seq = tf.pad(seq,[[0,1]],constant_values=seq_map[\"END\"])                                 # seq_map[\"END\"]\n",
        "    seq = tf.pad(seq,[[shift,Lmax-l-shift]])                                                 # seq_map[\"EMPTY\"]\n",
        "\n",
        "\n",
        "    # Bracket Processing\n",
        "    brac = ex[\"bracket_seq\"] + 1\n",
        "    brac = tf.pad(brac,[[1,0]],constant_values=bracket_map[\"START\"])                            # bracket_map[\"START\"]\n",
        "    brac = tf.pad(brac,[[0,1]],constant_values=bracket_map[\"END\"])                              # bracket_map[\"END\"]\n",
        "    brac = tf.pad(brac,[[shift,Lmax-l-shift]],constant_values=bracket_map[\"EMPTY\"])             # bracket_map[\"EMPTY\"]\n",
        "\n",
        "    # Reactivity Processing\n",
        "    reac = tf.stack([ex[\"reactivity_2a3\"][:l],ex[\"reactivity_dms\"][:l]],axis=-1)\n",
        "    reac = tf.pad(reac,[[shift+1,Lmax+1-l-shift],[0,0]],constant_values=np.nan)\n",
        "\n",
        "#     # SN_filter\n",
        "#     sn = (ex[\"sn_filter_2a3\"] > 0) & (ex[\"sn_filter_dms\"] > 0)\n",
        "\n",
        "    # BPPMatrix\n",
        "    bppm = ex[\"bpp_matrix\"][:l,:l]\n",
        "    bppm = tf.pad(bppm,[[shift+1,Lmax+1-l-shift],[shift+1,Lmax+1-l-shift]])\n",
        "\n",
        "    return (seq,brac,bppm),reac\n",
        "\n",
        "\n",
        "BATCH_SIZE = strategy.num_replicas_in_sync * 16 if tpu_present else 32\n",
        "\n",
        "\n",
        "def shape_set(X,y):\n",
        "    (seq,brac,bpp),reac = X,y\n",
        "    seq.set_shape([BATCH_SIZE,208])\n",
        "    brac.set_shape([BATCH_SIZE,208])\n",
        "    bpp.set_shape([BATCH_SIZE,208,208])\n",
        "    reac.set_shape([BATCH_SIZE,208,2])\n",
        "    return (seq,brac,bpp),reac\n",
        "\n",
        "\n",
        "def create_train_ds(dataset,batch_size:int=BATCH_SIZE):\n",
        "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.shuffle(20000)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch_size,drop_remainder=True,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(shape_set,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "def create_val_ds(dataset,batch_size:int=BATCH_SIZE):\n",
        "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size,drop_remainder=True,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(shape_set,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.cache()\n",
        "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "def create_test_ds(dataset,batch_size:int=BATCH_SIZE):\n",
        "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size,drop_remainder=True,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(shape_set,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "train_ds = create_train_ds(train_modified_ds,batch_size=BATCH_SIZE)\n",
        "valid_ds = create_val_ds(valid_modified_ds,batch_size=BATCH_SIZE)\n",
        "test_ds = create_test_ds(test_modified_ds,batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_of_files_currently_used = 2\n",
        "num_instances = 821840\n",
        "num_train_files = len(train_files)\n",
        "num_test_files = len(test_files)\n",
        "num_valid_files = len(valid_files)\n",
        "num_total_files = len(total_files)\n",
        "num_train_instances = (num_instances*num_train_files)//(164)\n",
        "num_valid_instances = (num_instances*num_valid_files)//(164)\n",
        "num_test_instances = (num_instances*num_test_files)//(164)\n",
        "num_instances_per_file = (num_instances)//(num_total_files)\n",
        "steps_per_epoch = num_train_instances//BATCH_SIZE\n",
        "test_steps_per_epoch = (num_instances * num_of_files_currently_used)//(164*BATCH_SIZE)\n",
        "validation_steps = num_valid_instances//BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "i07L32EZcp1m"
      },
      "outputs": [],
      "source": [
        "X,y = train_ds.take(1).get_single_element()\n",
        "seq_input = X[0]\n",
        "bracket_input = X[1]\n",
        "bpp_matrix = X[2]\n",
        "reactivity = y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOA9vxnhT81c",
        "outputId": "d5fd5c45-d75a-43cf-ba4e-30dceee5152e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequence input shape:  (32, 208)\n",
            "bracket input : (32, 208)\n",
            "bpp matrix shape : (32, 208, 208)\n",
            "reactivity shape : (32, 208, 2)\n"
          ]
        }
      ],
      "source": [
        "print(\"sequence input shape: \",seq_input.shape)\n",
        "print(\"bracket input :\",bracket_input.shape)\n",
        "print(\"bpp matrix shape :\",bpp_matrix.shape)\n",
        "print(\"reactivity shape :\",reactivity.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBWE_XTVZgS-"
      },
      "source": [
        "# Model Trying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "39rw0-NCYHas"
      },
      "outputs": [],
      "source": [
        "class StaticPosEncoding(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "            vocab_size:int,\n",
        "            d_model,\n",
        "            length,\n",
        "            **kwargs):\n",
        "\n",
        "        super(StaticPosEncoding,self).__init__(**kwargs)\n",
        "\n",
        "        assert d_model%2 == 0,\"Depth of model(d_model) should be even\"\n",
        "\n",
        "        d_model = d_model//2\n",
        "        positions = np.arange(length)[:,np.newaxis]\n",
        "        angles = np.arange(d_model)[np.newaxis,:]/d_model\n",
        "        angles = 1/(10000**angles)\n",
        "        angle_rads = positions * angles\n",
        "        encode = tf.concat([tf.sin(angle_rads),tf.cos(angle_rads)],axis=-1)\n",
        "        self.encode = tf.cast(encode,tf.float32)\n",
        "        self.factor = tf.sqrt(tf.cast(d_model,tf.float32))\n",
        "        self.embedding_layer = keras.layers.Embedding(vocab_size,d_model*2,mask_zero=True)\n",
        "\n",
        "    def compute_mask(self, *args,**kwargs):\n",
        "        return self.embedding_layer.compute_mask(*args,**kwargs)\n",
        "\n",
        "    def call(self,x):\n",
        "        seq_l = tf.shape(x)[1]\n",
        "        x = self.embedding_layer(x)\n",
        "        x *= self.factor\n",
        "        return x + self.encode[tf.newaxis,:seq_l,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YC_ZebEpdVdx",
        "outputId": "f7e0e3be-b0ea-4d03-b96b-248621356b41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 208, 512])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_encode = StaticPosEncoding(vocab_size=len(seq_map),d_model=512,length=2048)\n",
        "pos_encode_output = pos_encode(X[0])\n",
        "pos_encode_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vNycXdf9d2kZ"
      },
      "outputs": [],
      "source": [
        "class ConvolutionLayer(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 n_filters,\n",
        "                 ksize,\n",
        "                 drop_rate,\n",
        "                 **kwargs):\n",
        "        super(ConvolutionLayer,self).__init__(**kwargs)\n",
        "        self.conv_layers = [keras.layers.Conv2D(filters=n_filters,kernel_size=ksize,padding=\"same\",use_bias=False,activation=\"relu\") for _ in range(n_layers)]\n",
        "        self.perm = keras.layers.Permute(dims=[3,1,2])\n",
        "        self.norm = keras.layers.LayerNormalization()\n",
        "        self.drop = keras.layers.Dropout(drop_rate)\n",
        "\n",
        "    def call(self,x):\n",
        "        x = tf.expand_dims(x,axis=-1)\n",
        "        for layer in self.conv_layers:\n",
        "            x = layer(x)\n",
        "        x = self.perm(x)\n",
        "        return self.norm(self.drop(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86WwctnN-zfh",
        "outputId": "2e8ecd11-4181-41a7-9b58-099c02f66a67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 6, 208, 208])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conv = ConvolutionLayer(n_layers=3,n_filters=6,ksize=3,drop_rate=0.1)\n",
        "bpp_conv_ouput = conv(bpp_matrix)\n",
        "bpp_conv_ouput.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "P2ppV-pW3yBb"
      },
      "outputs": [],
      "source": [
        "class ConvolutedAttention(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "            num_heads,\n",
        "            key_dim,\n",
        "            **kwargs):\n",
        "\n",
        "        super(ConvolutedAttention,self).__init__(**kwargs)\n",
        "        self.num_heads = num_heads\n",
        "        self.key_dim = key_dim\n",
        "        self.wq = keras.layers.Dense(num_heads*key_dim)\n",
        "        self.wv = keras.layers.Dense(num_heads*key_dim)\n",
        "        self.wk = keras.layers.Dense(num_heads*key_dim)\n",
        "        self.dense = keras.layers.Dense(key_dim)\n",
        "        self.first_drop = keras.layers.Dropout(0.1)\n",
        "        self.last_drop = keras.layers.Dropout(0.1)\n",
        "        self.layer_norm = keras.layers.LayerNormalization()\n",
        "        self.factor = tf.math.rsqrt(tf.constant(key_dim,tf.float32))\n",
        "        self.softmax = keras.layers.Softmax()\n",
        "        self.add = keras.layers.Add()\n",
        "\n",
        "\n",
        "    def call(self,query,key,value,convoluted=None,return_attention_scores=False,mask=None):\n",
        "\n",
        "\n",
        "        batch_size = tf.shape(query)[0]\n",
        "        seq_len = tf.shape(query)[1]\n",
        "        q = self.wq(query)\n",
        "        k = self.wk(key)\n",
        "        v = self.wv(value)\n",
        "\n",
        "        q = tf.transpose(tf.reshape(q,shape=[batch_size,-1,self.num_heads,self.key_dim]),perm=[0,2,1,3])\n",
        "        k = tf.transpose(tf.reshape(k,shape=[batch_size,-1,self.num_heads,self.key_dim]),perm=[0,2,1,3])\n",
        "        v = tf.transpose(tf.reshape(v,shape=[batch_size,-1,self.num_heads,self.key_dim]),perm=[0,2,1,3])\n",
        "\n",
        "        attention_score = self.factor * tf.matmul(q,k,transpose_b=True)\n",
        "        attention_score = self.first_drop(self.softmax(attention_score + convoluted))\n",
        "\n",
        "        attention_out = tf.reshape(tf.transpose(tf.matmul(attention_score,v),perm=[0,2,1,3]),shape=[batch_size,seq_len,-1])\n",
        "        attention_out = self.last_drop(self.dense(attention_out))\n",
        "        attention_out = self.layer_norm(self.add([attention_out,query]))\n",
        "\n",
        "        if return_attention_scores:\n",
        "            return attention_out,attention_score\n",
        "        return attention_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlheKwBbOGD2",
        "outputId": "32345172-95b0-4b53-9d4c-bfda83650a50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 208, 512])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conv_attn = ConvolutedAttention(num_heads=6,key_dim=512)\n",
        "conv_attn_out = conv_attn(query=pos_encode_output,key=pos_encode_output,value=pos_encode_output,convoluted=bpp_conv_ouput)\n",
        "conv_attn_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MY8BoKHMhDsf"
      },
      "outputs": [],
      "source": [
        "class FeedForward(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "            feed_out_unit,\n",
        "            feed_forward,\n",
        "            feed_forward_drop,\n",
        "            **kwargs):\n",
        "\n",
        "        super(FeedForward,self).__init__(**kwargs)\n",
        "        self.dense_out = keras.layers.Dense(feed_out_unit)\n",
        "        self.feed_forward = keras.layers.Dense(feed_forward)\n",
        "        self.feed_forward_drop = keras.layers.Dropout(feed_forward_drop)\n",
        "        self.norm = keras.layers.LayerNormalization()\n",
        "        self.add = keras.layers.Add()\n",
        "\n",
        "    def call(self,x):\n",
        "\n",
        "        x_copy = x\n",
        "        x = self.feed_forward(x)\n",
        "        x = self.dense_out(x)\n",
        "        x = self.feed_forward_drop(x)\n",
        "        x = self.feed_forward_drop(x)\n",
        "        return self.norm(self.add([x_copy,x]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjL8klRpCCSo",
        "outputId": "427f9aa6-37da-4b84-bd95-73376c48b00c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 208, 512])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feed_forward = FeedForward(feed_out_unit=512,feed_forward=2048,feed_forward_drop=0.2)\n",
        "feed_out = feed_forward(conv_attn_out)\n",
        "feed_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Qil3FWxpCFoo"
      },
      "outputs": [],
      "source": [
        "class SequenceEncoderUint(keras.models.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "            encoder_convolution_layers:int,\n",
        "            encoder_convolution_ksize:int,\n",
        "            encoder_convolution_drop_rate:float,\n",
        "            encoder_convolution_num_heads:int,\n",
        "            encoder_cross_attention_num_heads:int,\n",
        "            encoder_key_dim:int,\n",
        "            encoder_feed_out_units:int,\n",
        "            encoder_feed_forward_units:int,\n",
        "            encoder_feed_forward_drop_rate:float,\n",
        "            **kwargs):\n",
        "\n",
        "        super(SequenceEncoderUint,self).__init__(**kwargs)\n",
        "\n",
        "        self.convolution_layer = ConvolutionLayer(\n",
        "            encoder_convolution_layers,\n",
        "            encoder_convolution_num_heads,\n",
        "            encoder_convolution_ksize,\n",
        "            encoder_convolution_drop_rate\n",
        "            )\n",
        "\n",
        "        self.convoluted_attention = ConvolutedAttention(\n",
        "            encoder_convolution_num_heads,\n",
        "            encoder_key_dim\n",
        "            )\n",
        "\n",
        "        self.encoder_cross_attention = keras.layers.MultiHeadAttention(\n",
        "            num_heads=encoder_cross_attention_num_heads,\n",
        "            key_dim=encoder_key_dim\n",
        "            )\n",
        "\n",
        "        self.feed_forward = FeedForward(\n",
        "            encoder_feed_out_units,\n",
        "            encoder_feed_forward_units,\n",
        "            encoder_feed_forward_drop_rate\n",
        "            )\n",
        "\n",
        "    def call(self,sequence_encode_out,bpp_matrix,bracket_encode_out):\n",
        "\n",
        "        convolution_out = self.convolution_layer(bpp_matrix)\n",
        "        convolutedattention_out = self.convoluted_attention(\n",
        "            query=sequence_encode_out,\n",
        "            key=sequence_encode_out,\n",
        "            value=sequence_encode_out,\n",
        "            convoluted=convolution_out\n",
        "            )\n",
        "        crossattention_out = self.encoder_cross_attention(\n",
        "            query=convolutedattention_out,\n",
        "            key=bracket_encode_out,\n",
        "            value=bracket_encode_out\n",
        "            )\n",
        "        feed_out = self.feed_forward(crossattention_out)\n",
        "\n",
        "        return feed_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwN72GFKO_4i",
        "outputId": "5ddaf7c6-1c4e-4c76-dcd8-5ba35d9a7993"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 208, 512])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seq_encoder = SequenceEncoderUint(\n",
        "    encoder_convolution_layers=3,\n",
        "    encoder_convolution_ksize=3,\n",
        "    encoder_convolution_drop_rate=0.1,\n",
        "    encoder_convolution_num_heads=6,\n",
        "    encoder_cross_attention_num_heads=6,\n",
        "    encoder_key_dim=512,\n",
        "    encoder_feed_forward_drop_rate=0.1,\n",
        "    encoder_feed_forward_units=2048,\n",
        "    encoder_feed_out_units=512\n",
        "    )\n",
        "\n",
        "seq_encode_out = tf.random.uniform(shape=[32,208,512])\n",
        "bpp_mat =  tf.random.uniform(shape=[32,208,208])\n",
        "bracket_sequence_out = tf.random.uniform(shape=[32,208,512])\n",
        "seq_encoder_out = seq_encoder(seq_encode_out,bpp_mat,bracket_sequence_out)\n",
        "seq_encoder_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ncHhhexQmVSz"
      },
      "outputs": [],
      "source": [
        "class BracketEncoderUnit(keras.models.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "            encoder_convolution_layers:int,\n",
        "            encoder_convolution_ksize:int,\n",
        "            encoder_convolution_drop_rate:float,\n",
        "            encoder_convolution_num_heads:int,\n",
        "            encoder_key_dim:int,\n",
        "            encoder_feed_out_units:int,\n",
        "            encoder_feed_forward_units:int,\n",
        "            encoder_feed_forward_drop_rate:float,\n",
        "            **kwargs):\n",
        "\n",
        "\n",
        "        super(BracketEncoderUnit,self).__init__(**kwargs)\n",
        "\n",
        "        self.convolution_layer = ConvolutionLayer(\n",
        "            encoder_convolution_layers,\n",
        "            encoder_convolution_num_heads,\n",
        "            encoder_convolution_ksize,\n",
        "            encoder_convolution_drop_rate,\n",
        "        )\n",
        "\n",
        "        self.convoluted_attention = ConvolutedAttention(\n",
        "            encoder_convolution_num_heads,\n",
        "            encoder_key_dim\n",
        "        )\n",
        "\n",
        "        self.feed_forward = FeedForward(\n",
        "            encoder_feed_out_units,\n",
        "            encoder_feed_forward_units,\n",
        "            encoder_feed_forward_drop_rate\n",
        "        )\n",
        "\n",
        "    def call(self,bracket_encode_out,bpp_matrix):\n",
        "\n",
        "        convolution_out = self.convolution_layer(bpp_matrix)\n",
        "        convoluted_attention_out = self.convoluted_attention(\n",
        "            query = bracket_encode_out,\n",
        "            key = bracket_encode_out,\n",
        "            value = bracket_encode_out,\n",
        "            convoluted = convolution_out\n",
        "        )\n",
        "        feed_out = self.feed_forward(convoluted_attention_out)\n",
        "\n",
        "        return feed_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iCnf1z1mZf0",
        "outputId": "b2429b4b-de37-4029-cf84-460c0bb7943b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 208, 512])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bracket_seq_encoder = BracketEncoderUnit(\n",
        "    encoder_convolution_layers=3,\n",
        "    encoder_convolution_ksize=3,\n",
        "    encoder_convolution_drop_rate=0.1,\n",
        "    encoder_convolution_num_heads=6,\n",
        "    encoder_key_dim=512,\n",
        "    encoder_feed_forward_drop_rate=0.1,\n",
        "    encoder_feed_forward_units=2048,\n",
        "    encoder_feed_out_units=512\n",
        ")\n",
        "\n",
        "bracket_encode_out = tf.random.uniform(shape=[32,208,512])\n",
        "bpp_mat = tf.random.uniform(shape=[32,208,208])\n",
        "bracket_seq_encoder_out = bracket_seq_encoder(bracket_encode_out,bpp_mat)\n",
        "bracket_seq_encoder_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "m3V6dWFmmcP9"
      },
      "outputs": [],
      "source": [
        "class Transformer(keras.models.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "\n",
        "            # Seuqence encoder arguments\n",
        "\n",
        "            sequence_encoder_vocab_size:int=len(seq_map),\n",
        "            sequence_encoder_d_model:int=256,\n",
        "            sequence_encoder_length:int=2048,\n",
        "            sequence_encoder_num_layers:int=4,\n",
        "            sequence_encoder_convolution_layers:int=3,\n",
        "            sequence_encoder_convolution_ksize:int=3,\n",
        "            sequence_encoder_convolution_drop_rate:float=0.1,\n",
        "            sequence_encoder_convolution_num_heads:int=4,\n",
        "            sequence_encoder_cross_attention_num_heads:int=4,\n",
        "            sequence_encoder_key_dim:int=256,\n",
        "            sequence_encoder_feed_out_units:int=256,\n",
        "            sequence_encoder_feed_forward_units:int=1024,\n",
        "            sequence_encoder_feed_forward_drop_rate:float=0.1,\n",
        "\n",
        "            # Bracket Sequence Encoder arguments\n",
        "\n",
        "            bracket_sequence_encoder_vocab_size:int=len(bracket_map),\n",
        "            bracket_sequence_encoder_d_model:int=256,\n",
        "            bracket_sequence_encoder_length:int=2048,\n",
        "            bracket_sequence_encoder_num_layers:int=6,\n",
        "            bracket_sequence_encoder_convolution_layers:int=3,\n",
        "            bracket_sequence_encoder_convolution_ksize:int=3,\n",
        "            bracket_sequence_encoder_convolution_drop_rate:float=0.1,\n",
        "            bracket_sequence_encoder_num_heads:int=4,\n",
        "            bracket_sequence_encoder_key_dim:int=256,\n",
        "            bracket_sequence_encoder_feed_out_units:int=256,\n",
        "            bracket_sequence_encoder_feed_forward_units:int=1024,\n",
        "            bracket_sequence_encoder_feed_forward_drop_rate:float=0.1,\n",
        "\n",
        "            # Out Dense\n",
        "            total_out_units = 2,\n",
        "            **kwargs):\n",
        "\n",
        "\n",
        "        super(Transformer,self).__init__(**kwargs)\n",
        "\n",
        "        self.sequence_pos_encoder = StaticPosEncoding(\n",
        "            sequence_encoder_vocab_size,\n",
        "            sequence_encoder_d_model,\n",
        "            sequence_encoder_length,\n",
        "        )\n",
        "\n",
        "        self.bracket_sequence_pos_encoder = StaticPosEncoding(\n",
        "            bracket_sequence_encoder_vocab_size,\n",
        "            bracket_sequence_encoder_d_model,\n",
        "            bracket_sequence_encoder_length,\n",
        "        )\n",
        "\n",
        "        self.sequence_encoder_units_list = [SequenceEncoderUint(\n",
        "            sequence_encoder_convolution_layers,\n",
        "            sequence_encoder_convolution_ksize,\n",
        "            sequence_encoder_convolution_drop_rate,\n",
        "            sequence_encoder_convolution_num_heads,\n",
        "            sequence_encoder_cross_attention_num_heads,\n",
        "            sequence_encoder_key_dim,\n",
        "            sequence_encoder_feed_out_units,\n",
        "            sequence_encoder_feed_forward_units,\n",
        "            sequence_encoder_feed_forward_drop_rate\n",
        "        ) for _ in range(sequence_encoder_num_layers)]\n",
        "\n",
        "        self.bracket_sequence_encoder_units_list = [BracketEncoderUnit(\n",
        "            bracket_sequence_encoder_convolution_layers,\n",
        "            bracket_sequence_encoder_convolution_ksize,\n",
        "            bracket_sequence_encoder_convolution_drop_rate,\n",
        "            bracket_sequence_encoder_num_heads,\n",
        "            bracket_sequence_encoder_key_dim,\n",
        "            bracket_sequence_encoder_feed_out_units,\n",
        "            bracket_sequence_encoder_feed_forward_units,\n",
        "            bracket_sequence_encoder_feed_forward_drop_rate\n",
        "        ) for _ in range(bracket_sequence_encoder_num_layers)]\n",
        "\n",
        "        self.total_out = keras.layers.Dense(total_out_units,activation=None)\n",
        "\n",
        "\n",
        "    def call(self,X):\n",
        "\n",
        "        sequence,bracket_sequence,bpp_matrix = X\n",
        "        out = self.bracket_sequence_pos_encoder(bracket_sequence)\n",
        "\n",
        "        for layer in self.bracket_sequence_encoder_units_list:\n",
        "            out = layer(out,bpp_matrix)\n",
        "\n",
        "        seq_out = self.sequence_pos_encoder(sequence)\n",
        "\n",
        "        for layer in self.sequence_encoder_units_list:\n",
        "            seq_out = layer(seq_out,bpp_matrix,out)\n",
        "\n",
        "\n",
        "        seq_out = self.total_out(seq_out)\n",
        "\n",
        "        try:\n",
        "            del seq_out._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        return seq_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SJRkz3IItJG",
        "outputId": "d165fd7e-fcf3-409c-a8dc-6943d8b9a134"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 208, 2])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer = Transformer()\n",
        "transformer_out = transformer(X)\n",
        "transformer_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8rLrUxRTfqF",
        "outputId": "918e845d-6d72-4d57-8eee-541b0573f62d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " static_pos_encoding_1 (Sta  multiple                  1792      \n",
            " ticPosEncoding)                                                 \n",
            "                                                                 \n",
            " static_pos_encoding_2 (Sta  multiple                  3072      \n",
            " ticPosEncoding)                                                 \n",
            "                                                                 \n",
            " sequence_encoder_uint_1 (S  multiple                  2631140   \n",
            " equenceEncoderUint)                                             \n",
            "                                                                 \n",
            " sequence_encoder_uint_2 (S  multiple                  2631140   \n",
            " equenceEncoderUint)                                             \n",
            "                                                                 \n",
            " sequence_encoder_uint_3 (S  multiple                  2631140   \n",
            " equenceEncoderUint)                                             \n",
            "                                                                 \n",
            " sequence_encoder_uint_4 (S  multiple                  2631140   \n",
            " equenceEncoderUint)                                             \n",
            "                                                                 \n",
            " bracket_encoder_unit_1 (Br  multiple                  1579236   \n",
            " acketEncoderUnit)                                               \n",
            "                                                                 \n",
            " bracket_encoder_unit_2 (Br  multiple                  1579236   \n",
            " acketEncoderUnit)                                               \n",
            "                                                                 \n",
            " bracket_encoder_unit_3 (Br  multiple                  1579236   \n",
            " acketEncoderUnit)                                               \n",
            "                                                                 \n",
            " bracket_encoder_unit_4 (Br  multiple                  1579236   \n",
            " acketEncoderUnit)                                               \n",
            "                                                                 \n",
            " bracket_encoder_unit_5 (Br  multiple                  1579236   \n",
            " acketEncoderUnit)                                               \n",
            "                                                                 \n",
            " bracket_encoder_unit_6 (Br  multiple                  1579236   \n",
            " acketEncoderUnit)                                               \n",
            "                                                                 \n",
            " dense_78 (Dense)            multiple                  514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20005354 (76.31 MB)\n",
            "Trainable params: 20005354 (76.31 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CY7NhElf6rOw"
      },
      "outputs": [],
      "source": [
        "class CustomMetric2A3(keras.metrics.Metric):\n",
        "\n",
        "    def __init__(self,**kwargs):\n",
        "\n",
        "        super(CustomMetric2A3,self).__init__(**kwargs)\n",
        "        self.mae = self.add_weight(name=\"mae\",initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "\n",
        "        y_true = tf.clip_by_value(y_true[...,0],clip_value_max=1,clip_value_min=0)\n",
        "        y_pred = tf.clip_by_value(y_pred[...,0],clip_value_max=1,clip_value_min=0)\n",
        "        mae = tf.abs(tf.subtract(y_true,y_pred))\n",
        "        mae = tf.reduce_mean(mae[~tf.math.is_nan(mae)])\n",
        "        self.mae.assign_add(mae)\n",
        "\n",
        "\n",
        "    def result(self):\n",
        "        return self.mae\n",
        "\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mae.assign(0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kMe2rx9L6n5V"
      },
      "outputs": [],
      "source": [
        "class CustomMetricDMS(keras.metrics.Metric):\n",
        "\n",
        "    def __init__(self,**kwargs):\n",
        "\n",
        "        super(CustomMetricDMS,self).__init__(**kwargs)\n",
        "        self.mae = self.add_weight(name=\"mae\",initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "\n",
        "        y_true = tf.clip_by_value(y_true[...,1],clip_value_min=0,clip_value_max=1)\n",
        "        y_pred = tf.clip_by_value(y_pred[...,1],clip_value_max=1,clip_value_min=0)\n",
        "        mae = tf.abs(tf.subtract(y_true,y_pred))\n",
        "        mae = tf.reduce_mean(mae[~tf.math.is_nan(mae)])\n",
        "        self.mae.assign_add(mae)\n",
        "\n",
        "    def result(self):\n",
        "        return self.mae\n",
        "\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mae.assign(0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HrmEuYl86lxy"
      },
      "outputs": [],
      "source": [
        "class CustomLoss(keras.losses.Loss):\n",
        "\n",
        "    def __init__(self,**kwargs):\n",
        "\n",
        "        super(CustomLoss,self).__init__(**kwargs)\n",
        "\n",
        "    def __call__(self,y_true,y_pred,sample_weight=None):\n",
        "\n",
        "        y_true = tf.clip_by_value(y_true,clip_value_max=1,clip_value_min=0)\n",
        "        y_pred = tf.clip_by_value(y_pred,clip_value_max=1,clip_value_min=0)\n",
        "        mae_loss = tf.reduce_mean(tf.abs(tf.subtract(y_true,y_pred)),axis=-1)\n",
        "        return tf.reduce_mean(mae_loss[~tf.math.is_nan(mae_loss)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvxJ3dK0L0xk",
        "outputId": "0210c44c-23e5-462b-eb8e-c5a58c7a3bb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:        0.372436\n",
            "Metric 2A3:  0.5113621\n",
            "Metric DMS:  0.23855911\n"
          ]
        }
      ],
      "source": [
        "cust_loss= CustomLoss()\n",
        "cust_metric_2a3 = CustomMetric2A3()\n",
        "cust_metric_dms = CustomMetricDMS()\n",
        "cust_metric_2a3.update_state(y,transformer_out)\n",
        "cust_metric_dms.update_state(y,transformer_out)\n",
        "print(\"Loss:       \",cust_loss(y,transformer_out).numpy())\n",
        "print(\"Metric 2A3: \",cust_metric_2a3.result().numpy())\n",
        "print(\"Metric DMS: \",cust_metric_dms.result().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ExpLR(keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self,factor,**kwargs):\n",
        "        \n",
        "        super(ExpLR,self).__init__(**kwargs)\n",
        "        self.factor = factor\n",
        "        self.rates = []\n",
        "        self.losses = []\n",
        "        \n",
        "    def on_epoch_begin(self,epoch,logs=None):\n",
        "        self.sum_of_epoch_losses = 0\n",
        "        \n",
        "    def on_batch_end(self,batch,logs=None):\n",
        "        mean_epoch_loss = logs[\"loss\"]\n",
        "        new_sum_of_epoch_losses = mean_epoch_loss * (batch+1)\n",
        "        batch_loss = new_sum_of_epoch_losses - self.sum_of_epoch_losses\n",
        "        self.sum_of_epoch_losses = new_sum_of_epoch_losses\n",
        "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
        "        self.losses.append(batch_loss)\n",
        "        K.set_value(self.model.optimizer.learning_rate,self.model.optimizer.learning_rate* self.factor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_learning_rate(model,ds:tf.data.Dataset,iterations=num_train_instances,epochs=1,batch_size:int=BATCH_SIZE,min_rate:float=1e-7,max_rate:float=1):\n",
        "    \n",
        "    init_weights = model.get_weights()\n",
        "    total_iterations = iterations * epochs\n",
        "    steps_per_epoch = iterations//BATCH_SIZE\n",
        "    factor = (max_rate/min_rate) ** (1/total_iterations)\n",
        "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
        "    K.set_value(model.optimizer.learning_rate,min_rate)\n",
        "    exp_lr = ExpLR(factor)\n",
        "    history = model.fit(ds,epochs=epochs,steps_per_epoch=steps_per_epoch,callbacks=[exp_lr])\n",
        "    K.set_value(model.optimizer.learning_rate,init_lr)\n",
        "    model.set_weights(init_weights)\n",
        "    return exp_lr.rates,exp_lr.losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "O45JR5HoJ8PB"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    model = Transformer()\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(1e-5),\n",
        "        loss=CustomLoss(name=\"custom_loss\"),\n",
        "        steps_per_execution=25\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rates,losses = find_learning_rate(model,train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "px.line(x=rates,y=losses)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNARi5kCujv+gKV8Y2Cczbl",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
