{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h4ck4l1/datasets/blob/main/Stanfordribonan/Copy_of_Copy_of_ribonanza_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEtUABBt4ed8",
        "outputId": "1eff0233-6495-4223-f2be-26493baff4fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os,sys,warnings,time\n",
        "from IPython.display import clear_output\n",
        "warnings.filterwarnings('ignore')\n",
        "os.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oqzT4mF7yot",
        "outputId": "869d8694-94cf-483c-8f46-ff37fc1c583d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "if \"COLAB_BACKEND_VERSION\" in os.environ.keys():\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    !gcloud config set project kaggle-406814\n",
        "    !pip install keras-tuner --upgrade\n",
        "    clear_output()\n",
        "elif \"KAGGLE_GCP_ZONE\" in os.environ.keys():\n",
        "    !pip install keras-tuner --upgrade\n",
        "    !pip install -q -U plotly --upgrade\n",
        "    !pip isntall google-cloud-storage\n",
        "    from google.cloud import storage\n",
        "    client = storage.Client(\"kaggle-406814\")\n",
        "    from kaggle_secrets import UserSecretsClient\n",
        "    user_secrets = UserSecretsClient()\n",
        "    user_credential = user_secrets.get_gcloud_credential()\n",
        "    user_secrets.set_tensorflow_credential(user_credential)\n",
        "else:\n",
        "    !gcloud config set project kaggle-406814"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hOHkSSICqgJJ"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "import numpy as np\n",
        "from typing import Literal,Optional\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.io as pio\n",
        "pio.templates.default = \"plotly_dark\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.sparse import to_dense\n",
        "from tensorflow.io import FixedLenFeature,VarLenFeature,parse_tensor,parse_single_example\n",
        "from tensorflow.data import TFRecordDataset\n",
        "from tensorflow import keras\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "import re,time,random,math\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cnoJ5NzvzpO",
        "outputId": "11cfd286-3d91-4d94-bb42-45e9922b3a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TPU is not present ,So running on GPU\n",
            "<tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy object at 0x7fb4807bbb50>\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "strategy = tf.distribute.Strategy\n",
        "try:\n",
        "    tpu_cluster = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print(\"Running on TPU ADDR: \",tpu_cluster.cluster_spec().as_dict()['worker'][0])\n",
        "    tf.config.experimental_connect_to_cluster(tpu_cluster)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu_cluster)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu_cluster)\n",
        "    is_tpu = True\n",
        "except ValueError:\n",
        "    print(\"TPU is not present ,So \",end=\"\")\n",
        "    is_tpu = False\n",
        "\n",
        "if not is_tpu:\n",
        "    if len(tf.config.list_physical_devices()) > 0:\n",
        "        strategy = tf.distribute.OneDeviceStrategy(\"GPU\")\n",
        "        print(\"running on GPU\")\n",
        "    else:\n",
        "        strategy = tf.distribute.OneDeviceStrategy(\"CPU\")\n",
        "        print(\"running on CPU\")\n",
        "print(strategy)\n",
        "print(strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oMFKUVuVrVWR"
      },
      "outputs": [],
      "source": [
        "PATH = \"gs://stanfordrna/ribo/train_*.tfrecord\"\n",
        "total_files = tf.io.gfile.glob(PATH)\n",
        "train_files = total_files[:165]\n",
        "valid_files = total_files[165:175]\n",
        "test_files = total_files[175:]\n",
        "train_raw_ds = TFRecordDataset(train_files,compression_type=\"GZIP\",num_parallel_reads=tf.data.AUTOTUNE)\n",
        "valid_raw_ds = TFRecordDataset(valid_files,compression_type=\"GZIP\",num_parallel_reads=tf.data.AUTOTUNE)\n",
        "test_raw_ds = TFRecordDataset(test_files,compression_type=\"GZIP\",num_parallel_reads=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lz9J4pwZ7gx_"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "rna_feature = dict(\n",
        "    seq_id = FixedLenFeature([],tf.string),\n",
        "    seq = FixedLenFeature([],tf.string),\n",
        "    reads_2a3 = FixedLenFeature([],tf.string),\n",
        "    reads_dms = FixedLenFeature([],tf.string),\n",
        "    signal_to_noise_2a3 = FixedLenFeature([],tf.string),\n",
        "    signal_to_noise_dms = FixedLenFeature([],tf.string),\n",
        "    reactivity_2a3 = FixedLenFeature([],tf.string),\n",
        "    reactivity_dms = FixedLenFeature([],tf.string),\n",
        "    reactivity_error_2a3 = FixedLenFeature([],tf.string),\n",
        "    reactivity_error_dms = FixedLenFeature([],tf.string),\n",
        "    bpp_matrix = FixedLenFeature([],tf.string),\n",
        "    bracket_seq = FixedLenFeature([],tf.string)\n",
        "    )\n",
        "\n",
        "def rna_example(example):\n",
        "    example = parse_single_example(example, rna_feature)\n",
        "\n",
        "    ### Dense Features\n",
        "    example[\"seq_id\"] = parse_tensor(example[\"seq_id\"], out_type=tf.string)\n",
        "    example[\"reads_2a3\"] = parse_tensor(example[\"reads_2a3\"], out_type=tf.float32)\n",
        "    example[\"reads_dms\"] = parse_tensor(example[\"reads_dms\"], out_type=tf.float32)\n",
        "    example[\"signal_to_noise_2a3\"] = parse_tensor(example[\"signal_to_noise_2a3\"], out_type=tf.float32)\n",
        "    example[\"signal_to_noise_dms\"] = parse_tensor(example[\"signal_to_noise_dms\"], out_type=tf.float32)\n",
        "    \n",
        "    ### Sequential Features\n",
        "    example[\"seq\"] = parse_tensor(example[\"seq\"], out_type=tf.float32)\n",
        "    example[\"reactivity_2a3\"] = parse_tensor(example[\"reactivity_2a3\"], out_type=tf.float32)\n",
        "    example[\"reactivity_dms\"] = parse_tensor(example[\"reactivity_dms\"], out_type=tf.float32)\n",
        "    example[\"reactivity_error_2a3\"] = parse_tensor(example[\"reactivity_error_2a3\"], out_type=tf.float32)\n",
        "    example[\"reactivity_error_dms\"] = parse_tensor(example[\"reactivity_error_dms\"], out_type=tf.float32)\n",
        "    example[\"bpp_matrix\"] = parse_tensor(example[\"bpp_matrix\"], out_type=tf.float32)\n",
        "    example[\"bracket_seq\"] = parse_tensor(example[\"bracket_seq\"], out_type=tf.float32)\n",
        "\n",
        "    return example\n",
        "\n",
        "train_modified_ds = train_raw_ds.map(rna_example,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "valid_modified_ds = valid_raw_ds.map(rna_example,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_modified_ds = test_raw_ds.map(rna_example,num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gCRgHPC098EQ",
        "outputId": "5ea5689d-5b97-4ccd-da93-d5f204d20838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id  :  b'25ce8d5109cd'\n",
            "\n",
            "\n",
            "\n",
            "seq  :  [3. 3. 3. 1. 1. 2. 3. 1. 2. 4. 2. 3. 1. 3. 4. 1. 3. 1. 3. 4.]\n",
            "seq shape : (170,)\n",
            "\n",
            "\n",
            "\n",
            "reads_2a3 :  4647.0\n",
            "\n",
            "\n",
            "\n",
            "reads_dms :  1964.0\n",
            "\n",
            "\n",
            "\n",
            "signal_to_noise_2a3 :  2.347\n",
            "\n",
            "\n",
            "\n",
            "signal_to_noise_dms :  1.848\n",
            "\n",
            "\n",
            "\n",
            "reactivity_2a3  :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "shape of reactivity_2a3 : (206,)\n",
            "\n",
            "\n",
            "\n",
            "reactivity_dms  :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "shape of reactivity_dms : (206,)\n",
            "\n",
            "\n",
            "\n",
            "reactivity_error_2a3 :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "shape of reactivity_error_2a3 (206,)\n",
            "\n",
            "\n",
            "\n",
            "reactivity_error_dms :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "shape of reactivity_error_dms (206,)\n",
            "\n",
            "\n",
            "\n",
            "bpp_matrix : [[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "bpp_matrix shape : (170, 170)\n",
            "\n",
            "\n",
            "\n",
            "bracket_sequence : [1. 1. 9. 9. 9. 1. 1. 1. 1. 1. 1. 9. 9. 9. 9. 9. 2. 2. 2. 2.]\n",
            "bracket_sequence shape : (170,)\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "single_example = train_modified_ds.take(1).get_single_element()\n",
        "print(\"id\",\" : \",single_example[\"seq_id\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"seq\",\" : \",single_example[\"seq\"].numpy()[:20])\n",
        "print(\"seq shape :\",single_example[\"seq\"].numpy().shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"reads_2a3\",\": \",single_example[\"reads_2a3\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"reads_dms\",\": \",single_example[\"reads_dms\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"signal_to_noise_2a3\",\": \",single_example[\"signal_to_noise_2a3\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"signal_to_noise_dms\",\": \",single_example[\"signal_to_noise_dms\"].numpy())\n",
        "print(\"\\n\\n\")\n",
        "print(\"reactivity_2a3\",\" : \",single_example[\"reactivity_2a3\"].numpy()[:20])\n",
        "print(\"shape of reactivity_2a3 :\",single_example[\"reactivity_2a3\"].shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"reactivity_dms\",\" : \",single_example[\"reactivity_dms\"].numpy()[:20])\n",
        "print(\"shape of reactivity_dms :\",single_example[\"reactivity_dms\"].shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"reactivity_error_2a3\",\": \",single_example[\"reactivity_error_2a3\"].numpy()[:20])\n",
        "print(\"shape of reactivity_error_2a3\",single_example[\"reactivity_error_2a3\"].shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"reactivity_error_dms\",\": \",single_example[\"reactivity_error_dms\"].numpy()[:20])\n",
        "print(\"shape of reactivity_error_dms\",single_example[\"reactivity_error_dms\"].shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"bpp_matrix :\",single_example[\"bpp_matrix\"].numpy()[:5,:5])\n",
        "print(\"bpp_matrix shape :\",single_example[\"bpp_matrix\"].numpy().shape)\n",
        "print(\"\\n\\n\")\n",
        "print(\"bracket_sequence :\",single_example[\"bracket_seq\"].numpy()[:20])\n",
        "print('bracket_sequence shape :',single_example[\"bracket_seq\"].numpy().shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EivynxKT2u-5"
      },
      "source": [
        "# The\n",
        "\n",
        "## Total number of rows in each dataset is: 821840\n",
        "\n",
        "## Total number of rows in sn_filter > 1 is: 181267\n",
        "\n",
        "### Total number of tfrecord files: 164\n",
        "\n",
        "### Total nunber of instances per file: 5005\n",
        "\n",
        "### Total number of steps per epoch: 6420\n",
        "\n",
        "### Total number of steps per epoch for 3 test files: 117\n",
        "\n",
        "\n",
        "\n",
        "## Example sizes of the input sequences\n",
        "- [170, 177, 115, 155, 206]\n",
        "- minimum of reactivity columns : -129.281\n",
        "- maximum of reactivity columns :  129.281\n",
        "- positions upto 26 and from 126 are all nans can be padded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "LcbxuzwBBkmA"
      },
      "outputs": [],
      "source": [
        "K = keras.backend\n",
        "seq_map = {\"A\":1,\"C\":2,\"G\":3,\"U\":4,\"START\":4,\"END\":5,\"EMPTY\":0}\n",
        "bracket_map = {\"(\":1,\")\":2,\"[\":3,\"]\":4,\"{\":5,\"}\":6,\"<\":7,\">\":8,\".\":9,\"START\":10,\"END\":11,\"EMPTY\":0}\n",
        "\n",
        "def convert_and_pad(ex):\n",
        "\n",
        "    l = tf.shape(ex[\"seq\"],tf.int32)[0]\n",
        "\n",
        "    shift = tf.random.uniform(shape=[1],minval=0,maxval=206-l+1,dtype=tf.int32)[0]\n",
        "\n",
        "    # Sequence Processing and Mask Processing\n",
        "    seq = ex[\"seq\"] + 1\n",
        "    seq = tf.pad(seq,[[1,0]],constant_values=seq_map[\"START\"])                               # seq_map[\"START\"]\n",
        "    seq = tf.pad(seq,[[0,1]],constant_values=seq_map[\"END\"])                                 # seq_map[\"END\"]\n",
        "    seq = tf.pad(seq,[[shift,206-l-shift]])                                                 # seq_map[\"EMPTY\"]\n",
        "\n",
        "    # Bracket Processing\n",
        "    brac = ex[\"bracket_seq\"] + 1\n",
        "    brac = tf.pad(brac,[[1,0]],constant_values=bracket_map[\"START\"])                            # bracket_map[\"START\"]\n",
        "    brac = tf.pad(brac,[[0,1]],constant_values=bracket_map[\"END\"])                              # bracket_map[\"END\"]\n",
        "    brac = tf.pad(brac,[[shift,206-l-shift]],constant_values=bracket_map[\"EMPTY\"])             # bracket_map[\"EMPTY\"]\n",
        "\n",
        "    # Reactivity Processing\n",
        "    reac = tf.stack([ex[\"reactivity_2a3\"][:l],ex[\"reactivity_dms\"][:l]],axis=-1)\n",
        "    reac = tf.pad(reac,[[shift+1,206+1-l-shift],[0,0]],constant_values=np.nan)\n",
        "\n",
        "    # BPPMatrix\n",
        "    bppm = ex[\"bpp_matrix\"][:l,:l]\n",
        "    bppm = tf.pad(bppm,[[shift+1,206+1-l-shift],[shift+1,206+1-l-shift]])\n",
        "\n",
        "    return (seq,brac,bppm),reac\n",
        "\n",
        "\n",
        "def shape_set(X,y,batch_size):\n",
        "    (seq,brac,bpp),reac = X,y\n",
        "    seq.set_shape([batch_size,208])\n",
        "    brac.set_shape([batch_size,208])\n",
        "    bpp.set_shape([batch_size,208,208])\n",
        "    reac.set_shape([batch_size,208,2])\n",
        "    return (seq,brac,bpp),reac\n",
        "\n",
        "\n",
        "def create_train_ds(dataset,batch_size:int):\n",
        "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch_size,drop_remainder=True,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(lambda X,y: shape_set(X,y,batch_size),num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "def create_val_ds(dataset,batch_size:int):\n",
        "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size,drop_remainder=True,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(lambda X,y: shape_set(X,y,batch_size),num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.cache()\n",
        "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "def create_test_ds(dataset,batch_size:int):\n",
        "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size,drop_remainder=True,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(lambda X,y: shape_set(X,y,batch_size),num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "train_ds = create_train_ds(train_modified_ds,batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "i07L32EZcp1m"
      },
      "outputs": [],
      "source": [
        "X,y = train_ds.take(1).get_single_element()\n",
        "\n",
        "seq_input = X[0]\n",
        "bracket_input = X[1]\n",
        "bpp_matrix = X[2]\n",
        "reactivity = y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOA9vxnhT81c",
        "outputId": "3bdbe7df-df04-4675-dcb2-815e3a8fc9dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequence input shape:  (8, 208)\n",
            "bracket input : (8, 208)\n",
            "bpp matrix shape : (8, 208, 208)\n",
            "reactivity shape : (8, 208, 2)\n"
          ]
        }
      ],
      "source": [
        "print(\"sequence input shape: \",seq_input.shape)\n",
        "print(\"bracket input :\",bracket_input.shape)\n",
        "print(\"bpp matrix shape :\",bpp_matrix.shape)\n",
        "print(\"reactivity shape :\",reactivity.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBWE_XTVZgS-"
      },
      "source": [
        "# Model Trying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "39rw0-NCYHas"
      },
      "outputs": [],
      "source": [
        "class StaticPosEncoding(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "            vocab_size:int,\n",
        "            d_model,\n",
        "            length,\n",
        "            **kwargs):\n",
        "\n",
        "        super(StaticPosEncoding,self).__init__(**kwargs)\n",
        "\n",
        "        assert d_model%2 == 0,\"Depth of model(d_model) should be even\"\n",
        "\n",
        "        d_model = d_model//2\n",
        "        positions = np.arange(length)[:,np.newaxis]\n",
        "        angles = np.arange(d_model)[np.newaxis,:]/d_model\n",
        "        angles = 1/(10000**angles)\n",
        "        angle_rads = positions * angles\n",
        "        encode = tf.concat([tf.sin(angle_rads),tf.cos(angle_rads)],axis=-1)\n",
        "        self.encode = tf.cast(encode,tf.float32)\n",
        "        self.factor = tf.sqrt(tf.cast(d_model,tf.float32))\n",
        "        self.embedding_layer = keras.layers.Embedding(vocab_size,d_model*2,mask_zero=True)\n",
        "\n",
        "    def compute_mask(self, *args,**kwargs):\n",
        "        return self.embedding_layer.compute_mask(*args,**kwargs)\n",
        "\n",
        "    def call(self,x):\n",
        "        seq_l = tf.shape(x)[1]\n",
        "        x = self.embedding_layer(x)\n",
        "        x *= self.factor\n",
        "        return x + self.encode[tf.newaxis,:seq_l,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YC_ZebEpdVdx",
        "outputId": "ed87fa49-43c2-40a9-a40f-2422cd55fd46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8, 208, 512)\n",
            "(8, 208, 512)\n"
          ]
        }
      ],
      "source": [
        "seq_pos_encode = StaticPosEncoding(vocab_size=len(seq_map),d_model=512,length=2048)\n",
        "brac_pos_encode = StaticPosEncoding(vocab_size=len(bracket_map),d_model=512,length=2048)\n",
        "seq_pos_encode_output = seq_pos_encode(X[0])\n",
        "brac_pos_encode_output = brac_pos_encode(X[1])\n",
        "print(seq_pos_encode_output.shape)\n",
        "print(brac_pos_encode_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vNycXdf9d2kZ"
      },
      "outputs": [],
      "source": [
        "class ConvolutionLayer(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 n_filters,\n",
        "                 ksize,\n",
        "                 drop_rate,\n",
        "                 **kwargs):\n",
        "        super(ConvolutionLayer,self).__init__(**kwargs)\n",
        "        self.conv_layers = [keras.layers.Conv2D(filters=n_filters,kernel_size=ksize,padding=\"same\",use_bias=False,activation=\"relu\") for _ in range(n_layers)]\n",
        "        self.perm = keras.layers.Permute(dims=[3,1,2])\n",
        "        self.norm = keras.layers.LayerNormalization()\n",
        "        self.drop = keras.layers.Dropout(drop_rate)\n",
        "\n",
        "    def call(self,x):\n",
        "        x = tf.expand_dims(x,axis=-1)\n",
        "        for layer in self.conv_layers:\n",
        "            x = layer(x)\n",
        "        x = self.perm(x)\n",
        "        return self.norm(self.drop(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86WwctnN-zfh",
        "outputId": "4e2a0496-195e-48fd-999c-d00bb46bd134"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([8, 6, 208, 208])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conv = ConvolutionLayer(n_layers=3,n_filters=6,ksize=3,drop_rate=0.1)\n",
        "bpp_conv_ouput = conv(bpp_matrix)\n",
        "bpp_conv_ouput.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "P2ppV-pW3yBb"
      },
      "outputs": [],
      "source": [
        "class ConvolutedAttention(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "            num_heads,\n",
        "            key_dim,\n",
        "            **kwargs):\n",
        "\n",
        "        super(ConvolutedAttention,self).__init__(**kwargs)\n",
        "        self.num_heads = num_heads\n",
        "        self.key_dim = key_dim\n",
        "        self.wq = keras.layers.Dense(num_heads*key_dim)\n",
        "        self.wv = keras.layers.Dense(num_heads*key_dim)\n",
        "        self.wk = keras.layers.Dense(num_heads*key_dim)\n",
        "        self.dense = keras.layers.Dense(key_dim)\n",
        "        self.first_drop = keras.layers.Dropout(0.1)\n",
        "        self.last_drop = keras.layers.Dropout(0.1)\n",
        "        self.layer_norm = keras.layers.LayerNormalization()\n",
        "        self.factor = tf.math.rsqrt(tf.constant(key_dim,tf.float32))\n",
        "        self.softmax = keras.layers.Softmax()\n",
        "        self.add = keras.layers.Add()\n",
        "\n",
        "\n",
        "    def call(self,query,key,value,convoluted=None,return_attention_scores=False,mask=None):\n",
        "\n",
        "\n",
        "        batch_size = tf.shape(query)[0]\n",
        "        seq_len = tf.shape(query)[1]\n",
        "        q = self.wq(query)\n",
        "        k = self.wk(key)\n",
        "        v = self.wv(value)\n",
        "\n",
        "        q = tf.transpose(tf.reshape(q,shape=[batch_size,-1,self.num_heads,self.key_dim]),perm=[0,2,1,3])\n",
        "        k = tf.transpose(tf.reshape(k,shape=[batch_size,-1,self.num_heads,self.key_dim]),perm=[0,2,1,3])\n",
        "        v = tf.transpose(tf.reshape(v,shape=[batch_size,-1,self.num_heads,self.key_dim]),perm=[0,2,1,3])\n",
        "\n",
        "        attention_score = self.factor * tf.matmul(q,k,transpose_b=True)\n",
        "        attention_score = self.first_drop(self.softmax(attention_score + convoluted))\n",
        "\n",
        "        attention_out = tf.reshape(tf.transpose(tf.matmul(attention_score,v),perm=[0,2,1,3]),shape=[batch_size,seq_len,-1])\n",
        "        attention_out = self.last_drop(self.dense(attention_out))\n",
        "        attention_out = self.layer_norm(self.add([attention_out,query]))\n",
        "\n",
        "        if return_attention_scores:\n",
        "            return attention_out,attention_score\n",
        "        return attention_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlheKwBbOGD2",
        "outputId": "5bee5705-cf69-4b7d-f424-470c00e5ca18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([8, 208, 512])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conv_attn = ConvolutedAttention(num_heads=6,key_dim=512)\n",
        "conv_attn_out = conv_attn(query=seq_pos_encode_output,key=seq_pos_encode_output,value=seq_pos_encode_output,convoluted=bpp_conv_ouput)\n",
        "conv_attn_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MY8BoKHMhDsf"
      },
      "outputs": [],
      "source": [
        "class FeedForward(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "            feed_out_unit,\n",
        "            feed_forward,\n",
        "            feed_forward_drop,\n",
        "            **kwargs):\n",
        "\n",
        "        super(FeedForward,self).__init__(**kwargs)\n",
        "        self.dense_out = keras.layers.Dense(feed_out_unit)\n",
        "        self.feed_forward = keras.layers.Dense(feed_forward)\n",
        "        self.feed_forward_drop = keras.layers.Dropout(feed_forward_drop)\n",
        "        self.norm = keras.layers.LayerNormalization()\n",
        "        self.add = keras.layers.Add()\n",
        "\n",
        "    def call(self,x):\n",
        "\n",
        "        x_copy = x\n",
        "        x = self.feed_forward(x)\n",
        "        x = self.dense_out(x)\n",
        "        x = self.feed_forward_drop(x)\n",
        "        x = self.feed_forward_drop(x)\n",
        "        return self.norm(self.add([x_copy,x]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjL8klRpCCSo",
        "outputId": "f0dbedc3-8c21-4aac-b27d-0b6c61403044"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([8, 208, 512])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feed_forward = FeedForward(feed_out_unit=512,feed_forward=2048,feed_forward_drop=0.2)\n",
        "feed_out = feed_forward(conv_attn_out)\n",
        "feed_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "N09NEdOgVLwn"
      },
      "outputs": [],
      "source": [
        "class BracketEncoderUnit(keras.models.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "            encoder_convolution_layers:int,\n",
        "            encoder_convolution_ksize:int,\n",
        "            encoder_convolution_drop_rate:float,\n",
        "            encoder_convolution_num_heads:int,\n",
        "            encoder_key_dim:int,\n",
        "            encoder_feed_out_units:int,\n",
        "            encoder_feed_forward_units:int,\n",
        "            encoder_feed_forward_drop_rate:float,\n",
        "            **kwargs):\n",
        "\n",
        "\n",
        "        super(BracketEncoderUnit,self).__init__(**kwargs)\n",
        "\n",
        "        self.convolution_layer = ConvolutionLayer(\n",
        "            encoder_convolution_layers,\n",
        "            encoder_convolution_num_heads,\n",
        "            encoder_convolution_ksize,\n",
        "            encoder_convolution_drop_rate,\n",
        "        )\n",
        "\n",
        "        self.convoluted_attention = ConvolutedAttention(\n",
        "            encoder_convolution_num_heads,\n",
        "            encoder_key_dim\n",
        "        )\n",
        "\n",
        "        self.feed_forward = FeedForward(\n",
        "            encoder_feed_out_units,\n",
        "            encoder_feed_forward_units,\n",
        "            encoder_feed_forward_drop_rate\n",
        "        )\n",
        "\n",
        "    def call(self,bracket_encode_out,bpp_matrix):\n",
        "\n",
        "        convolution_out = self.convolution_layer(bpp_matrix)\n",
        "        convoluted_attention_out = self.convoluted_attention(\n",
        "            query = bracket_encode_out,\n",
        "            key = bracket_encode_out,\n",
        "            value = bracket_encode_out,\n",
        "            convoluted = convolution_out\n",
        "        )\n",
        "        feed_out = self.feed_forward(convoluted_attention_out)\n",
        "\n",
        "        return feed_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbT272NlVM1-",
        "outputId": "7db4db52-28ed-4a1b-b4b0-9b8074c523aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([8, 208, 512])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bracket_seq_encoder = BracketEncoderUnit(\n",
        "    encoder_convolution_layers=3,\n",
        "    encoder_convolution_ksize=3,\n",
        "    encoder_convolution_drop_rate=0.1,\n",
        "    encoder_convolution_num_heads=6,\n",
        "    encoder_key_dim=512,\n",
        "    encoder_feed_forward_drop_rate=0.1,\n",
        "    encoder_feed_forward_units=2048,\n",
        "    encoder_feed_out_units=512\n",
        ")\n",
        "\n",
        "bracket_seq_encoder_out = bracket_seq_encoder(brac_pos_encode_output,bpp_matrix)\n",
        "bracket_seq_encoder_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Qil3FWxpCFoo"
      },
      "outputs": [],
      "source": [
        "class SequenceEncoderUint(keras.models.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "            encoder_convolution_layers:int,\n",
        "            encoder_convolution_ksize:int,\n",
        "            encoder_convolution_drop_rate:float,\n",
        "            encoder_convolution_num_heads:int,\n",
        "            encoder_cross_attention_num_heads:int,\n",
        "            encoder_key_dim:int,\n",
        "            encoder_feed_out_units:int,\n",
        "            encoder_feed_forward_units:int,\n",
        "            encoder_feed_forward_drop_rate:float,\n",
        "            **kwargs):\n",
        "\n",
        "        super(SequenceEncoderUint,self).__init__(**kwargs)\n",
        "\n",
        "        self.convolution_layer = ConvolutionLayer(\n",
        "            encoder_convolution_layers,\n",
        "            encoder_convolution_num_heads,\n",
        "            encoder_convolution_ksize,\n",
        "            encoder_convolution_drop_rate\n",
        "            )\n",
        "\n",
        "        self.convoluted_attention = ConvolutedAttention(\n",
        "            encoder_convolution_num_heads,\n",
        "            encoder_key_dim\n",
        "            )\n",
        "\n",
        "        self.encoder_cross_attention = keras.layers.MultiHeadAttention(\n",
        "            num_heads=encoder_cross_attention_num_heads,\n",
        "            key_dim=encoder_key_dim\n",
        "            )\n",
        "\n",
        "        self.feed_forward = FeedForward(\n",
        "            encoder_feed_out_units,\n",
        "            encoder_feed_forward_units,\n",
        "            encoder_feed_forward_drop_rate\n",
        "            )\n",
        "\n",
        "    def call(self,sequence_encode_out,bpp_matrix,bracket_encode_out):\n",
        "\n",
        "        convolution_out = self.convolution_layer(bpp_matrix)\n",
        "        convolutedattention_out = self.convoluted_attention(\n",
        "            query=sequence_encode_out,\n",
        "            key=sequence_encode_out,\n",
        "            value=sequence_encode_out,\n",
        "            convoluted=convolution_out\n",
        "            )\n",
        "        crossattention_out = self.encoder_cross_attention(\n",
        "            query=convolutedattention_out,\n",
        "            key=bracket_encode_out,\n",
        "            value=bracket_encode_out\n",
        "            )\n",
        "        feed_out = self.feed_forward(crossattention_out)\n",
        "\n",
        "        return feed_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwN72GFKO_4i",
        "outputId": "7a3b6c6f-fa84-4a87-98bb-5e5be3ae6a14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([8, 208, 512])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seq_encoder = SequenceEncoderUint(\n",
        "    encoder_convolution_layers=3,\n",
        "    encoder_convolution_ksize=3,\n",
        "    encoder_convolution_drop_rate=0.1,\n",
        "    encoder_convolution_num_heads=6,\n",
        "    encoder_cross_attention_num_heads=6,\n",
        "    encoder_key_dim=512,\n",
        "    encoder_feed_forward_drop_rate=0.1,\n",
        "    encoder_feed_forward_units=2048,\n",
        "    encoder_feed_out_units=512\n",
        "    )\n",
        "\n",
        "seq_encoder_out = seq_encoder(seq_pos_encode_output,bpp_matrix,bracket_seq_encoder_out)\n",
        "seq_encoder_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "m3V6dWFmmcP9"
      },
      "outputs": [],
      "source": [
        "class Transformer(keras.models.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "\n",
        "            # Seuqence encoder arguments\n",
        "\n",
        "            sequence_encoder_vocab_size:int=len(seq_map),\n",
        "            sequence_encoder_d_model:int=256,\n",
        "            sequence_encoder_length:int=2048,\n",
        "            sequence_encoder_num_layers:int=4,\n",
        "            sequence_encoder_convolution_layers:int=3,\n",
        "            sequence_encoder_convolution_ksize:int=3,\n",
        "            sequence_encoder_convolution_drop_rate:float=0.1,\n",
        "            sequence_encoder_convolution_num_heads:int=4,\n",
        "            sequence_encoder_cross_attention_num_heads:int=4,\n",
        "            sequence_encoder_key_dim:int=256,\n",
        "            sequence_encoder_feed_out_units:int=256,\n",
        "            sequence_encoder_feed_forward_units:int=1024,\n",
        "            sequence_encoder_feed_forward_drop_rate:float=0.1,\n",
        "\n",
        "            # Bracket Sequence Encoder arguments\n",
        "\n",
        "            bracket_sequence_encoder_vocab_size:int=len(bracket_map),\n",
        "            bracket_sequence_encoder_d_model:int=256,\n",
        "            bracket_sequence_encoder_length:int=2048,\n",
        "            bracket_sequence_encoder_num_layers:int=6,\n",
        "            bracket_sequence_encoder_convolution_layers:int=3,\n",
        "            bracket_sequence_encoder_convolution_ksize:int=3,\n",
        "            bracket_sequence_encoder_convolution_drop_rate:float=0.1,\n",
        "            bracket_sequence_encoder_num_heads:int=4,\n",
        "            bracket_sequence_encoder_key_dim:int=256,\n",
        "            bracket_sequence_encoder_feed_out_units:int=256,\n",
        "            bracket_sequence_encoder_feed_forward_units:int=1024,\n",
        "            bracket_sequence_encoder_feed_forward_drop_rate:float=0.1,\n",
        "\n",
        "            # Out Dense\n",
        "            total_out_units = 2,\n",
        "            **kwargs):\n",
        "\n",
        "\n",
        "        super(Transformer,self).__init__(**kwargs)\n",
        "\n",
        "        self.sequence_pos_encoder = StaticPosEncoding(\n",
        "            sequence_encoder_vocab_size,\n",
        "            sequence_encoder_d_model,\n",
        "            sequence_encoder_length,\n",
        "        )\n",
        "\n",
        "        self.bracket_sequence_pos_encoder = StaticPosEncoding(\n",
        "            bracket_sequence_encoder_vocab_size,\n",
        "            bracket_sequence_encoder_d_model,\n",
        "            bracket_sequence_encoder_length,\n",
        "        )\n",
        "\n",
        "        self.sequence_encoder_units_list = [SequenceEncoderUint(\n",
        "            sequence_encoder_convolution_layers,\n",
        "            sequence_encoder_convolution_ksize,\n",
        "            sequence_encoder_convolution_drop_rate,\n",
        "            sequence_encoder_convolution_num_heads,\n",
        "            sequence_encoder_cross_attention_num_heads,\n",
        "            sequence_encoder_key_dim,\n",
        "            sequence_encoder_feed_out_units,\n",
        "            sequence_encoder_feed_forward_units,\n",
        "            sequence_encoder_feed_forward_drop_rate\n",
        "        ) for _ in range(sequence_encoder_num_layers)]\n",
        "\n",
        "        self.bracket_sequence_encoder_units_list = [BracketEncoderUnit(\n",
        "            bracket_sequence_encoder_convolution_layers,\n",
        "            bracket_sequence_encoder_convolution_ksize,\n",
        "            bracket_sequence_encoder_convolution_drop_rate,\n",
        "            bracket_sequence_encoder_num_heads,\n",
        "            bracket_sequence_encoder_key_dim,\n",
        "            bracket_sequence_encoder_feed_out_units,\n",
        "            bracket_sequence_encoder_feed_forward_units,\n",
        "            bracket_sequence_encoder_feed_forward_drop_rate\n",
        "        ) for _ in range(bracket_sequence_encoder_num_layers)]\n",
        "\n",
        "        self.total_out = keras.layers.Dense(total_out_units,activation=None)\n",
        "\n",
        "\n",
        "    def call(self,X):\n",
        "\n",
        "        sequence,bracket_sequence,bpp_matrix = X\n",
        "        out = self.bracket_sequence_pos_encoder(bracket_sequence)\n",
        "\n",
        "        for layer in self.bracket_sequence_encoder_units_list:\n",
        "            out = layer(out,bpp_matrix)\n",
        "\n",
        "        seq_out = self.sequence_pos_encoder(sequence)\n",
        "\n",
        "        for layer in self.sequence_encoder_units_list:\n",
        "            seq_out = layer(seq_out,bpp_matrix,out)\n",
        "\n",
        "\n",
        "        seq_out = self.total_out(seq_out)\n",
        "\n",
        "        try:\n",
        "            del seq_out._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        return seq_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SJRkz3IItJG",
        "outputId": "d9ca62a1-7133-4d61-d7ea-ad4602c906da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([8, 208, 2])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer = Transformer()\n",
        "transformer_out = transformer(X)\n",
        "transformer_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8rLrUxRTfqF",
        "outputId": "5672fb54-70c3-46ff-bb5e-81091dc5e33d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│ static_pos_encoding_2           │ ?                         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StaticPosEncoding</span>)             │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ static_pos_encoding_3           │ ?                         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StaticPosEncoding</span>)             │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ sequence_encoder_uint_1         │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,631,140</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SequenceEncoderUint</span>)           │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ sequence_encoder_uint_2         │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,631,140</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SequenceEncoderUint</span>)           │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ sequence_encoder_uint_3         │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,631,140</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SequenceEncoderUint</span>)           │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ sequence_encoder_uint_4         │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,631,140</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SequenceEncoderUint</span>)           │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_1          │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,579,236</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BracketEncoderUnit</span>)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_2          │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,579,236</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BracketEncoderUnit</span>)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_3          │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,579,236</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BracketEncoderUnit</span>)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_4          │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,579,236</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BracketEncoderUnit</span>)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_5          │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,579,236</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BracketEncoderUnit</span>)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_6          │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,579,236</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BracketEncoderUnit</span>)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dense_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │\n",
              "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│ static_pos_encoding_2           │ ?                         │      \u001b[38;5;34m1,792\u001b[0m │\n",
              "│ (\u001b[38;5;33mStaticPosEncoding\u001b[0m)             │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ static_pos_encoding_3           │ ?                         │      \u001b[38;5;34m3,072\u001b[0m │\n",
              "│ (\u001b[38;5;33mStaticPosEncoding\u001b[0m)             │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ sequence_encoder_uint_1         │ ?                         │  \u001b[38;5;34m2,631,140\u001b[0m │\n",
              "│ (\u001b[38;5;33mSequenceEncoderUint\u001b[0m)           │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ sequence_encoder_uint_2         │ ?                         │  \u001b[38;5;34m2,631,140\u001b[0m │\n",
              "│ (\u001b[38;5;33mSequenceEncoderUint\u001b[0m)           │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ sequence_encoder_uint_3         │ ?                         │  \u001b[38;5;34m2,631,140\u001b[0m │\n",
              "│ (\u001b[38;5;33mSequenceEncoderUint\u001b[0m)           │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ sequence_encoder_uint_4         │ ?                         │  \u001b[38;5;34m2,631,140\u001b[0m │\n",
              "│ (\u001b[38;5;33mSequenceEncoderUint\u001b[0m)           │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_1          │ ?                         │  \u001b[38;5;34m1,579,236\u001b[0m │\n",
              "│ (\u001b[38;5;33mBracketEncoderUnit\u001b[0m)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_2          │ ?                         │  \u001b[38;5;34m1,579,236\u001b[0m │\n",
              "│ (\u001b[38;5;33mBracketEncoderUnit\u001b[0m)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_3          │ ?                         │  \u001b[38;5;34m1,579,236\u001b[0m │\n",
              "│ (\u001b[38;5;33mBracketEncoderUnit\u001b[0m)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_4          │ ?                         │  \u001b[38;5;34m1,579,236\u001b[0m │\n",
              "│ (\u001b[38;5;33mBracketEncoderUnit\u001b[0m)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_5          │ ?                         │  \u001b[38;5;34m1,579,236\u001b[0m │\n",
              "│ (\u001b[38;5;33mBracketEncoderUnit\u001b[0m)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ bracket_encoder_unit_6          │ ?                         │  \u001b[38;5;34m1,579,236\u001b[0m │\n",
              "│ (\u001b[38;5;33mBracketEncoderUnit\u001b[0m)            │                           │            │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dense_78 (\u001b[38;5;33mDense\u001b[0m)                │ ?                         │        \u001b[38;5;34m514\u001b[0m │\n",
              "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,005,354</span> (76.31 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,005,354\u001b[0m (76.31 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,005,354</span> (76.31 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,005,354\u001b[0m (76.31 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CY7NhElf6rOw"
      },
      "outputs": [],
      "source": [
        "class CustomMetric2A3(keras.metrics.Metric):\n",
        "\n",
        "    def __init__(self,**kwargs):\n",
        "\n",
        "        super(CustomMetric2A3,self).__init__(**kwargs)\n",
        "        self.mae = self.add_weight(name=\"mae\",initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "\n",
        "        y_true = tf.clip_by_value(y_true[...,0],clip_value_max=1,clip_value_min=0)\n",
        "        y_pred = tf.clip_by_value(y_pred[...,0],clip_value_max=1,clip_value_min=0)\n",
        "        mae = tf.abs(tf.subtract(y_true,y_pred))\n",
        "        mae = tf.reduce_mean(mae[~tf.math.is_nan(mae)])\n",
        "        self.mae.assign_add(mae)\n",
        "\n",
        "\n",
        "    def result(self):\n",
        "        return self.mae\n",
        "\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mae.assign(0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kMe2rx9L6n5V"
      },
      "outputs": [],
      "source": [
        "class CustomMetricDMS(keras.metrics.Metric):\n",
        "\n",
        "    def __init__(self,**kwargs):\n",
        "\n",
        "        super(CustomMetricDMS,self).__init__(**kwargs)\n",
        "        self.mae = self.add_weight(name=\"mae\",initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "\n",
        "        y_true = tf.clip_by_value(y_true[...,1],clip_value_min=0,clip_value_max=1)\n",
        "        y_pred = tf.clip_by_value(y_pred[...,1],clip_value_max=1,clip_value_min=0)\n",
        "        mae = tf.abs(tf.subtract(y_true,y_pred))\n",
        "        mae = tf.reduce_mean(mae[~tf.math.is_nan(mae)])\n",
        "        self.mae.assign_add(mae)\n",
        "\n",
        "    def result(self):\n",
        "        return self.mae\n",
        "\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mae.assign(0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HrmEuYl86lxy"
      },
      "outputs": [],
      "source": [
        "class CustomLoss(keras.losses.Loss):\n",
        "\n",
        "    def __init__(self,**kwargs):\n",
        "\n",
        "        super(CustomLoss,self).__init__(**kwargs)\n",
        "\n",
        "    def __call__(self,y_true,y_pred,sample_weight=None):\n",
        "\n",
        "        y_true = tf.clip_by_value(y_true,clip_value_max=1,clip_value_min=0)\n",
        "        y_pred = tf.clip_by_value(y_pred,clip_value_max=1,clip_value_min=0)\n",
        "        mae_loss = tf.reduce_mean(tf.abs(tf.subtract(y_true,y_pred)),axis=-1)\n",
        "        return tf.reduce_mean(mae_loss[~tf.math.is_nan(mae_loss)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvxJ3dK0L0xk",
        "outputId": "76684afa-ba6a-45ef-b680-dc9a73b928cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:        0.51130915\n",
            "Metric 2A3:  0.33561227\n",
            "Metric DMS:  0.6870061\n"
          ]
        }
      ],
      "source": [
        "cust_loss= CustomLoss()\n",
        "cust_metric_2a3 = CustomMetric2A3()\n",
        "cust_metric_dms = CustomMetricDMS()\n",
        "cust_metric_2a3.update_state(y,transformer_out)\n",
        "cust_metric_dms.update_state(y,transformer_out)\n",
        "print(\"Loss:       \",cust_loss(y,transformer_out).numpy())\n",
        "print(\"Metric 2A3: \",cust_metric_2a3.result().numpy())\n",
        "print(\"Metric DMS: \",cust_metric_dms.result().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hGDktSFseHWv"
      },
      "outputs": [],
      "source": [
        "class ExpLR(keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self,factor,**kwargs):\n",
        "\n",
        "        super(ExpLR,self).__init__(**kwargs)\n",
        "        self.factor = factor\n",
        "        self.rates = []\n",
        "        self.losses = []\n",
        "\n",
        "    def on_epoch_begin(self,epoch,logs=None):\n",
        "        self.sum_of_epoch_losses = 0\n",
        "\n",
        "    def on_batch_end(self,batch,logs=None):\n",
        "        mean_epoch_loss = logs[\"loss\"]\n",
        "        new_sum_of_epoch_losses = mean_epoch_loss * (batch+1)\n",
        "        batch_loss = new_sum_of_epoch_losses - self.sum_of_epoch_losses\n",
        "        self.sum_of_epoch_losses = new_sum_of_epoch_losses\n",
        "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
        "        self.losses.append(batch_loss)\n",
        "        K.set_value(self.model.optimizer.learning_rate,self.model.optimizer.learning_rate* self.factor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "LCp5tJKpeHWv"
      },
      "outputs": [],
      "source": [
        "def find_learning_rate(model,ds:tf.data.Dataset,iterations:int,batch_size:int,epochs=1,min_rate:float=1e-7,max_rate:float=1):\n",
        "\n",
        "    init_weights = model.get_weights()\n",
        "    total_iterations = iterations * epochs\n",
        "    steps_per_epoch = iterations//batch_size\n",
        "    factor = (max_rate/min_rate) ** (1/total_iterations)\n",
        "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
        "    K.set_value(model.optimizer.learning_rate,min_rate)\n",
        "    exp_lr = ExpLR(factor)\n",
        "    history = model.fit(ds,epochs=epochs,steps_per_epoch=steps_per_epoch,callbacks=[exp_lr])\n",
        "    return exp_lr.rates,exp_lr.losses,init_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    model = Transformer()\n",
        "    optimizer = keras"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
