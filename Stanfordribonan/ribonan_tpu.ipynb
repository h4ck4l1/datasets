{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bismillah Hirrahamaa Nirraheem\n"
     ]
    }
   ],
   "source": [
    "print(\"Bismillah Hirrahamaa Nirraheem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,warnings,time,re,math\n",
    "from IPython.display import clear_output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "from concurrent.futures import ThreadPoolExecutor,ProcessPoolExecutor,wait\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Literal\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "from einops import rearrange\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch import nn\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "%matplotlib inline\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu_cluster = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu_cluster)\n",
    "    tf.config.experimental_connect_to_cluster(tpu_cluster)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu_cluster)\n",
    "    details = None\n",
    "    device = \"TPU\"\n",
    "if any(device.device_type == \"GPU\" for device in tf.config.list_physical_devices()):\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"GPU\")\n",
    "    device = \"GPU\"\n",
    "    details = tf.config.experimental.get_device_details(tf.config.list_physical_devices(\"GPU\")[0])\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"CPU\")\n",
    "    device = \"CPU\"\n",
    "    details = tf.config.experimental.get_device_details(tf.config.list_physical_devices(\"CPU\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"gs://stanfordrna/ribo/train_*.tfrecord\"\n",
    "total_files = tf.io.gfile.glob(PATH)\n",
    "train_files = total_files[:150]\n",
    "val_files = total_files[150:160]\n",
    "test_files = total_files[160:]\n",
    "train_raw_ds = tf.data.TFRecordDataset(train_files,compression_type=\"GZIP\")\n",
    "val_raw_ds = tf.data.TFRecordDataset(val_files,compression_type=\"GZIP\")\n",
    "test_raw_ds = tf.data.TFRecordDataset(test_files,compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_feature = dict(\n",
    "    seq_id = tf.io.FixedLenFeature([],tf.string),\n",
    "    seq = tf.io.VarLenFeature(tf.string),\n",
    "    dataset_name_2a3 = tf.io.FixedLenFeature([],tf.string),\n",
    "    dataset_name_dms = tf.io.FixedLenFeature([],tf.string),\n",
    "    reads_2a3 = tf.io.FixedLenFeature([],tf.string),\n",
    "    reads_dms = tf.io.FixedLenFeature([],tf.string),\n",
    "    signal_to_noise_2a3 = tf.io.FixedLenFeature([],tf.string),\n",
    "    signal_to_noise_dms = tf.io.FixedLenFeature([],tf.string),\n",
    "    reactivity_2a3 = tf.io.VarLenFeature(tf.string),\n",
    "    reactivity_dms = tf.io.VarLenFeature(tf.string),\n",
    "    reactivity_error_2a3 = tf.io.VarLenFeature(tf.string),\n",
    "    reactivity_error_dms = tf.io.VarLenFeature(tf.string),\n",
    "    sn_filter_2a3 = tf.io.FixedLenFeature([],tf.string),\n",
    "    sn_filter_dms = tf.io.FixedLenFeature([],tf.string),\n",
    "    length = tf.io.FixedLenFeature([],tf.string),\n",
    "    bpp_matrix = tf.io.VarLenFeature(tf.string),\n",
    "    bracket_seq = tf.io.VarLenFeature(tf.string)\n",
    "    )\n",
    "\n",
    "def rna_example(example):\n",
    "    example = tf.io.parse_single_example(example, rna_feature)\n",
    "\n",
    "    ### Dense Features\n",
    "    example[\"seq_id\"] = tf.io.parse_tensor(example[\"seq_id\"], out_type=tf.string)\n",
    "    example[\"reads_2a3\"] = tf.io.parse_tensor(example[\"reads_2a3\"], out_type=tf.float32)\n",
    "    example[\"reads_dms\"] = tf.io.parse_tensor(example[\"reads_dms\"], out_type=tf.float32)\n",
    "    example[\"sn_filter_2a3\"] = tf.io.parse_tensor(example[\"sn_filter_2a3\"], out_type=tf.float32)\n",
    "    example[\"sn_filter_dms\"] = tf.io.parse_tensor(example[\"sn_filter_dms\"], out_type=tf.float32)\n",
    "    example[\"dataset_name_2a3\"] = tf.io.parse_tensor(example[\"dataset_name_2a3\"], out_type=tf.string)\n",
    "    example[\"dataset_name_dms\"] = tf.io.parse_tensor(example[\"dataset_name_dms\"], out_type=tf.string)\n",
    "    example[\"signal_to_noise_2a3\"] = tf.io.parse_tensor(example[\"signal_to_noise_2a3\"], out_type=tf.float32)\n",
    "    example[\"signal_to_noise_dms\"] = tf.io.parse_tensor(example[\"signal_to_noise_dms\"], out_type=tf.float32)\n",
    "    example[\"length\"] = tf.io.parse_tensor(example[\"length\"], out_type=tf.float32)\n",
    "\n",
    "    ### Sparse Features\n",
    "    example[\"seq\"] = tf.io.parse_tensor(tf.sparse.to_dense(example[\"seq\"])[0], out_type=tf.float32)\n",
    "    example[\"reactivity_2a3\"] = tf.io.parse_tensor(tf.sparse.to_dense(example[\"reactivity_2a3\"])[0], out_type=tf.float32)\n",
    "    example[\"reactivity_dms\"] = tf.io.parse_tensor(tf.sparse.to_dense(example[\"reactivity_dms\"])[0], out_type=tf.float32)\n",
    "    example[\"reactivity_error_2a3\"] = tf.io.parse_tensor(tf.sparse.to_dense(example[\"reactivity_error_2a3\"])[0], out_type=tf.float32)\n",
    "    example[\"reactivity_error_dms\"] = tf.io.parse_tensor(tf.sparse.to_dense(example[\"reactivity_error_dms\"])[0], out_type=tf.float32)\n",
    "    example[\"bpp_matrix\"] = tf.io.parse_tensor(tf.sparse.to_dense(example[\"bpp_matrix\"])[0], out_type=tf.float32)\n",
    "    example[\"bracket_seq\"] = tf.io.parse_tensor(tf.sparse.to_dense(example[\"bracket_seq\"])[0], out_type=tf.float32)\n",
    "\n",
    "    return example\n",
    "\n",
    "train_modified_ds = train_raw_ds.map(rna_example, tf.data.AUTOTUNE)\n",
    "val_modified_ds = val_raw_ds.map(rna_example, tf.data.AUTOTUNE)\n",
    "test_modified_ds = test_raw_ds.map(rna_example, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id  :  b'8cdfeef009ea'\n",
      "\n",
      "\n",
      "\n",
      "seq  :  [3. 3. 3. 0. 0. 2. 3. 0. 2. 4. 2. 3. 0. 3. 4. 0. 3. 0. 3. 4.]\n",
      "seq shape : (170,)\n",
      "\n",
      "\n",
      "\n",
      "dataset_name_2a3  :  b'15k_2A3'\n",
      "\n",
      "\n",
      "\n",
      "dataset_name_dms  :  b'15k_DMS'\n",
      "\n",
      "\n",
      "\n",
      "reads_2a3 :  2343.0\n",
      "\n",
      "\n",
      "\n",
      "reads_dms :  1668.0\n",
      "\n",
      "\n",
      "\n",
      "signal_to_noise_2a3 :  0.944\n",
      "\n",
      "\n",
      "\n",
      "signal_to_noise_dms :  0.972\n",
      "\n",
      "\n",
      "\n",
      "reactivity_2a3  :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "shape of reactivity_2a3 : (206,)\n",
      "\n",
      "\n",
      "\n",
      "reactivity_dms  :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "shape of reactivity_dms : (206,)\n",
      "\n",
      "\n",
      "\n",
      "reactivity_error_2a3 :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "shape of reactivity_error_2a3 (206,)\n",
      "\n",
      "\n",
      "\n",
      "reactivity_error_dms :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "shape of reactivity_error_dms (206,)\n",
      "\n",
      "\n",
      "\n",
      "sn_filter_2a3 :  0.0\n",
      "\n",
      "\n",
      "\n",
      "sn_filter_dms :  0.0\n",
      "\n",
      "\n",
      "\n",
      "Lenght : 170.0\n",
      "\n",
      "\n",
      "\n",
      "bpp_matrix : [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "bpp_matrix shape : (170, 170)\n",
      "\n",
      "\n",
      "\n",
      "bracket_sequence : [8. 8. 8. 8. 8. 0. 0. 0. 0. 0. 0. 8. 8. 8. 8. 8. 1. 1. 1. 1.]\n",
      "bracket_sequence shape : (170,)\n"
     ]
    }
   ],
   "source": [
    "single_example = train_modified_ds.take(1).get_single_element()\n",
    "print(\"id\",\" : \",single_example[\"seq_id\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"seq\",\" : \",single_example[\"seq\"].numpy()[:20])\n",
    "print(\"seq shape :\",single_example[\"seq\"].numpy().shape)\n",
    "print(\"\\n\\n\")\n",
    "print(\"dataset_name_2a3\",\" : \",single_example[\"dataset_name_2a3\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"dataset_name_dms\",\" : \",single_example[\"dataset_name_dms\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"reads_2a3\",\": \",single_example[\"reads_2a3\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"reads_dms\",\": \",single_example[\"reads_dms\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"signal_to_noise_2a3\",\": \",single_example[\"signal_to_noise_2a3\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"signal_to_noise_dms\",\": \",single_example[\"signal_to_noise_dms\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"reactivity_2a3\",\" : \",single_example[\"reactivity_2a3\"].numpy()[:20])\n",
    "print(\"shape of reactivity_2a3 :\",single_example[\"reactivity_2a3\"].shape)\n",
    "print(\"\\n\\n\")\n",
    "print(\"reactivity_dms\",\" : \",single_example[\"reactivity_dms\"].numpy()[:20])\n",
    "print(\"shape of reactivity_dms :\",single_example[\"reactivity_dms\"].shape)\n",
    "print(\"\\n\\n\")\n",
    "print(\"reactivity_error_2a3\",\": \",single_example[\"reactivity_error_2a3\"].numpy()[:20])\n",
    "print(\"shape of reactivity_error_2a3\",single_example[\"reactivity_error_2a3\"].shape)\n",
    "print(\"\\n\\n\")\n",
    "print(\"reactivity_error_dms\",\": \",single_example[\"reactivity_error_dms\"].numpy()[:20])\n",
    "print(\"shape of reactivity_error_dms\",single_example[\"reactivity_error_dms\"].shape)\n",
    "print(\"\\n\\n\")\n",
    "print(\"sn_filter_2a3\",\": \",single_example[\"sn_filter_2a3\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"sn_filter_dms\",\": \",single_example[\"sn_filter_dms\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"Lenght :\",single_example[\"length\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"bpp_matrix :\",single_example[\"bpp_matrix\"].numpy()[:5,:5])\n",
    "print(\"bpp_matrix shape :\",single_example[\"bpp_matrix\"].numpy().shape)\n",
    "print(\"\\n\\n\")\n",
    "print(\"bracket_sequence :\",single_example[\"bracket_seq\"].numpy()[:20])\n",
    "print('bracket_sequence shape :',single_example[\"bracket_seq\"].numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "seq_map = {\"A\":1,\"C\":2,\"G\":3,\"U\":4,\"START\":4,\"END\":5,\"EMPTY\":0}\n",
    "bracket_map = {\"(\":1,\")\":2,\"[\":3,\"]\":4,\"{\":5,\"}\":6,\"<\":7,\">\":8,\".\":9,\"START\":10,\"END\":11,\"EMPTY\":0}\n",
    "\n",
    "def convert_and_pad(ex,Lmax:int=206,shift=True,sn_filter:bool=True):\n",
    "\n",
    "    l = tf.shape(ex[\"seq\"],tf.int32)[0]\n",
    "\n",
    "    if not shift:\n",
    "        shift = 0\n",
    "    else:\n",
    "        shift = tf.random.uniform(shape=[1],minval=0,maxval=Lmax-l+1,dtype=tf.int32)[0]\n",
    "\n",
    "    # Sequence Processing and Mask Processing\n",
    "    seq = ex[\"seq\"] + 1\n",
    "    mask = tf.math.greater(tf.pad(seq,[[shift+1,Lmax-l-shift+1]]),0)\n",
    "    seq = tf.pad(seq,[[1,0]],constant_values=seq_map[\"START\"])                               # seq_map[\"START\"]\n",
    "    seq = tf.pad(seq,[[0,1]],constant_values=seq_map[\"END\"])                                 # seq_map[\"END\"]\n",
    "    seq = tf.pad(seq,[[shift,Lmax-l-shift]])                                                 # seq_map[\"EMPTY\"]\n",
    "    forward_mask = tf.math.greater(seq,0)\n",
    "\n",
    "\n",
    "    # Bracket Processing\n",
    "    brac = ex[\"bracket_seq\"] + 1\n",
    "    brac = tf.pad(brac,[[1,0]],constant_values=bracket_map[\"START\"])                            # bracket_map[\"START\"]\n",
    "    brac = tf.pad(brac,[[0,1]],constant_values=bracket_map[\"END\"])                              # bracket_map[\"END\"]\n",
    "    brac = tf.pad(brac,[[shift,Lmax-l-shift]],constant_values=bracket_map[\"EMPTY\"])             # bracket_map[\"EMPTY\"]\n",
    "\n",
    "    # Reactivity Processing\n",
    "    reac = tf.stack([ex[\"reactivity_2a3\"][:l],ex[\"reactivity_dms\"][:l]],axis=-1)\n",
    "    reac = tf.pad(reac,[[shift+1,Lmax+1-l-shift],[0,0]],constant_values=np.nan)\n",
    "\n",
    "    # SN_filter\n",
    "    sn = (ex[\"sn_filter_2a3\"] > 0) & (ex[\"sn_filter_dms\"] > 0)\n",
    "\n",
    "    # BPPMatrix\n",
    "    bppm = ex[\"bpp_matrix\"][:l,:l]\n",
    "    bppm = tf.pad(bppm,[[shift+1,Lmax+1-l-shift],[shift+1,Lmax+1-l-shift]])\n",
    "\n",
    "    if sn_filter:\n",
    "        return (seq,brac,mask,forward_mask,sn,bppm),(reac,mask)\n",
    "    return (seq,brac,mask,forward_mask,bppm),(reac,mask)\n",
    "\n",
    "\n",
    "BATCH_SIZE = strategy.num_replicas_in_sync * 16 if (device == \"TPU\") else 32\n",
    "\n",
    "\n",
    "def create_train_ds(dataset,batch_size:int=BATCH_SIZE):\n",
    "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(20000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "def create_val_ds(dataset,batch_size:int=BATCH_SIZE):\n",
    "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.cache()\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "def create_test_ds(dataset,batch_size:int=BATCH_SIZE):\n",
    "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "train_ds = create_train_ds(train_modified_ds,batch_size=BATCH_SIZE)\n",
    "val_ds = create_val_ds(val_modified_ds,batch_size=BATCH_SIZE)\n",
    "test_ds = create_test_ds(test_modified_ds,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = train_ds.take(1).get_single_element()\n",
    "seq_input = X[0]\n",
    "bracket_input = X[1]\n",
    "mask = X[2]\n",
    "forward_mask = X[3]\n",
    "sn_filter = X[4]\n",
    "bpp_matrix = X[5]\n",
    "reactivity = y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Metrics and Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMetric2A3(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "        super(CustomMetric2A3,self).__init__(**kwargs)\n",
    "        self.mae = self.add_weight(name=\"mae_2a3_metric\",initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self,y_true,y_pred, **kwargs):\n",
    "        y_mask_metric = y_true[1]\n",
    "        y_true_metric = y_true[0][...,0]\n",
    "        y_pred_metric = y_pred[...,0]\n",
    "        y_pred_metric = tf.clip_by_value(y_pred_metric[y_mask_metric],clip_value_min=0,clip_value_max=1)\n",
    "        y_true_metric = tf.clip_by_value(y_true_metric[y_mask_metric],clip_value_min=0,clip_value_max=1)\n",
    "        mae = tf.abs(tf.subtract(y_true_metric,y_pred_metric))\n",
    "        mae = tf.reduce_mean(mae[~tf.math.is_nan(mae)])\n",
    "        self.mae.assign_add(mae)\n",
    "\n",
    "    def result(self):\n",
    "        return self.mae\n",
    "    \n",
    "    def reset_state(self):\n",
    "        return self.mae.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMetricDMS(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "        super(CustomMetricDMS,self).__init__(**kwargs)\n",
    "        self.mae = self.add_weight(name=\"mae_dms_metric\",initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self,y_true,y_pred, **kwargs):\n",
    "        y_mask_metric = y_true[1]\n",
    "        y_true_metric = y_true[0][...,1]\n",
    "        y_pred_metric = y_pred[...,1]\n",
    "        y_pred_metric = tf.clip_by_value(y_pred_metric[y_mask_metric],clip_value_min=0,clip_value_max=1)\n",
    "        y_true_metric = tf.clip_by_value(y_true_metric[y_mask_metric],clip_value_min=0,clip_value_max=1)\n",
    "        mae = tf.abs(tf.subtract(y_true_metric,y_pred_metric))\n",
    "        mae = tf.reduce_mean(mae[~tf.math.is_nan(mae)])\n",
    "        self.mae.assign_add(mae)\n",
    "\n",
    "    def result(self):\n",
    "        return self.mae\n",
    "    \n",
    "    def reset_state(self):\n",
    "        return self.mae.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4628213\n",
      "0.48597777\n"
     ]
    }
   ],
   "source": [
    "cust_metric_2a3 = CustomMetric2A3()\n",
    "cust_metric_dms = CustomMetricDMS()\n",
    "y_pred = tf.random.uniform(shape=y[0].shape,minval=-1,maxval=2)\n",
    "cust_metric_2a3.update_state(y,y_pred)\n",
    "cust_metric_dms.update_state(y,y_pred)\n",
    "print(cust_metric_2a3.result().numpy())\n",
    "print(cust_metric_dms.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(keras.losses.Loss):\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "        super(CustomLoss,self).__init__(**kwargs)\n",
    "\n",
    "    def call(self,y_true,y_pred):\n",
    "        y_mask = tf.cast(y_true[1],tf.bool)\n",
    "        y_true = y_true[0]\n",
    "        y_pred = tf.clip_by_value(y_pred[y_mask],clip_value_min=0,clip_value_max=1)\n",
    "        y_true = tf.clip_by_value(y_true[y_mask],clip_value_max=1,clip_value_min=0)\n",
    "        mae = tf.reduce_mean(tf.math.abs(tf.math.subtract(y_true,y_pred)),axis=-1)\n",
    "        return tf.reduce_mean(mae[~tf.math.is_nan(mae)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47559246"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_loss = CustomLoss()\n",
    "cust_loss(y,y_pred).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticPosEncoding(keras.layers.Layer):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size:int,\n",
    "            d_model:int=512,\n",
    "            length:int=2048,\n",
    "            casting:Literal[\"concat\",\"interleave\"]=\"concat\",\n",
    "            **kwargs):\n",
    "        \n",
    "        super(StaticPosEncoding,self).__init__(**kwargs)\n",
    "\n",
    "        assert d_model%2 == 0,\"Depth of model(d_model) should be even\"\n",
    "\n",
    "        d_model = d_model//2\n",
    "        positions = np.arange(length)[:,np.newaxis]\n",
    "        angles = np.arange(d_model)[np.newaxis,:]/d_model\n",
    "        angles = 1/(10000**angles)\n",
    "        angle_rads = positions * angles\n",
    "        if casting == \"concat\":\n",
    "            encode = tf.concat([tf.sin(angle_rads),tf.cos(angle_rads)],axis=-1)\n",
    "        else:\n",
    "            encode = np.zeros(shape=[length,d_model])\n",
    "            encode[:,::2] = tf.sin(angle_rads)\n",
    "            encode[:,1::2] = tf.cos(angle_rads)\n",
    "        \n",
    "        self.encode = tf.cast(encode,tf.float32)\n",
    "        self.factor = tf.sqrt(tf.cast(d_model,tf.float32))\n",
    "        self.embedding_layer = keras.layers.Embedding(vocab_size,d_model*2,mask_zero=True)\n",
    "\n",
    "    def compute_mask(self, *args,**kwargs):\n",
    "        return self.embedding_layer.compute_mask(*args,**kwargs)\n",
    "    \n",
    "    def call(self,x):\n",
    "        seq_l = tf.shape(x)[1]\n",
    "        x = self.embedding_layer(x)\n",
    "        x *= self.factor\n",
    "        return x + self.encode[tf.newaxis,:seq_l,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 208, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_encode = StaticPosEncoding(vocab_size=len(seq_map))\n",
    "pos_encode_output = pos_encode(X[0])\n",
    "pos_encode_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 208, 512)\n",
      "(32, 6, 208, 208)\n"
     ]
    }
   ],
   "source": [
    "mha = keras.layers.MultiHeadAttention(num_heads=6,key_dim=512)\n",
    "attn_out,attn_scores = mha(query=pos_encode_output,key=pos_encode_output,value=pos_encode_output,return_attention_scores=True)\n",
    "print(attn_out.shape)\n",
    "print(attn_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 6, 208, 208)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 6, 208, 208])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = bpp_matrix[:,tf.newaxis,:,:]\n",
    "_ = keras.layers.Conv2D(filters=6,kernel_size=3,padding=\"same\",data_format=\"channels_first\")(_)\n",
    "_ = keras.layers.BatchNormalization()(_)\n",
    "print(_.shape)\n",
    "(attn_scores + _).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    ''' Scaled Dot-Product Attention '''\n",
    "\n",
    "    def __init__(self, temperature, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        attn = torch.matmul(q / self.temperature, k.transpose(2, 3))\n",
    "\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        attn = self.dropout(F.softmax(attn, dim=-1))\n",
    "        output = torch.matmul(attn, v)\n",
    "\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutedSelfAttention(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,num_heads:int=6,key_dim:int=512,**kwargs):\n",
    "\n",
    "        super(ConvolutedSelfAttention,self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = key_dim\n",
    "        self.depth = key_dim//num_heads\n",
    "        self.wq = keras.layers.Dense(key_dim)\n",
    "        self.wv = keras.layers.Dense(key_dim)\n",
    "        self.wk = keras.layers.Dense(key_dim)\n",
    "        self.factor = tf.math.rsqrt(tf.constant(key_dim,tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "    def call(self,query,convoluted,key=None,mask=None,return_attention_scores=False):\n",
    "\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        seq_l = tf.shape(query)[1]\n",
    "\n",
    "\n",
    "        k = query if key is not None else None\n",
    "        v = query\n",
    "\n",
    "        q = self.wq(q)\n",
    "        v = self.wv(v)\n",
    "        k = self.wk(k)\n",
    "\n",
    "        q = tf.reshape(q,shape=[batch_size,-1,self.num_heads,self.depth])\n",
    "        q = tf.transpose(q,perm=[0,2,1,3])\n",
    "        v = tf.reshape(v,shape=[batch_size,-1,self.num_heads,self.depth])\n",
    "        v = tf.transpose(v,perm=[0,2,1,3])\n",
    "        k = tf.reshape(k,shape=[batch_size,-1,self.num_heads,self.depth])\n",
    "        k = tf.transpose(k,perm=[0,2,1,3])\n",
    "\n",
    "        attention_scores = tf.matmul(q,k,transpose_b=True)\n",
    "        attention_scores += convoluted\n",
    "        attention_scores *= self.factor\n",
    "        attention_output = tf.matmul(attention_scores,v)\n",
    "\n",
    "\n",
    "\n",
    "        if return_attention_scores:\n",
    "            return attention_output,attention_scores\n",
    "        return attention_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 3407872 values, but the requested shape requires a multiple of 39936 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m208\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 3407872 values, but the requested shape requires a multiple of 39936 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "tf.reshape(a,shape=(32,208,6,-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
