{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bismillah Hirrahamaa Nirraheem\n"
     ]
    }
   ],
   "source": [
    "print(\"Bismillah Hirrahamaa Nirraheem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,warnings,time,re,math\n",
    "from IPython.display import clear_output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "from concurrent.futures import ThreadPoolExecutor,ProcessPoolExecutor,wait\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Literal\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "from einops import rearrange\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "%matplotlib inline\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu_cluster = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu_cluster)\n",
    "    tf.config.experimental_connect_to_cluster(tpu_cluster)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu_cluster)\n",
    "    details = None\n",
    "    device = \"TPU\"\n",
    "if any(device.device_type == \"GPU\" for device in tf.config.list_physical_devices()):\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"GPU\")\n",
    "    device = \"GPU\"\n",
    "    details = tf.config.experimental.get_device_details(tf.config.list_physical_devices(\"GPU\")[0])\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"CPU\")\n",
    "    device = \"CPU\"\n",
    "    details = tf.config.experimental.get_device_details(tf.config.list_physical_devices(\"CPU\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"gs://stanfordrna/ribo/train_*.tfrecord\"\n",
    "total_files = tf.io.gfile.glob(PATH)\n",
    "train_files = total_files[:150]\n",
    "val_files = total_files[150:160]\n",
    "test_files = total_files[160:]\n",
    "train_raw_ds = tf.data.TFRecordDataset(train_files,compression_type=\"GZIP\")\n",
    "val_raw_ds = tf.data.TFRecordDataset(val_files,compression_type=\"GZIP\")\n",
    "test_raw_ds = tf.data.TFRecordDataset(test_files,compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_feature = dict(\n",
    "    seq_id = tf.io.FixedLenFeature([],tf.string),\n",
    "    seq = tf.io.VarLenFeature(tf.string),\n",
    "    dataset_name_2a3 = tf.io.FixedLenFeature([],tf.string),\n",
    "    dataset_name_dms = tf.io.FixedLenFeature([],tf.string),\n",
    "    reads_2a3 = tf.io.FixedLenFeature([],tf.string),\n",
    "    reads_dms = tf.io.FixedLenFeature([],tf.string),\n",
    "    signal_to_noise_2a3 = tf.io.FixedLenFeature([],tf.string),\n",
    "    signal_to_noise_dms = tf.io.FixedLenFeature([],tf.string),\n",
    "    reactivity_2a3 = tf.io.VarLenFeature(tf.string),\n",
    "    reactivity_dms = tf.io.VarLenFeature(tf.string),\n",
    "    reactivity_error_2a3 = tf.io.VarLenFeature(tf.string),\n",
    "    reactivity_error_dms = tf.io.VarLenFeature(tf.string),\n",
    "    sn_filter_2a3 = tf.io.FixedLenFeature([],tf.string),\n",
    "    sn_filter_dms = tf.io.FixedLenFeature([],tf.string),\n",
    "    length = tf.io.FixedLenFeature([],tf.string),\n",
    "    bpp_matrix = tf.io.VarLenFeature(tf.string),\n",
    "    bracket_seq = tf.io.VarLenFeature(tf.string)\n",
    "    )\n",
    "\n",
    "def rna_example(example):\n",
    "    example = tf.io.parse_single_example(example, rna_feature)\n",
    "\n",
    "    ### Dense Features\n",
    "    example[\"seq_id\"] = tf.io.parse_tensor(example[\"seq_id\"], out_type=tf.string)\n",
    "    example[\"reads_2a3\"] = tf.io.parse_tensor(example[\"reads_2a3\"], out_type=tf.float32)\n",
    "    example[\"reads_dms\"] = tf.io.parse_tensor(example[\"reads_dms\"], out_type=tf.float32)\n",
    "    example[\"sn_filter_2a3\"] = tf.io.parse_tensor(example[\"sn_filter_2a3\"], out_type=tf.float32)\n",
    "    example[\"sn_filter_dms\"] = tf.io.parse_tensor(example[\"sn_filter_dms\"], out_type=tf.float32)\n",
    "    example[\"dataset_name_2a3\"] = tf.io.parse_tensor(example[\"dataset_name_2a3\"], out_type=tf.string)\n",
    "    example[\"dataset_name_dms\"] = tf.io.parse_tensor(example[\"dataset_name_dms\"], out_type=tf.string)\n",
    "    example[\"signal_to_noise_2a3\"] = tf.io.parse_tensor(example[\"signal_to_noise_2a3\"], out_type=tf.float32)\n",
    "    example[\"signal_to_noise_dms\"] = tf.io.parse_tensor(example[\"signal_to_noise_dms\"], out_type=tf.float32)\n",
    "    example[\"length\"] = tf.io.parse_tensor(example[\"length\"], out_type=tf.float32)\n",
    "\n",
    "    ### Sparse Features\n",
    "    example[\"seq\"] = tf.io.parse_tensor(tf.sparse.to_dense(example[\"seq\"])[0], out_type=tf.float32)\n",
    "    example[\"reactivity_2a3\"] = tf.io.parse_tensor(tf.sparse.to_dense(example[\"reactivity_2a3\"])[0], out_type=tf.float32)\n",
    "    example[\"reactivity_dms\"] = tf.io.parse_tensor(tf.sparse.to_dense(example[\"reactivity_dms\"])[0], out_type=tf.float32)\n",
    "    example[\"reactivity_error_2a3\"] = tf.io.parse_tensor(tf.sparse.to_dense(example[\"reactivity_error_2a3\"])[0], out_type=tf.float32)\n",
    "    example[\"reactivity_error_dms\"] = tf.io.parse_tensor(tf.sparse.to_dense(example[\"reactivity_error_dms\"])[0], out_type=tf.float32)\n",
    "    example[\"bpp_matrix\"] = tf.io.parse_tensor(tf.sparse.to_dense(example[\"bpp_matrix\"])[0], out_type=tf.float32)\n",
    "    example[\"bracket_seq\"] = tf.io.parse_tensor(tf.sparse.to_dense(example[\"bracket_seq\"])[0], out_type=tf.float32)\n",
    "\n",
    "    return example\n",
    "\n",
    "train_modified_ds = train_raw_ds.map(rna_example, tf.data.AUTOTUNE)\n",
    "val_modified_ds = val_raw_ds.map(rna_example, tf.data.AUTOTUNE)\n",
    "test_modified_ds = test_raw_ds.map(rna_example, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id  :  b'8cdfeef009ea'\n",
      "\n",
      "\n",
      "\n",
      "seq  :  [3. 3. 3. 0. 0. 2. 3. 0. 2. 4. 2. 3. 0. 3. 4. 0. 3. 0. 3. 4.]\n",
      "seq shape : (170,)\n",
      "\n",
      "\n",
      "\n",
      "dataset_name_2a3  :  b'15k_2A3'\n",
      "\n",
      "\n",
      "\n",
      "dataset_name_dms  :  b'15k_DMS'\n",
      "\n",
      "\n",
      "\n",
      "reads_2a3 :  2343.0\n",
      "\n",
      "\n",
      "\n",
      "reads_dms :  1668.0\n",
      "\n",
      "\n",
      "\n",
      "signal_to_noise_2a3 :  0.944\n",
      "\n",
      "\n",
      "\n",
      "signal_to_noise_dms :  0.972\n",
      "\n",
      "\n",
      "\n",
      "reactivity_2a3  :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "shape of reactivity_2a3 : (206,)\n",
      "\n",
      "\n",
      "\n",
      "reactivity_dms  :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "shape of reactivity_dms : (206,)\n",
      "\n",
      "\n",
      "\n",
      "reactivity_error_2a3 :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "shape of reactivity_error_2a3 (206,)\n",
      "\n",
      "\n",
      "\n",
      "reactivity_error_dms :  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "shape of reactivity_error_dms (206,)\n",
      "\n",
      "\n",
      "\n",
      "sn_filter_2a3 :  0.0\n",
      "\n",
      "\n",
      "\n",
      "sn_filter_dms :  0.0\n",
      "\n",
      "\n",
      "\n",
      "Lenght : 170.0\n",
      "\n",
      "\n",
      "\n",
      "bpp_matrix : [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "bpp_matrix shape : (170, 170)\n",
      "\n",
      "\n",
      "\n",
      "bracket_sequence : [8. 8. 8. 8. 8. 0. 0. 0. 0. 0. 0. 8. 8. 8. 8. 8. 1. 1. 1. 1.]\n",
      "bracket_sequence shape : (170,)\n"
     ]
    }
   ],
   "source": [
    "single_example = train_modified_ds.take(1).get_single_element()\n",
    "print(\"id\",\" : \",single_example[\"seq_id\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"seq\",\" : \",single_example[\"seq\"].numpy()[:20])\n",
    "print(\"seq shape :\",single_example[\"seq\"].numpy().shape)\n",
    "print(\"\\n\\n\")\n",
    "print(\"dataset_name_2a3\",\" : \",single_example[\"dataset_name_2a3\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"dataset_name_dms\",\" : \",single_example[\"dataset_name_dms\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"reads_2a3\",\": \",single_example[\"reads_2a3\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"reads_dms\",\": \",single_example[\"reads_dms\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"signal_to_noise_2a3\",\": \",single_example[\"signal_to_noise_2a3\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"signal_to_noise_dms\",\": \",single_example[\"signal_to_noise_dms\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"reactivity_2a3\",\" : \",single_example[\"reactivity_2a3\"].numpy()[:20])\n",
    "print(\"shape of reactivity_2a3 :\",single_example[\"reactivity_2a3\"].shape)\n",
    "print(\"\\n\\n\")\n",
    "print(\"reactivity_dms\",\" : \",single_example[\"reactivity_dms\"].numpy()[:20])\n",
    "print(\"shape of reactivity_dms :\",single_example[\"reactivity_dms\"].shape)\n",
    "print(\"\\n\\n\")\n",
    "print(\"reactivity_error_2a3\",\": \",single_example[\"reactivity_error_2a3\"].numpy()[:20])\n",
    "print(\"shape of reactivity_error_2a3\",single_example[\"reactivity_error_2a3\"].shape)\n",
    "print(\"\\n\\n\")\n",
    "print(\"reactivity_error_dms\",\": \",single_example[\"reactivity_error_dms\"].numpy()[:20])\n",
    "print(\"shape of reactivity_error_dms\",single_example[\"reactivity_error_dms\"].shape)\n",
    "print(\"\\n\\n\")\n",
    "print(\"sn_filter_2a3\",\": \",single_example[\"sn_filter_2a3\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"sn_filter_dms\",\": \",single_example[\"sn_filter_dms\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"Lenght :\",single_example[\"length\"].numpy())\n",
    "print(\"\\n\\n\")\n",
    "print(\"bpp_matrix :\",single_example[\"bpp_matrix\"].numpy()[:5,:5])\n",
    "print(\"bpp_matrix shape :\",single_example[\"bpp_matrix\"].numpy().shape)\n",
    "print(\"\\n\\n\")\n",
    "print(\"bracket_sequence :\",single_example[\"bracket_seq\"].numpy()[:20])\n",
    "print('bracket_sequence shape :',single_example[\"bracket_seq\"].numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "seq_map = {\"A\":1,\"C\":2,\"G\":3,\"U\":4,\"START\":4,\"END\":5,\"EMPTY\":0}\n",
    "bracket_map = {\"(\":1,\")\":2,\"[\":3,\"]\":4,\"{\":5,\"}\":6,\"<\":7,\">\":8,\".\":9,\"START\":10,\"END\":11,\"EMPTY\":0}\n",
    "\n",
    "def convert_and_pad(ex,Lmax:int=206,shift=True,sn_filter:bool=True):\n",
    "\n",
    "    l = tf.shape(ex[\"seq\"],tf.int32)[0]\n",
    "\n",
    "    if not shift:\n",
    "        shift = 0\n",
    "    else:\n",
    "        shift = tf.random.uniform(shape=[1],minval=0,maxval=Lmax-l+1,dtype=tf.int32)[0]\n",
    "\n",
    "    # Sequence Processing and Mask Processing\n",
    "    seq = ex[\"seq\"] + 1\n",
    "    mask = tf.math.greater(tf.pad(seq,[[shift+1,Lmax-l-shift+1]]),0)\n",
    "    seq = tf.pad(seq,[[1,0]],constant_values=seq_map[\"START\"])                               # seq_map[\"START\"]\n",
    "    seq = tf.pad(seq,[[0,1]],constant_values=seq_map[\"END\"])                                 # seq_map[\"END\"]\n",
    "    seq = tf.pad(seq,[[shift,Lmax-l-shift]])                                                 # seq_map[\"EMPTY\"]\n",
    "    forward_mask = tf.math.greater(seq,0)\n",
    "\n",
    "\n",
    "    # Bracket Processing\n",
    "    brac = ex[\"bracket_seq\"] + 1\n",
    "    brac = tf.pad(brac,[[1,0]],constant_values=bracket_map[\"START\"])                            # bracket_map[\"START\"]\n",
    "    brac = tf.pad(brac,[[0,1]],constant_values=bracket_map[\"END\"])                              # bracket_map[\"END\"]\n",
    "    brac = tf.pad(brac,[[shift,Lmax-l-shift]],constant_values=bracket_map[\"EMPTY\"])             # bracket_map[\"EMPTY\"]\n",
    "\n",
    "    # Reactivity Processing\n",
    "    reac = tf.stack([ex[\"reactivity_2a3\"][:l],ex[\"reactivity_dms\"][:l]],axis=-1)\n",
    "    reac = tf.pad(reac,[[shift+1,Lmax+1-l-shift],[0,0]],constant_values=np.nan)\n",
    "\n",
    "    # SN_filter\n",
    "    sn = (ex[\"sn_filter_2a3\"] > 0) & (ex[\"sn_filter_dms\"] > 0)\n",
    "\n",
    "    # BPPMatrix\n",
    "    bppm = ex[\"bpp_matrix\"][:l,:l]\n",
    "    bppm = tf.pad(bppm,[[shift+1,Lmax+1-l-shift],[shift+1,Lmax+1-l-shift]])\n",
    "\n",
    "    if sn_filter:\n",
    "        return (seq,brac,mask,forward_mask,sn,bppm),(reac,mask)\n",
    "    return (seq,brac,mask,forward_mask,bppm),(reac,mask)\n",
    "\n",
    "\n",
    "BATCH_SIZE = strategy.num_replicas_in_sync * 16 if (device == \"TPU\") else 32\n",
    "\n",
    "\n",
    "def create_train_ds(dataset,batch_size:int=BATCH_SIZE):\n",
    "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(20000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "def create_val_ds(dataset,batch_size:int=BATCH_SIZE):\n",
    "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.cache()\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "def create_test_ds(dataset,batch_size:int=BATCH_SIZE):\n",
    "    dataset = dataset.map(convert_and_pad,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "train_ds = create_train_ds(train_modified_ds,batch_size=BATCH_SIZE)\n",
    "val_ds = create_val_ds(val_modified_ds,batch_size=BATCH_SIZE)\n",
    "test_ds = create_test_ds(test_modified_ds,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence : tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [4. 4. 4. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 3. 5.]\n",
      " [0. 0. 4. ... 0. 0. 0.]], shape=(32, 208), dtype=float32)\n",
      "bracket sequence tf.Tensor(\n",
      "[[ 0.  0.  0. ...  0.  0.  0.]\n",
      " [10.  1.  1. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  9.  9. 11.]\n",
      " [ 0.  0. 10. ...  0.  0.  0.]], shape=(32, 208), dtype=float32)\n",
      "mask : tf.Tensor(\n",
      "[[False False False ... False False False]\n",
      " [False  True  True ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ...  True  True False]\n",
      " [False False False ... False False False]], shape=(32, 208), dtype=bool)\n",
      "forward mask : tf.Tensor(\n",
      "[[False False False ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ...  True  True  True]\n",
      " [False False  True ... False False False]], shape=(32, 208), dtype=bool)\n",
      "sn filter : tf.Tensor(\n",
      "[False False False  True False False False False  True False False False\n",
      "  True  True False False False False False False False False  True  True\n",
      " False False False False False  True  True False], shape=(32,), dtype=bool)\n",
      "bpp_matrix : tf.Tensor(\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]], shape=(32, 208, 208), dtype=float32)\n",
      "reactivity : tf.Tensor(\n",
      "[[[nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  ...\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]]\n",
      "\n",
      " [[nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  ...\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]]\n",
      "\n",
      " [[nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  ...\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  ...\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]]\n",
      "\n",
      " [[nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  ...\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]]\n",
      "\n",
      " [[nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  ...\n",
      "  [nan nan]\n",
      "  [nan nan]\n",
      "  [nan nan]]], shape=(32, 208, 2), dtype=float32)\n",
      "mask : tf.Tensor(\n",
      "[[False False False ... False False False]\n",
      " [False  True  True ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ...  True  True False]\n",
      " [False False False ... False False False]], shape=(32, 208), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "X,y = train_ds.take(1).get_single_element()\n",
    "print(\"sequence :\",X[0])\n",
    "print(\"bracket sequence\",X[1])\n",
    "print(\"mask :\",X[2])\n",
    "print(\"forward mask :\",X[3])\n",
    "print(\"sn filter :\",X[4])\n",
    "print(\"bpp_matrix :\",X[5])\n",
    "print(\"reactivity :\",y[0])\n",
    "print(\"mask :\",y[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Metrics and Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMetric2A3(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "        super(CustomMetric2A3,self).__init__(**kwargs)\n",
    "        self.mae = self.add_weight(name=\"mae_2a3_metric\",initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self,y_true,y_pred, **kwargs):\n",
    "        y_mask_metric = y_true[1]\n",
    "        y_true_metric = y_true[0][...,0]\n",
    "        y_pred_metric = y_pred[...,0]\n",
    "        y_pred_metric = tf.clip_by_value(y_pred_metric[y_mask_metric],clip_value_min=0,clip_value_max=1)\n",
    "        y_true_metric = tf.clip_by_value(y_true_metric[y_mask_metric],clip_value_min=0,clip_value_max=1)\n",
    "        mae = tf.abs(tf.subtract(y_true_metric,y_pred_metric))\n",
    "        mae = tf.reduce_mean(mae[~tf.math.is_nan(mae)])\n",
    "        self.mae.assign_add(mae)\n",
    "\n",
    "    def result(self):\n",
    "        return self.mae\n",
    "    \n",
    "    def reset_state(self):\n",
    "        return self.mae.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMetricDMS(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "        super(CustomMetricDMS,self).__init__(**kwargs)\n",
    "        self.mae = self.add_weight(name=\"mae_dms_metric\",initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self,y_true,y_pred, **kwargs):\n",
    "        y_mask_metric = y_true[1]\n",
    "        y_true_metric = y_true[0][...,1]\n",
    "        y_pred_metric = y_pred[...,1]\n",
    "        y_pred_metric = tf.clip_by_value(y_pred_metric[y_mask_metric],clip_value_min=0,clip_value_max=1)\n",
    "        y_true_metric = tf.clip_by_value(y_true_metric[y_mask_metric],clip_value_min=0,clip_value_max=1)\n",
    "        mae = tf.abs(tf.subtract(y_true_metric,y_pred_metric))\n",
    "        mae = tf.reduce_mean(mae[~tf.math.is_nan(mae)])\n",
    "        self.mae.assign_add(mae)\n",
    "\n",
    "    def result(self):\n",
    "        return self.mae\n",
    "    \n",
    "    def reset_state(self):\n",
    "        return self.mae.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48885757\n",
      "0.4869247\n"
     ]
    }
   ],
   "source": [
    "cust_metric_2a3 = CustomMetric2A3()\n",
    "cust_metric_dms = CustomMetricDMS()\n",
    "y_pred = tf.random.uniform(shape=y[0].shape,minval=-1,maxval=2)\n",
    "cust_metric_2a3.update_state(y,y_pred)\n",
    "cust_metric_dms.update_state(y,y_pred)\n",
    "print(cust_metric_2a3.result().numpy())\n",
    "print(cust_metric_dms.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(keras.losses.Loss):\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "        super(CustomLoss,self).__init__(**kwargs)\n",
    "\n",
    "    def call(self,y_true,y_pred):\n",
    "        y_mask = tf.cast(y_true[1],tf.bool)\n",
    "        y_true = y_true[0]\n",
    "        y_pred = tf.clip_by_value(y_pred[y_mask],clip_value_min=0,clip_value_max=1)\n",
    "        y_true = tf.clip_by_value(y_true[y_mask],clip_value_max=1,clip_value_min=0)\n",
    "        mae = tf.reduce_mean(tf.math.abs(tf.math.subtract(y_true,y_pred)),axis=-1)\n",
    "        return tf.reduce_mean(mae[~tf.math.is_nan(mae)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48638263"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_loss = CustomLoss()\n",
    "cust_loss(y,y_pred).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticPosEncoding(keras.layers.Layer):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size:int,\n",
    "            d_model:int=512,\n",
    "            length:int=2048,\n",
    "            casting:Literal[\"concat\",\"interleave\"]=\"concat\",\n",
    "            **kwargs):\n",
    "        \n",
    "        super(StaticPosEncoding,self).__init__(**kwargs)\n",
    "\n",
    "        assert d_model%2 == 0,\"Depth of model(d_model) should be even\"\n",
    "\n",
    "        d_model = d_model//2\n",
    "        positions = np.arange(length)[:,np.newaxis]\n",
    "        angles = np.arange(d_model)[np.newaxis,:]/d_model\n",
    "        angles = 1/(10000**angles)\n",
    "        angle_rads = positions * angles\n",
    "        if casting == \"concat\":\n",
    "            encode = tf.concat([tf.sin(angle_rads),tf.cos(angle_rads)],axis=-1)\n",
    "        else:\n",
    "            encode = np.zeros(shape=[length,d_model])\n",
    "            encode[:,::2] = tf.sin(angle_rads)\n",
    "            encode[:,1::2] = tf.cos(angle_rads)\n",
    "        \n",
    "        self.encode = tf.cast(encode,tf.float32)\n",
    "        self.factor = tf.sqrt(tf.cast(d_model,tf.float32))\n",
    "        self.embedding_layer = keras.layers.Embedding(vocab_size,d_model*2,mask_zero=True)\n",
    "\n",
    "    def compute_mask(self, *args,**kwargs):\n",
    "        return self.embedding_layer.compute_mask(*args,**kwargs)\n",
    "    \n",
    "    def call(self,x):\n",
    "        seq_l = tf.shape(x)[1]\n",
    "        x = self.embedding_layer(x)\n",
    "        x *= self.factor\n",
    "        return x + self.encode[tf.newaxis,:seq_l,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
