{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bismillah Hirrahamaa Nirraheem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(suppress=True)\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.templates['mod'] = go.layout.Template(layout=dict(font=dict(family=\"Fira Code\",size=20)))\n",
    "pio.templates.default = \"plotly_dark+mod\"\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,OrdinalEncoder,OneHotEncoder,RobustScaler\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier,BaggingClassifier,RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from miceforest import ImputationKernel\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score,confusion_matrix,roc_auc_score,roc_curve\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from missingno import matrix\n",
    "from zipfile import ZipFile\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c spaceship-titanic\n",
    "!mv spaceship-titanic.zip /home/sohail/Downloads/\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(file='/home/sohail/Downloads/spaceship-titanic.zip',mode=\"r\") as file:\n",
    "    file.extractall('/home/sohail/Downloads/spaceship-titanic-folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/sohail/Downloads/spaceship-titanic/train.csv')\n",
    "test = pd.read_csv('/home/sohail/Downloads/spaceship-titanic/test.csv')\n",
    "sample = pd.read_csv('/home/sohail/Downloads/spaceship-titanic/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table\n",
    "<font size=4>\n",
    "\n",
    "|SI.No|Name of Column|Description|\n",
    "|-----|--------------|-----------|\n",
    "|1|PassengerId|A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.|\n",
    "|2|HomePlanet|The planet the passenger departed from, typically their planet of permanent residence|\n",
    "|3|CryoSleep|Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins|\n",
    "|4|Cabin|The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.|\n",
    "|5|Destination|The planet the passenger will be debarking to|\n",
    "|6|Age|The age of the passenger|\n",
    "|7|VIP|Whether the passenger has paid for special VIP service during the voyage|\n",
    "|8|RoomService, FoodCourt, ShoppingMall, Spa, VRDeck|Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities|\n",
    "|9|Name|The first and last names of the passenger|\n",
    "|10|Transported| Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict|\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling Nan's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as you can see there are quite a bit of Null values which need to be filled, we can apply some stratergies as we will see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_1(data:pd.DataFrame):\n",
    "    df = data.copy()\n",
    "    df[['CryoSleep','VIP']] = df[['CryoSleep','VIP']].astype(np.float32)\n",
    "    df[['Group','Within']] = df.PassengerId.str.split('_',expand=True).astype(np.float32)\n",
    "    df = df[df.columns[-2:].to_list()+df.columns[1:-2].to_list()]\n",
    "    df[['deck','num','side']] = df.Cabin.str.split('/',expand=True)\n",
    "    df = df[df.columns[:4].to_list() + df.columns[-3:].to_list() + df.columns[5:-3].to_list()]\n",
    "    df['num'] = df['num'].astype(np.float32)\n",
    "    df[['First','Last']] = df.Name.str.split(' ',expand=True)\n",
    "    df = df[df.columns[:2].to_list() + df.columns[-2:].to_list() + df.columns[2:-2].to_list()]\n",
    "    df.drop('Name',axis=1,inplace=True)\n",
    "    return df.infer_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = preprocess_1(train)\n",
    "total_test = preprocess_1(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.concat([total_train,total_test])\n",
    "y_total = total_df[['Transported']]\n",
    "total_df.drop('Transported',axis=1,inplace=True)\n",
    "total_df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Group','Within','num','Age','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
    "cat_cols = ['HomePlanet','CryoSleep','deck','side','Destination','VIP']\n",
    "last_cols = ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
    "all_cats = []\n",
    "for col in cat_cols:\n",
    "    all_cats += total_df[col].dropna().unique().tolist()\n",
    "all_cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Group, Within don't have any null values as they are from PassengerId column<br>\n",
    "<br>\n",
    "<font size=8>\n",
    "Strategy :\n",
    "</font>\n",
    "\n",
    "- The strategy is to first fill null values according to the first and last names of the passengers as they are the closest relations for null values\n",
    "- The First,Last columns also have null values so for the columns with null we will impute the most recurrent in terms of categorical column\n",
    "- Then Look for the best predictors for single na values and impute those\n",
    "- The impute the doubly filled columns with clustering/normal imputation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "matrix(total_df,color=(99/250,110/250,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_no_na = total_df.dropna()\n",
    "total_na = total_df[total_df.isna().any(axis=1)]\n",
    "print(\"No NaN shape\",total_no_na.shape)\n",
    "print(\"any NaN shape\",total_na.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.get_dummies(total_no_na,columns=['HomePlanet','deck','side','Destination'],prefix=\"\",prefix_sep=\"\",dtype=np.float32)\n",
    "temp_df = temp_df.loc[:,temp_df.columns.difference(['First','Last'])].corr(method='spearman')\n",
    "np.fill_diagonal(temp_df.to_numpy(),0)\n",
    "px.imshow(temp_df,height=1000,width=1800).update_xaxes(tickangle=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filling the values with same First Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before filling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before filling :\")\n",
    "print(\"no of single vacant rows :\",total_df.loc[(total_df.isna().sum(axis=1) == 1)].shape[0])\n",
    "print(\"no of double vacant rows :\",total_df.loc[(total_df.isna().sum(axis=1) == 2)].shape[0])\n",
    "print(\"no of triple vacant rows :\",total_df.loc[(total_df.isna().sum(axis=1) == 3)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in total_na.index:\n",
    "    col = total_na.columns[total_na.loc[ind].isna()]\n",
    "    temp_df = total_no_na.query(f\"Group == {total_na.loc[ind,'Group']} and Last == '{total_na.loc[ind,'Last']}'\")\n",
    "    if temp_df.shape[0] != 0:\n",
    "        total_df.loc[ind,col] = temp_df.loc[temp_df.index[0],col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"after filling :\")\n",
    "print(\"no of single vacant rows :\",total_df.loc[(total_df.isna().sum(axis=1) == 1)].shape[0])\n",
    "print(\"no of double vacant rows :\",total_df.loc[(total_df.isna().sum(axis=1) == 2)].shape[0])\n",
    "print(\"no of triple vacant rows :\",total_df.loc[(total_df.isna().sum(axis=1) == 3)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_no_na = total_df.dropna()\n",
    "total_na = total_df[total_df.isna().any(axis=1)]\n",
    "print(\"No NaN shape\",total_no_na.shape)\n",
    "print(\"any NaN shape\",total_na.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_na.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.get_dummies(total_no_na,columns=['HomePlanet','deck','side','Destination'],prefix=\"\",prefix_sep=\"\",dtype=np.float32)\n",
    "temp_df = temp_df.drop(['First','Last'],axis=1).corr(method='spearman')\n",
    "np.fill_diagonal(temp_df.to_numpy(),0)\n",
    "px.imshow(temp_df,height=1000,width=1800).update_xaxes(tickangle=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = total_df.drop(['First','Last'],axis=1)\n",
    "temp_df = pd.get_dummies(temp_df,columns=['HomePlanet','side','deck','Destination'],prefix_sep=\"\",prefix=\"\",dtype=np.float32)\n",
    "kds = ImputationKernel(temp_df.drop(['Group','Within','num'],axis=1),random_state=55,save_all_iterations=True,datasets=4)\n",
    "kds.mice(10,n_estimators=100,device=\"gpu\")\n",
    "new_data = kds.complete_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = new_data.loc[:8692].copy()\n",
    "test_set = new_data.loc[8693:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_scale = RobustScaler()\n",
    "rob_scale.set_output(transform='pandas')\n",
    "rob_temp = rob_scale.fit_transform(train_set[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']])\n",
    "rob_temp.RoomService.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,X_test,y_train,y_test = train_test_split(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train.num.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TotalTransform(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self,train=True):\n",
    "        self.train = train\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for corr() coefficient\n",
    "# arr1 = np.random.randint(20,40,30)\n",
    "# arr2 = np.random.randint(1,20,30)\n",
    "# temp_df = pd.DataFrame(np.hstack([arr1,arr2]),columns=[\"num\"])\n",
    "# temp_df.loc[:30,'choice'] = 0\n",
    "# temp_df.loc[30:,'choice'] = 1\n",
    "# temp_df.corr()\n",
    "# check for same deck,num,side in total_na\n",
    "# num = 2\n",
    "# total_no_na.query(f\"Last == '{total_na.query('deck != deck').Last.iloc[num]}' and Group == {total_na.query('deck != deck').Group.iloc[num]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
