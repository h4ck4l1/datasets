{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5xEiGjRP7m6sY9n/8ilnk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h4ck4l1/datasets/blob/main/NLP_with_RNN_and_Attention/NMT_with_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xHJa_8IeCwTX"
      },
      "outputs": [],
      "source": [
        "import os,warnings\n",
        "from IPython.display import clear_output\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "!pip3 install -q -U \"tensorflow-text==2.13.0\"\n",
        "!pip3 install -q -U einops\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_text as tf_text\n",
        "np.printoptions(precision=2)\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "pio.templates.default = \"plotly_dark\"\n",
        "import einops\n",
        "from zipfile import ZipFile\n",
        "from typing import Any\n",
        "# %xmode Minimal\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "origin = \"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
        "file_path = keras.utils.get_file(fname=\"spa-eng.zip\",origin=origin,extract=True)\n",
        "with ZipFile(file_path,\"r\") as f:\n",
        "    f.extractall(\"spa-eng\")\n",
        "with open(\"spa-eng/spa-eng/spa.txt\",\"r\") as f:\n",
        "    text = f.read()\n",
        "en_text,es_text = zip(*[line.split(\"\\t\") for line in text.splitlines()])\n",
        "for en,es in zip(en_text[:10],es_text[:10]):\n",
        "    print(en,\"---->\",es)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id5fVBZMgo8Q",
        "outputId": "c273ed5a-734c-4b45-a039-56c8fa3f64ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go. ----> Ve.\n",
            "Go. ----> Vete.\n",
            "Go. ----> Vaya.\n",
            "Go. ----> Váyase.\n",
            "Hi. ----> Hola.\n",
            "Run! ----> ¡Corre!\n",
            "Run. ----> Corred.\n",
            "Who? ----> ¿Quién?\n",
            "Fire! ----> ¡Fuego!\n",
            "Fire! ----> ¡Incendio!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocess(sentence:str):\n",
        "    sentence = tf_text.normalize_utf8(sentence,\"NFKD\")\n",
        "    sentence = tf.strings.lower(sentence)\n",
        "    sentence = tf.strings.regex_replace(sentence,r\"[^ a-z.,!?¿]\",\"\")\n",
        "    sentence = tf.strings.regex_replace(sentence,r\"[.,!?¿]\",r\" \\0 \")\n",
        "    sentence = tf.strings.strip(sentence)\n",
        "    sentence = tf.strings.join([\"[START]\",sentence,\"[END]\"],separator=\" \")\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "L-X_f9el6esj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_layers(vocab_size=5000):\n",
        "    en_vec_layer = keras.layers.TextVectorization(max_tokens=vocab_size,standardize=text_preprocess,ragged=True)\n",
        "    es_vec_layer = keras.layers.TextVectorization(max_tokens=vocab_size,standardize=text_preprocess,ragged=True)\n",
        "    en_vec_layer.adapt(en_text)\n",
        "    es_vec_layer.adapt(es_text)\n",
        "    return en_vec_layer,es_vec_layer"
      ],
      "metadata": {
        "id": "bARcJi8D_PHT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_vec_layer,es_vec_layer = get_layers(vocab_size=5000)"
      ],
      "metadata": {
        "id": "rVntjkub3yE5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(en_inputs,es_inputs):\n",
        "    en_inputs = en_vec_layer(en_inputs).to_tensor()\n",
        "    es_inputs = es_vec_layer(es_inputs).to_tensor()\n",
        "    return (en_inputs,es_inputs[:,:-1]),es_inputs[:,1:]"
      ],
      "metadata": {
        "id": "Av4bEWHDJO0i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "all_indices = np.random.uniform(size=len(en_text))\n",
        "train_indices = all_indices <= 0.8\n",
        "valid_indices = (all_indices > 0.8) & (all_indices <= 0.97)\n",
        "test_indices = all_indices > 0.97\n",
        "en_text = np.array(en_text)\n",
        "es_text = np.array(es_text)\n",
        "batch_size = 64\n",
        "train_size = len(train_indices)\n",
        "valid_size = len(valid_indices)\n",
        "train_ds = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((en_text[train_indices],es_text[train_indices]))\n",
        "    .shuffle(len(en_text))\n",
        "    .batch(batch_size)\n",
        "    .map(preprocess)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "valid_ds = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((en_text[valid_indices],es_text[valid_indices]))\n",
        "    .shuffle(len(en_text))\n",
        "    .batch(batch_size)\n",
        "    .map(preprocess)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "test_ds = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((en_text[test_indices],es_text[test_indices]))\n",
        "    .shuffle(len(en_text))\n",
        "    .batch(batch_size)\n",
        "    .map(preprocess)\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "metadata": {
        "id": "ZnJ8xsuyLJnB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,vec_layer: keras.layers.TextVectorization=en_vec_layer,units: int=256,**kwargs):\n",
        "\n",
        "        super(Encoder,self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.vec_layer = vec_layer\n",
        "        self.vocab_size = vec_layer.vocabulary_size()\n",
        "\n",
        "        self.embedder = keras.layers.Embedding(self.vocab_size,units,mask_zero=True)\n",
        "        self.encoder_unit = keras.layers.Bidirectional(keras.layers.LSTM(units,return_state=True,return_sequences=True,recurrent_initializer=\"glorot_uniform\"),merge_mode=\"sum\")\n",
        "\n",
        "    def call(self,encoder_inputs):\n",
        "\n",
        "        encoder_embedded_outputs = self.embedder(encoder_inputs)\n",
        "\n",
        "        encoder_outputs,*self.encoder_state = self.encoder_unit(encoder_embedded_outputs)\n",
        "\n",
        "        return encoder_outputs"
      ],
      "metadata": {
        "id": "ryWbLFERWQ-k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder()\n",
        "\n",
        "for en_in in train_ds.map(lambda x,y:x[0]).take(1):\n",
        "    print(encoder(en_in).shape)\n",
        "\n",
        "for en_in in valid_ds.map(lambda x,y:x[0]).take(1):\n",
        "    print(encoder(en_in).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvwOYJLerfhA",
        "outputId": "25856d7a-3be6-4b41-c720-1446a31b31b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 22, 256)\n",
            "(64, 15, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,vec_layer:keras.layers.TextVectorization=es_vec_layer,units:int=256,**kwargs):\n",
        "\n",
        "        super(Decoder,self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.vec_layer = vec_layer\n",
        "        self.vocab_size = vec_layer.vocabulary_size()\n",
        "\n",
        "        self.embedder = keras.layers.Embedding(self.vocab_size,units,mask_zero=True)\n",
        "        self.decoder_unit = keras.layers.LSTM(units,return_state=True,return_sequences=True,recurrent_initializer=\"glorot_uniform\")\n",
        "\n",
        "\n",
        "    def call(self,decoder_inputs,decoder_initial_state=None):\n",
        "\n",
        "\n",
        "        decoder_embedded_outputs = self.embedder(decoder_inputs)\n",
        "\n",
        "        decoder_outputs,*self.decoder_state = self.decoder_unit(decoder_embedded_outputs,initial_state=decoder_initial_state)\n",
        "\n",
        "        return decoder_outputs"
      ],
      "metadata": {
        "id": "Iub11qtwhQv0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,units=256,**kwargs):\n",
        "\n",
        "        super(CrossAttention,self).__init__(**kwargs)\n",
        "\n",
        "        self.mha = keras.layers.MultiHeadAttention(num_heads=1,key_dim=units)\n",
        "        self.add = keras.layers.Add()\n",
        "        self.layer_norm = keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self,encoder_outputs,decoder_outputs):\n",
        "\n",
        "\n",
        "        attention_outputs,attention_scores = self.mha(query=decoder_outputs,value=encoder_outputs,return_attention_scores=True)\n",
        "        self.attention_scores = tf.reduce_mean(attention_scores,axis=1)\n",
        "        normalized_attention_outputs = self.layer_norm(self.add([attention_outputs,decoder_outputs]))\n",
        "\n",
        "        return normalized_attention_outputs"
      ],
      "metadata": {
        "id": "HrsGUVD8xkfq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(keras.Model):\n",
        "    @classmethod\n",
        "    def add_method(cls,func):\n",
        "        setattr(cls,func.__name__,func)\n",
        "        return func\n",
        "\n",
        "    def __init__(self,input_vec_layer=en_vec_layer,output_vec_layer=es_vec_layer,units=256,**kwargs):\n",
        "\n",
        "        super(Translator,self).__init__(**kwargs)\n",
        "\n",
        "        self.encoder_layer = Encoder(units=units,vec_layer=input_vec_layer)\n",
        "        self.decoder_layer = Decoder(units=units,vec_layer=output_vec_layer)\n",
        "        self.attention_layer = CrossAttention(units=units)\n",
        "\n",
        "        self.words_to_ids = keras.layers.StringLookup(\n",
        "            vocabulary=self.decoder_layer.vec_layer.get_vocabulary(),\n",
        "            oov_token=\"[UNK]\",\n",
        "            mask_token=\"\"\n",
        "        )\n",
        "        self.ids_to_words = keras.layers.StringLookup(\n",
        "            vocabulary=self.decoder_layer.vec_layer.get_vocabulary(),\n",
        "            oov_token=\"[UNK]\",\n",
        "            mask_token=\"\",\n",
        "            invert=True\n",
        "        )\n",
        "        self.start_token = self.words_to_ids([\"[START]\"])\n",
        "        self.end_token = self.words_to_ids([\"[END]\"])\n",
        "\n",
        "        self.out = keras.layers.Dense(self.decoder_layer.vec_layer.vocabulary_size())\n",
        "\n",
        "\n",
        "    def call(self,inputs,decoder_initial_state=None):\n",
        "\n",
        "\n",
        "\n",
        "        encoder_inputs,decoder_inputs = inputs\n",
        "\n",
        "        encoder_outputs = self.encoder_layer(encoder_inputs)\n",
        "\n",
        "        decoder_outputs = self.decoder_layer(decoder_inputs,decoder_initial_state)\n",
        "\n",
        "        attention_outputs = self.attention_layer(encoder_outputs,decoder_outputs)\n",
        "\n",
        "        total_outputs = self.out(attention_outputs)\n",
        "\n",
        "        try:\n",
        "            del total_outputs._keras_mask\n",
        "\n",
        "        except AttributeError:\n",
        "\n",
        "            pass\n",
        "\n",
        "        return total_outputs\n"
      ],
      "metadata": {
        "id": "bmlCyOD6rlIe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Translator()"
      ],
      "metadata": {
        "id": "tmTgW4JA4I3X"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "UNITS = 256\n",
        "train_steps = train_size//BATCH_SIZE\n",
        "valid_steps = valid_size//BATCH_SIZE"
      ],
      "metadata": {
        "id": "13YEGUyQ3lMK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss(y_true,y_pred):\n",
        "\n",
        "    '''\n",
        "        y_pred will be [batch sequence vocab_size]\n",
        "        y_true will be [batch sequence]\n",
        "        as the sequence contains zeros we only use the non-zero part of the sequence so we will mask it\n",
        "    '''\n",
        "    loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction=\"none\")\n",
        "    loss = loss_fn(y_true,y_pred) # tf.float32\n",
        "    mask = tf.cast(y_true != 0,loss.dtype) # tf.float32\n",
        "    loss *= mask # reducing the effective output scale\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def custom_metric(y_true,y_pred):\n",
        "\n",
        "    '''\n",
        "        y_pred will be [batch sequence vocab_size]             with dtype = tf.float32\n",
        "        y_true will be [batch sequence]                        with dtype = tf.int64\n",
        "        as the sequence also has zeros we use masked accuracy\n",
        "    '''\n",
        "\n",
        "    y_pred = tf.cast(tf.argmax(y_pred,-1),y_true.dtype) # tf.int64\n",
        "    mask = tf.cast(y_true != 0,tf.float32) # tf.float32\n",
        "    accuracy = tf.cast(y_pred == y_true,tf.float32) # tf.float32\n",
        "    return tf.reduce_sum(accuracy)/tf.reduce_sum(mask) # tf.float32\n"
      ],
      "metadata": {
        "id": "erliTUJi5uOb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=custom_loss,optimizer=keras.optimizers.Adam(),metrics=[custom_metric,custom_loss],steps_per_execution=20)"
      ],
      "metadata": {
        "id": "I2kDhWTy_2LA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(patience=15,monitor='val_custom_loss',restore_best_weights=True)\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=100,\n",
        "    validation_data=valid_ds,\n",
        "    callbacks=[early_stop]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C862ftJAexp",
        "outputId": "86dad885-fa73-4ae4-e998-0dc7c5a028fc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1483/1483 [==============================] - 80s 54ms/step - loss: 2.6403 - custom_metric: 0.5389 - custom_loss: 2.6397 - val_loss: 1.5764 - val_custom_metric: 0.6775 - val_custom_loss: 1.5780\n",
            "Epoch 2/100\n",
            "1483/1483 [==============================] - 33s 22ms/step - loss: 1.2798 - custom_metric: 0.7195 - custom_loss: 1.2800 - val_loss: 1.2606 - val_custom_metric: 0.7271 - val_custom_loss: 1.2607\n",
            "Epoch 3/100\n",
            "1483/1483 [==============================] - 32s 22ms/step - loss: 1.0047 - custom_metric: 0.7631 - custom_loss: 1.0043 - val_loss: 1.1665 - val_custom_metric: 0.7435 - val_custom_loss: 1.1669\n",
            "Epoch 4/100\n",
            "1483/1483 [==============================] - 32s 22ms/step - loss: 0.8517 - custom_metric: 0.7892 - custom_loss: 0.8518 - val_loss: 1.1326 - val_custom_metric: 0.7479 - val_custom_loss: 1.1332\n",
            "Epoch 5/100\n",
            "1483/1483 [==============================] - 32s 22ms/step - loss: 0.7407 - custom_metric: 0.8104 - custom_loss: 0.7405 - val_loss: 1.1252 - val_custom_metric: 0.7558 - val_custom_loss: 1.1251\n",
            "Epoch 6/100\n",
            "1483/1483 [==============================] - 32s 22ms/step - loss: 0.6487 - custom_metric: 0.8285 - custom_loss: 0.6485 - val_loss: 1.1313 - val_custom_metric: 0.7574 - val_custom_loss: 1.1309\n",
            "Epoch 7/100\n",
            "1483/1483 [==============================] - 32s 22ms/step - loss: 0.5722 - custom_metric: 0.8446 - custom_loss: 0.5724 - val_loss: 1.1663 - val_custom_metric: 0.7570 - val_custom_loss: 1.1660\n",
            "Epoch 8/100\n",
            "1483/1483 [==============================] - 32s 21ms/step - loss: 0.5068 - custom_metric: 0.8593 - custom_loss: 0.5076 - val_loss: 1.1940 - val_custom_metric: 0.7572 - val_custom_loss: 1.1938\n",
            "Epoch 9/100\n",
            "1483/1483 [==============================] - 32s 22ms/step - loss: 0.4520 - custom_metric: 0.8727 - custom_loss: 0.4518 - val_loss: 1.2314 - val_custom_metric: 0.7552 - val_custom_loss: 1.2320\n",
            "Epoch 10/100\n",
            "1483/1483 [==============================] - 32s 21ms/step - loss: 0.4020 - custom_metric: 0.8854 - custom_loss: 0.4020 - val_loss: 1.2782 - val_custom_metric: 0.7551 - val_custom_loss: 1.2781\n",
            "Epoch 11/100\n",
            "1483/1483 [==============================] - 32s 21ms/step - loss: 0.3621 - custom_metric: 0.8952 - custom_loss: 0.3619 - val_loss: 1.3340 - val_custom_metric: 0.7538 - val_custom_loss: 1.3336\n",
            "Epoch 12/100\n",
            "1483/1483 [==============================] - 32s 21ms/step - loss: 0.3278 - custom_metric: 0.9042 - custom_loss: 0.3276 - val_loss: 1.3825 - val_custom_metric: 0.7537 - val_custom_loss: 1.3819\n",
            "Epoch 13/100\n",
            "1483/1483 [==============================] - 31s 21ms/step - loss: 0.2987 - custom_metric: 0.9120 - custom_loss: 0.2988 - val_loss: 1.4153 - val_custom_metric: 0.7524 - val_custom_loss: 1.4149\n",
            "Epoch 14/100\n",
            "1483/1483 [==============================] - 31s 21ms/step - loss: 0.2750 - custom_metric: 0.9186 - custom_loss: 0.2750 - val_loss: 1.4645 - val_custom_metric: 0.7499 - val_custom_loss: 1.4657\n",
            "Epoch 15/100\n",
            "1483/1483 [==============================] - 31s 21ms/step - loss: 0.2535 - custom_metric: 0.9245 - custom_loss: 0.2535 - val_loss: 1.5286 - val_custom_metric: 0.7499 - val_custom_loss: 1.5296\n",
            "Epoch 16/100\n",
            "1483/1483 [==============================] - 31s 21ms/step - loss: 0.2382 - custom_metric: 0.9292 - custom_loss: 0.2381 - val_loss: 1.5576 - val_custom_metric: 0.7514 - val_custom_loss: 1.5570\n",
            "Epoch 17/100\n",
            "1483/1483 [==============================] - 32s 21ms/step - loss: 0.2228 - custom_metric: 0.9335 - custom_loss: 0.2228 - val_loss: 1.5823 - val_custom_metric: 0.7484 - val_custom_loss: 1.5810\n",
            "Epoch 18/100\n",
            "1483/1483 [==============================] - 31s 21ms/step - loss: 0.2098 - custom_metric: 0.9374 - custom_loss: 0.2098 - val_loss: 1.6281 - val_custom_metric: 0.7502 - val_custom_loss: 1.6277\n",
            "Epoch 19/100\n",
            "1483/1483 [==============================] - 31s 21ms/step - loss: 0.1990 - custom_metric: 0.9406 - custom_loss: 0.1989 - val_loss: 1.6527 - val_custom_metric: 0.7488 - val_custom_loss: 1.6524\n",
            "Epoch 20/100\n",
            "1483/1483 [==============================] - 32s 21ms/step - loss: 0.1887 - custom_metric: 0.9437 - custom_loss: 0.1887 - val_loss: 1.7081 - val_custom_metric: 0.7484 - val_custom_loss: 1.7088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()"
      ],
      "metadata": {
        "id": "K2_s0ZQX5jmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c4e76c3-3619-41d0-e05d-214459c0df38"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'custom_metric', 'custom_loss', 'val_loss', 'val_custom_metric', 'val_custom_loss'])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(y=model.history.history['custom_loss'],mode=\"lines\"))\n",
        "fig.add_trace(go.Scatter(y=model.history.history['val_custom_loss'],mode=\"lines\"))\n",
        "fig.update_layout(title=\"Loss Train v/s Validation\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "JMwSURbZ5RQl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "6b1e8e34-2787-497e-e33a-8b347b3b1f6c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"bd207715-31be-4752-bbb4-680b064ff751\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bd207715-31be-4752-bbb4-680b064ff751\")) {                    Plotly.newPlot(                        \"bd207715-31be-4752-bbb4-680b064ff751\",                        [{\"mode\":\"lines\",\"y\":[2.6396801471710205,1.2800071239471436,1.0043436288833618,0.8517506718635559,0.7404767274856567,0.6484588980674744,0.572387158870697,0.5076351165771484,0.4518178403377533,0.4019889831542969,0.3619394302368164,0.32759684324264526,0.29877138137817383,0.27503475546836853,0.253527969121933,0.23807789385318756,0.22279344499111176,0.20976927876472473,0.19891402125358582,0.1887149065732956],\"type\":\"scatter\"},{\"mode\":\"lines\",\"y\":[1.5779756307601929,1.2607088088989258,1.1669074296951294,1.1332060098648071,1.1250998973846436,1.1308540105819702,1.1659642457962036,1.1938108205795288,1.2319505214691162,1.2781025171279907,1.3335896730422974,1.3819087743759155,1.4148975610733032,1.4656511545181274,1.529592752456665,1.5570447444915771,1.5809975862503052,1.627734661102295,1.6524416208267212,1.7088383436203003],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"title\":{\"text\":\"Loss Train v\\u002fs Validation\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bd207715-31be-4752-bbb4-680b064ff751');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(y=model.history.history['custom_metric'],mode=\"lines\"))\n",
        "fig.add_trace(go.Scatter(y=model.history.history['val_custom_metric'],mode=\"lines\"))\n",
        "fig.update_layout(title=\"MaskedAccuracy Train v/s Validation\")\n",
        "fig.update_yaxes(range=[0,1])\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "a3iBRePM5_Gr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "826da372-e15b-4e69-f70d-33e1f084c110"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"c18632c2-2f83-4626-9051-255868b4eba6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c18632c2-2f83-4626-9051-255868b4eba6\")) {                    Plotly.newPlot(                        \"c18632c2-2f83-4626-9051-255868b4eba6\",                        [{\"mode\":\"lines\",\"y\":[0.5389438271522522,0.719505786895752,0.7630582451820374,0.7891902327537537,0.8103514909744263,0.8285242915153503,0.8445736169815063,0.8593354821205139,0.8726910352706909,0.8853773474693298,0.8952147960662842,0.9042359590530396,0.912025511264801,0.9185940623283386,0.9244515895843506,0.9292217493057251,0.93352872133255,0.9374179244041443,0.9406379461288452,0.9437057375907898],\"type\":\"scatter\"},{\"mode\":\"lines\",\"y\":[0.6775151491165161,0.7271424531936646,0.7435064911842346,0.7479303479194641,0.7557907104492188,0.7574278116226196,0.7570323348045349,0.7572034597396851,0.7552003264427185,0.755057692527771,0.7537641525268555,0.7536523342132568,0.7523805499076843,0.7499295473098755,0.7499157786369324,0.7514119148254395,0.7484421133995056,0.7501855492591858,0.7488027215003967,0.7483934164047241],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"title\":{\"text\":\"MaskedAccuracy Train v\\u002fs Validation\"},\"yaxis\":{\"range\":[0,1]}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c18632c2-2f83-4626-9051-255868b4eba6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@Translator.add_method\n",
        "def text_to_encoder_outputs(self,texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    en_vec_outputs = self.encoder_layer.vec_layer(texts).to_tensor()\n",
        "    return self.encoder_layer(en_vec_outputs)"
      ],
      "metadata": {
        "id": "gIZLn4Qyl0uW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Translator.add_method\n",
        "def get_decoder_initial_state(self,encoder_outputs):\n",
        "    batch_size = encoder_outputs.shape[0]\n",
        "    start_tokens = tf.fill(dims=[batch_size,1],value=self.start_token)\n",
        "    done = tf.zeros(shape=[batch_size,1],dtype=tf.bool)\n",
        "    embedding = self.decoder_layer.embedder(start_tokens)\n",
        "    return start_tokens,done,self.decoder_layer.decoder_unit.get_initial_state(embedding)"
      ],
      "metadata": {
        "id": "OPw-O5Q7l2dl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Translator.add_method\n",
        "def get_next_token(self,encoder_inputs,next_token,done,state,temperature=0.0):\n",
        "    total_out = self((encoder_inputs,next_token),state)\n",
        "\n",
        "    if temperature:\n",
        "        scaled_total_out = total_out[:,-1,:]/temperature\n",
        "        next_token = tf.random.categorical(scaled_total_out,num_samples=1)\n",
        "    else:\n",
        "        next_token = tf.argmax(total_out,axis=-1)\n",
        "\n",
        "    done = done | (next_token == self.end_token)\n",
        "    next_token = tf.where(done,tf.constant(0,tf.int64),next_token)\n",
        "    return next_token,done,self.decoder_layer.decoder_state"
      ],
      "metadata": {
        "id": "0ZbmfOjdl5sz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Translator.add_method\n",
        "def tokens_to_text(self,tokens):\n",
        "    texts = self.ids_to_words(tokens)\n",
        "    texts = tf.strings.reduce_join(texts,separator=\" \",axis=-1)\n",
        "    texts = tf.strings.regex_replace(texts,r\"^ *\\[START\\]* \",\"\")\n",
        "    texts = tf.strings.regex_replace(texts,r\" *\\[END]\\ *$\",\"\")\n",
        "    texts = tf.strings.strip(texts)\n",
        "    return texts"
      ],
      "metadata": {
        "id": "c-qIOpx0lNjn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Translator.add_method\n",
        "def translate(self,text,temperature=1):\n",
        "    preprocessed_text = self.encoder_layer.vec_layer(text).to_tensor()\n",
        "    encoder_outputs = self.encoder_layer(preprocessed_text)\n",
        "    next_token,done,state = self.get_decoder_initial_state(encoder_outputs)\n",
        "    tokens_list = []\n",
        "\n",
        "    for i in range(10):\n",
        "        next_token,done,state = self.get_next_token(preprocessed_text,next_token,done,state,temperature)\n",
        "        tokens_list.append(next_token)\n",
        "\n",
        "    string_obj = self.tokens_to_text(tf.concat(tokens_list,axis=-1))\n",
        "    return tf.strings.regex_replace(string_obj,r\" *\\[UNK]\\ *$\",\"\").numpy()[0].decode()"
      ],
      "metadata": {
        "id": "vvC9uWd7mBIX"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Testing on a random inputs'''\n",
        "model.translate([\"Hey! are you still there?\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tHMAeGUXmXGC",
        "outputId": "f0e56690-5c0f-475b-ef2b-98887e629adf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eh ! ¿ estas todavia ?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = model.evaluate(train_ds,return_dict=True)\n",
        "train_result"
      ],
      "metadata": {
        "id": "qd5Zwsj0dB4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ec7536-d7f3-447a-8049-1c8844cdb3d6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1483/1483 [==============================] - 17s 11ms/step - loss: 0.5834 - custom_metric: 0.8443 - custom_loss: 0.5833\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 0.5834096670150757,\n",
              " 'custom_metric': 0.844276487827301,\n",
              " 'custom_loss': 0.5832920074462891}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_result = model.evaluate(valid_ds,return_dict=True)\n",
        "valid_result"
      ],
      "metadata": {
        "id": "XLiNWrBXdE6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4502421-0793-4600-f08a-696e6a72e8ed"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "321/321 [==============================] - 4s 12ms/step - loss: 1.1259 - custom_metric: 0.7555 - custom_loss: 1.1265\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 1.1259492635726929,\n",
              " 'custom_metric': 0.7554615139961243,\n",
              " 'custom_loss': 1.126450538635254}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_result = model.evaluate(test_ds,return_dict=True)\n",
        "test_result"
      ],
      "metadata": {
        "id": "_wUUjd5Qc6qR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db62c91c-f7aa-45b7-90bb-f42d5979438a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 1s 13ms/step - loss: 1.1147 - custom_metric: 0.7564 - custom_loss: 1.1154\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 1.1146509647369385,\n",
              " 'custom_metric': 0.7564138174057007,\n",
              " 'custom_loss': 1.1154146194458008}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_text[test_indices][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfEbe1pjqngT",
        "outputId": "5a3c657a-d6e6-4a7a-98da-7653466c8f4e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Call me.', 'Get out.', 'Get out.', \"It's me!\", 'Go on in.',\n",
              "       'I agreed.', 'I can go.', \"I'm fine.\", \"I'm poor.\", 'Leave it.'],\n",
              "      dtype='<U247')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for en,es in zip(en_text[test_indices][:10],es_text[test_indices][:10]):\n",
        "    print(f\"Original: {es}     Translated: {model.translate([en])}\")"
      ],
      "metadata": {
        "id": "jg-tbljf6_F4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00923191-fd20-4018-ef37-64fea1de3554"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: Llámame.     Translated: me [UNK] .\n",
            "Original: Salid.     Translated: sal .\n",
            "Original: Salgan.     Translated: baje .\n",
            "Original: Soy yo.     Translated: es mio !\n",
            "Original: Entrad.     Translated: vaya adentro .\n",
            "Original: Accedí.     Translated: estoy de acuerdo .\n",
            "Original: Puedo ir.     Translated: puedo ir .\n",
            "Original: Estoy perfectamente.     Translated: estoy perfectamente .\n",
            "Original: Soy pobre.     Translated: soy pobre .\n",
            "Original: Déjalo.     Translated: dejalo .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.translate([\"Hello, How are you doing\"])"
      ],
      "metadata": {
        "id": "Z8puVS25F9yl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5fffbfe3-9964-4029-a59c-c4d1fca78436"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hola como [UNK] .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "81zaxI0dT4C8"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}