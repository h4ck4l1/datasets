{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPoyzszjPGPIjPpxgbDqKJf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h4ck4l1/datasets/blob/main/NLP_with_RNN_and_Attention/NMT_with_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xHJa_8IeCwTX"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "import os,warnings\n",
        "from IPython.display import clear_output\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "!pip3 install -q -U \"tensorflow-text==2.13.0\"\n",
        "!pip3 install -q -U einops\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_text as tf_text\n",
        "np.printoptions(precision=2)\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "pio.templates.default = \"plotly_dark\"\n",
        "import einops\n",
        "from zipfile import ZipFile\n",
        "from typing import Any\n",
        "# %xmode Minimal\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "# tf.config.experimental_connect_to_cluster(resolver)\n",
        "# tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "# strategy = tf.distribute.TPUStrategy(resolver)\n",
        "# strategy = tf.distribute.OneDeviceStrategy(device=\"/device:GPU:0\")"
      ],
      "metadata": {
        "id": "DdP5qZJVtU2j"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class ShapeCheck():\n",
        "\n",
        "#     def __init__(self):\n",
        "#         self.shapes = {}\n",
        "\n",
        "#     def __call__(self,tensor,names,**kwargs):\n",
        "\n",
        "#         if not tf.executing_eagerly():\n",
        "#             return\n",
        "\n",
        "#         for name,dim in einops.parse_shape(tensor,names).items():\n",
        "\n",
        "#             if name not in self.shapes:\n",
        "#                 self.shapes[name] = dim\n",
        "\n",
        "#             elif self.shapes[name] == dim:\n",
        "#                 continue\n",
        "\n",
        "#             else:\n",
        "#                 raise ValueError(f\"Dimension mismatch for tensor {tensor}\\nfound dimention :{self.shapes[name]}\\nnew dimension given :{dim}\")\n"
      ],
      "metadata": {
        "id": "wXQqhK5Q_gAg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(\"/job:localhost\"):\n",
        "    origin = \"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
        "    file_path = keras.utils.get_file(fname=\"spa-eng.zip\",origin=origin,extract=True)\n",
        "    with ZipFile(file_path,\"r\") as f:\n",
        "        f.extractall(\"spa-eng\")\n",
        "    with open(\"spa-eng/spa-eng/spa.txt\",\"r\") as f:\n",
        "        text = f.read()\n",
        "    en_text,es_text = zip(*[line.split(\"\\t\") for line in text.splitlines()])\n",
        "    for en,es in zip(en_text[:10],es_text[:10]):\n",
        "        print(en,\"---->\",es)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id5fVBZMgo8Q",
        "outputId": "2736e719-6743-4049-b053-84a41f371443"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go. ----> Ve.\n",
            "Go. ----> Vete.\n",
            "Go. ----> Vaya.\n",
            "Go. ----> Váyase.\n",
            "Hi. ----> Hola.\n",
            "Run! ----> ¡Corre!\n",
            "Run. ----> Corred.\n",
            "Who? ----> ¿Quién?\n",
            "Fire! ----> ¡Fuego!\n",
            "Fire! ----> ¡Incendio!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocess(sentence:str):\n",
        "    sentence = tf_text.normalize_utf8(sentence,\"NFKD\")\n",
        "    sentence = tf.strings.lower(sentence)\n",
        "    sentence = tf.strings.regex_replace(sentence,r\"[^ a-z.,!?¿]\",\"\")\n",
        "    sentence = tf.strings.regex_replace(sentence,r\"[.,!?¿]\",r\" \\0 \")\n",
        "    sentence = tf.strings.strip(sentence)\n",
        "    sentence = tf.strings.join([\"[START]\",sentence,\"[END]\"],separator=\" \")\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "L-X_f9el6esj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for en,es in zip(text_preprocess(en_text[:10]).numpy(),text_preprocess(es_text[:10]).numpy()):\n",
        "#     print(f\"{en}   ---->{es}\")"
      ],
      "metadata": {
        "id": "DAIPy26E9umu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_layers(vocab_size=5000):\n",
        "    en_vec_layer = keras.layers.TextVectorization(max_tokens=vocab_size,standardize=text_preprocess,ragged=True)\n",
        "    es_vec_layer = keras.layers.TextVectorization(max_tokens=vocab_size,standardize=text_preprocess,ragged=True)\n",
        "    en_vec_layer.adapt(en_text)\n",
        "    es_vec_layer.adapt(es_text)\n",
        "    return en_vec_layer,es_vec_layer"
      ],
      "metadata": {
        "id": "bARcJi8D_PHT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(en_inputs,es_inputs):\n",
        "    en_inputs = en_vec_layer(en_inputs).to_tensor()\n",
        "    es_inputs = es_vec_layer(es_inputs).to_tensor()\n",
        "    return (en_inputs,es_inputs[:,:-1]),es_inputs[:,1:]"
      ],
      "metadata": {
        "id": "Av4bEWHDJO0i"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTO = tf.data.AUTOTUNE\n",
        "def get_datasets(en_text,es_text,batch_size=64):\n",
        "    all_indices = np.random.uniform(size=len(en_text))\n",
        "    train_indices = all_indices < 0.8\n",
        "    valid_indices = all_indices > 0.8\n",
        "    en_text = np.array(en_text)\n",
        "    es_text = np.array(es_text)\n",
        "    train_size = len(train_indices)\n",
        "    valid_size = len(valid_indices)\n",
        "    train_ds = (\n",
        "        tf.data.Dataset\n",
        "        .from_tensor_slices((en_text[train_indices],es_text[train_indices]))\n",
        "        .shuffle(len(en_text))\n",
        "        .batch(batch_size)\n",
        "        .map(preprocess)\n",
        "        .prefetch(AUTO)\n",
        "    )\n",
        "    valid_ds = (\n",
        "        tf.data.Dataset\n",
        "        .from_tensor_slices((en_text[valid_indices],es_text[valid_indices]))\n",
        "        .shuffle(len(en_text))\n",
        "        .batch(batch_size)\n",
        "        .map(preprocess)\n",
        "        .prefetch(AUTO)\n",
        "    )\n",
        "    return train_ds,valid_ds,train_size,valid_size\n",
        "\n",
        "\n",
        "# train_ds,valid_ds = get_dataset(en_text,es_text)"
      ],
      "metadata": {
        "id": "ZnJ8xsuyLJnB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for (en_in,es_in),tar_in in train_ds.take(1):\n",
        "#     print(en_in.shape,es_in.shape,tar_in.shape)\n",
        "#     print(en_in[:2],es_in[:2],tar_in[:2])"
      ],
      "metadata": {
        "id": "HXZKnKSEWCNl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,vec_layer: keras.layers.TextVectorization,units: int=256,**kwargs):\n",
        "\n",
        "        super(Encoder,self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.vec_layer = vec_layer\n",
        "        self.vocab_size = vec_layer.vocabulary_size()\n",
        "\n",
        "        self.embedder = keras.layers.Embedding(self.vocab_size,units,mask_zero=True)\n",
        "        self.encoder_unit = keras.layers.Bidirectional(keras.layers.LSTM(units,return_state=True,return_sequences=True,recurrent_initializer=\"glorot_uniform\"),merge_mode=\"sum\")\n",
        "\n",
        "    def call(self,encoder_inputs):\n",
        "\n",
        "        # shape_checker = ShapeCheck()\n",
        "        # shape_checker(encoder_inputs,\"batch encoder_sequence\")\n",
        "\n",
        "        encoder_embedded_outputs = self.embedder(encoder_inputs)\n",
        "        # shape_checker(encoder_embedded_outputs,\"batch encoder_sequence units\")\n",
        "\n",
        "        encoder_outputs,*self.encoder_state = self.encoder_unit(encoder_embedded_outputs)\n",
        "        # shape_checker(self.encoder_state[0],\"batch units\")\n",
        "        # shape_checker(self.encoder_state[1],\"batch units\")\n",
        "\n",
        "        return encoder_outputs"
      ],
      "metadata": {
        "id": "ryWbLFERWQ-k"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '''Test whether encoder is working for all inputs'''\n",
        "# with strategy.scope():\n",
        "#     encoder = Encoder()\n",
        "\n",
        "# for en_in in train_ds.map(lambda x,y:x[0]).take(1):\n",
        "#     encoder(en_in)\n",
        "\n",
        "# for en_in in valid_ds.map(lambda x,y:x[0]).take(1):\n",
        "#     encoder(en_in)"
      ],
      "metadata": {
        "id": "c6MqIEFcrcgO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,vec_layer:keras.layers.TextVectorization,units:int=256,**kwargs):\n",
        "\n",
        "        super(Decoder,self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.vec_layer = vec_layer\n",
        "        self.vocab_size = vec_layer.vocabulary_size()\n",
        "\n",
        "        self.embedder = keras.layers.Embedding(self.vocab_size,units,mask_zero=True)\n",
        "        self.decoder_unit = keras.layers.LSTM(units,return_state=True,return_sequences=True,recurrent_initializer=\"glorot_uniform\")\n",
        "\n",
        "\n",
        "    def call(self,decoder_inputs,decoder_initial_state=None):\n",
        "\n",
        "        # shape_checker = ShapeCheck()\n",
        "        # shape_checker(decoder_inputs,\"batch decoder_sequence\")\n",
        "\n",
        "        decoder_embedded_outputs = self.embedder(decoder_inputs)\n",
        "        # shape_checker(decoder_embedded_outputs,\"batch decoder_sequence units\")\n",
        "\n",
        "        decoder_outputs,*self.decoder_state = self.decoder_unit(decoder_embedded_outputs,initial_state=decoder_initial_state)\n",
        "        # shape_checker(decoder_outputs,\"batch decoder_sequence units\")\n",
        "        # shape_checker(self.decoder_state[0],\"batch units\")\n",
        "        # shape_checker(self.decoder_state[1],\"batch units\")\n",
        "\n",
        "        return decoder_outputs"
      ],
      "metadata": {
        "id": "Iub11qtwhQv0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '''Testing for Decoder Errors'''\n",
        "# with strategy.scope():\n",
        "#     decoder = Decoder()\n",
        "\n",
        "\n",
        "# for es_in in train_ds.map(lambda x,y:x[1]).take(1):\n",
        "#     decoder(es_in)\n",
        "\n",
        "# for es_in in valid_ds.map(lambda x,y:x[1]).take(1):\n",
        "#     decoder(es_in)"
      ],
      "metadata": {
        "id": "i-c1HwT6qMn7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,units=256,**kwargs):\n",
        "\n",
        "        super(CrossAttention,self).__init__(**kwargs)\n",
        "\n",
        "        self.mha = keras.layers.MultiHeadAttention(num_heads=1,key_dim=units)\n",
        "        self.add = keras.layers.Add()\n",
        "        self.layer_norm = keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self,encoder_outputs,decoder_outputs):\n",
        "\n",
        "        # shape_checker = ShapeCheck()\n",
        "        # shape_checker(encoder_outputs,\"batch encoder_sequence units\")\n",
        "        # shape_checker(decoder_outputs,\"batch decoder_sequence units\")\n",
        "\n",
        "        attention_outputs,attention_scores = self.mha(query=decoder_outputs,value=encoder_outputs,return_attention_scores=True)\n",
        "        # shape_checker(attention_outputs,\"batch decoder_sequence units\")\n",
        "        # shape_checker(attention_scores,\"batch num_heads decoder_sequence encoder_sequence\")\n",
        "        self.attention_scores = tf.reduce_mean(attention_scores,axis=1)\n",
        "        normalized_attention_outputs = self.layer_norm(self.add([attention_outputs,decoder_outputs]))\n",
        "\n",
        "        return normalized_attention_outputs"
      ],
      "metadata": {
        "id": "HrsGUVD8xkfq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '''Testing for Attention Errors'''\n",
        "# with strategy.scope():\n",
        "#     attention_layer = CrossAttention()\n",
        "\n",
        "# for en_in,es_in in train_ds.map(lambda x,y:x).take(1):\n",
        "#     attention_layer(encoder(en_in),decoder(es_in)\n",
        "\n",
        "\n",
        "# for en_in,es_in in valid_ds.map(lambda x,y:x).take(1):\n",
        "#     attention_layer(encoder(en_in),decoder(es_in))"
      ],
      "metadata": {
        "id": "qKWAe8DW5XOD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(keras.Model):\n",
        "\n",
        "    def __init__(self,input_vec_layer,output_vec_layer,units=256,**kwargs):\n",
        "\n",
        "        super(Translator,self).__init__(**kwargs)\n",
        "\n",
        "        self.encoder_layer = Encoder(units=units,vec_layer=input_vec_layer)\n",
        "        self.decoder_layer = Decoder(units=units,vec_layer=output_vec_layer)\n",
        "        self.attention_layer = CrossAttention(units=units)\n",
        "\n",
        "        self.words_to_ids = keras.layers.StringLookup(\n",
        "            vocabulary=self.decoder_layer.vec_layer.get_vocabulary(),\n",
        "            oov_token=\"[UNK]\",\n",
        "            mask_token=\"\"\n",
        "        )\n",
        "        self.ids_to_words = keras.layers.StringLookup(\n",
        "            vocabulary=self.decoder_layer.vec_layer.get_vocabulary(),\n",
        "            oov_token=\"[UNK]\",\n",
        "            mask_token=\"\",\n",
        "            invert=True\n",
        "        )\n",
        "        self.start_token = self.words_to_ids([\"[START]\"])\n",
        "        self.end_token = self.words_to_ids([\"[END]\"])\n",
        "\n",
        "        self.out = keras.layers.Dense(self.decoder_layer.vec_layer.vocabulary_size())\n",
        "\n",
        "\n",
        "    def call(self,inputs,decoder_initial_state=None):\n",
        "\n",
        "\n",
        "        # shape_checker = ShapeCheck()\n",
        "\n",
        "        encoder_inputs,decoder_inputs = inputs\n",
        "        # shape_checker(encoder_inputs,\"batch encoder_sequence\")\n",
        "        # shape_checker(decoder_inputs,\"batch decoder_sequence\")\n",
        "\n",
        "        encoder_outputs = self.encoder_layer(encoder_inputs)\n",
        "        # shape_checker(encoder_outputs,\"batch encoder_sequenc units\")\n",
        "        # shape_checker(self.encoder_layer.encoder_state[0],\"batch units\")\n",
        "        # shape_checker(self.encoder_layer.encoder_state[1],\"batch units\")\n",
        "\n",
        "        decoder_outputs = self.decoder_layer(decoder_inputs,decoder_initial_state)\n",
        "        # shape_checker(decoder_outputs,\"batch decoder_sequence units\")\n",
        "        # shape_checker(self.decoder_layer.decoder_state[0],\"batch units\")\n",
        "        # shape_checker(self.decoder_layer.decoder_state[1],\"batch units\")\n",
        "\n",
        "        attention_outputs = self.attention_layer(encoder_outputs,decoder_outputs)\n",
        "        # shape_checker(attention_outputs,\"batch decoder_sequence units\")\n",
        "\n",
        "        total_outputs = self.out(attention_outputs)\n",
        "        # shape_checker(total_outputs,\"batch decoder_sequence vocab_size\")\n",
        "\n",
        "        try:\n",
        "            del total_outputs._keras_mask\n",
        "\n",
        "        except AttributeError:\n",
        "\n",
        "            pass\n",
        "\n",
        "        return total_outputs\n",
        "\n",
        "\n",
        "    def text_to_encoder_outputs(self,texts):\n",
        "        texts = tf.convert_to_tensor(texts)\n",
        "        en_vec_outputs = self.encoder_layer.vec_layer(texts).to_tensor()\n",
        "        return self.encoder_layer(en_vec_outputs)\n",
        "\n",
        "    def get_decoder_initial_state(self,encoder_outputs):\n",
        "        batch_size = encoder_outputs.shape[0]\n",
        "        start_tokens = tf.fill(dims=[batch_size,1],value=self.start_token)\n",
        "        done = tf.zeros(shape=[batch_size,1],dtype=tf.bool)\n",
        "        embedding = self.decoder_layer.embedder(start_tokens)\n",
        "        return start_tokens,done,self.decoder_layer.decoder_unit.get_initial_state(embedding)\n",
        "\n",
        "    def get_next_token(self,encoder_inputs,next_token,done,state,temperature=0.0):\n",
        "        total_out = self((encoder_inputs,next_token),state)\n",
        "\n",
        "        if temperature:\n",
        "            scaled_total_out = total_out[:,-1,:]/temperature\n",
        "            next_token = tf.random.categorical(scaled_total_out,num_samples=1)\n",
        "        else:\n",
        "            next_token = tf.argmax(total_out,axis=-1)\n",
        "\n",
        "        done = done | (next_token == self.end_token)\n",
        "        next_token = tf.where(done,tf.constant(0,tf.int64),next_token)\n",
        "        return next_token,done,self.decoder_layer.decoder_state\n",
        "\n",
        "    def tokens_to_text(self,tokens):\n",
        "        texts = self.ids_to_words(tokens)\n",
        "        texts = tf.strings.reduce_join(texts,separator=\" \",axis=-1)\n",
        "        texts = tf.strings.regex_replace(texts,r\"^ *\\[START\\]* \",\"\")\n",
        "        texts = tf.strings.regex_replace(texts,r\" *\\[END]\\ *$\",\"\")\n",
        "        texts = tf.strings.strip(texts)\n",
        "        return texts\n"
      ],
      "metadata": {
        "id": "bmlCyOD6rlIe"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '''Testing for Total Translator errors'''\n",
        "# with strategy.scope():\n",
        "#     model = Translator()\n",
        "\n",
        "\n",
        "# for x in train_ds.map(lambda x,y:x).take(1):\n",
        "#     model(x)\n",
        "# for x in valid_ds.map(lambda x,y:x).take(1):\n",
        "#     model(x)"
      ],
      "metadata": {
        "id": "UxEGjrOol5ll"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '''Example Text Generation'''\n",
        "# next_token,done,state = model.get_decoder_initial_state(model.encoder_layer(en_in))\n",
        "# tokens_list = []\n",
        "# for i in range(10):\n",
        "#     next_token,done,state = model.get_next_token(en_in,next_token,done,state=state,temperature=1)\n",
        "#     tokens_list.append(next_token)\n",
        "\n",
        "# tokens_list = tf.concat(tokens_list,axis=-1)\n",
        "# model.tokens_to_text(tokens_list)[:10]"
      ],
      "metadata": {
        "id": "C97tMa5SuchK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss(y_true,y_pred):\n",
        "\n",
        "    '''\n",
        "        y_pred will be [batch sequence vocab_size]\n",
        "        y_true will be [batch sequence]\n",
        "        as the sequence contains zeros we only use the non-zero part of the sequence so we will mask it\n",
        "    '''\n",
        "    loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction=\"none\")\n",
        "    loss = loss_fn(y_true,y_pred) # tf.float32\n",
        "    mask = tf.cast(y_true != 0,loss.dtype) # tf.float32\n",
        "    loss *= mask # reducing the effective output scale\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def custom_metric(y_true,y_pred):\n",
        "\n",
        "    '''\n",
        "        y_pred will be [batch sequence vocab_size]             with dtype = tf.float32\n",
        "        y_true will be [batch sequence]                        with dtype = tf.int64\n",
        "        as the sequence also has zeros we use masked accuracy\n",
        "    '''\n",
        "\n",
        "    y_pred = tf.cast(tf.argmax(y_pred,-1),y_true.dtype) # tf.int64\n",
        "    mask = tf.cast(y_true != 0,tf.float32) # tf.float32\n",
        "    accuracy = tf.cast(y_pred == y_true,tf.float32) # tf.float32\n",
        "    return tf.reduce_sum(accuracy)/tf.reduce_sum(mask) # tf.float32\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "erliTUJi5uOb"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64 #8*strategy.num_replicas_in_sync\n",
        "UNITS = 256\n",
        "en_vec_layer,es_vec_layer = get_layers(vocab_size=5000)\n",
        "train_ds,valid_ds,train_size,valid_size = get_datasets(en_text,es_text,batch_size=BATCH_SIZE)\n",
        "train_steps = train_size//BATCH_SIZE\n",
        "valid_steps = valid_size//BATCH_SIZE\n",
        "# with strategy.scope():\n",
        "model = Translator(input_vec_layer=en_vec_layer,output_vec_layer=es_vec_layer,units=UNITS)\n",
        "model.compile(loss=custom_loss,optimizer=\"adam\",metrics=[custom_metric,custom_loss],steps_per_execution=20)"
      ],
      "metadata": {
        "id": "I2kDhWTy_2LA"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(patience=15,monitor='val_custom_metric',restore_best_weights=True)\n",
        "check = keras.callbacks.ModelCheckpoint(filepath=\"/content/nmt\",monitor=\"val_custom_loss\",save_best_only=True)\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=100,\n",
        "    validation_data=valid_ds,\n",
        "    callbacks=[early_stop,check]\n",
        "    # steps_per_epoch=train_steps,\n",
        "    # validation_steps=valid_steps\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C862ftJAexp",
        "outputId": "7bc06f56-cd9e-4fd9-878a-d5d48f2d22b5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1485/1485 [==============================] - 57s 38ms/step - loss: 0.5743 - custom_metric: 0.8450 - custom_loss: 0.5744 - val_loss: 1.1563 - val_custom_metric: 0.7572 - val_custom_loss: 1.1566\n",
            "Epoch 2/100\n",
            "1485/1485 [==============================] - 33s 22ms/step - loss: 0.4980 - custom_metric: 0.8616 - custom_loss: 0.4981 - val_loss: 1.1942 - val_custom_metric: 0.7569 - val_custom_loss: 1.1947\n",
            "Epoch 3/100\n",
            "1485/1485 [==============================] - 32s 22ms/step - loss: 0.4421 - custom_metric: 0.8749 - custom_loss: 0.4421 - val_loss: 1.2345 - val_custom_metric: 0.7557 - val_custom_loss: 1.2342\n",
            "Epoch 4/100\n",
            "1485/1485 [==============================] - 33s 22ms/step - loss: 0.3955 - custom_metric: 0.8865 - custom_loss: 0.3954 - val_loss: 1.2813 - val_custom_metric: 0.7531 - val_custom_loss: 1.2814\n",
            "Epoch 5/100\n",
            "1485/1485 [==============================] - 33s 22ms/step - loss: 0.3567 - custom_metric: 0.8965 - custom_loss: 0.3568 - val_loss: 1.3209 - val_custom_metric: 0.7523 - val_custom_loss: 1.3211\n",
            "Epoch 6/100\n",
            "1485/1485 [==============================] - 33s 22ms/step - loss: 0.3224 - custom_metric: 0.9058 - custom_loss: 0.3224 - val_loss: 1.3802 - val_custom_metric: 0.7523 - val_custom_loss: 1.3802\n",
            "Epoch 7/100\n",
            "1485/1485 [==============================] - 33s 22ms/step - loss: 0.2953 - custom_metric: 0.9129 - custom_loss: 0.2953 - val_loss: 1.4273 - val_custom_metric: 0.7507 - val_custom_loss: 1.4272\n",
            "Epoch 8/100\n",
            "1485/1485 [==============================] - 33s 22ms/step - loss: 0.2713 - custom_metric: 0.9195 - custom_loss: 0.2714 - val_loss: 1.4716 - val_custom_metric: 0.7497 - val_custom_loss: 1.4716\n",
            "Epoch 9/100\n",
            "1485/1485 [==============================] - 32s 22ms/step - loss: 0.2527 - custom_metric: 0.9252 - custom_loss: 0.2527 - val_loss: 1.5117 - val_custom_metric: 0.7509 - val_custom_loss: 1.5113\n",
            "Epoch 10/100\n",
            "1485/1485 [==============================] - 33s 22ms/step - loss: 0.2352 - custom_metric: 0.9301 - custom_loss: 0.2353 - val_loss: 1.5628 - val_custom_metric: 0.7487 - val_custom_loss: 1.5626\n",
            "Epoch 11/100\n",
            "1485/1485 [==============================] - 33s 22ms/step - loss: 0.2212 - custom_metric: 0.9342 - custom_loss: 0.2212 - val_loss: 1.6000 - val_custom_metric: 0.7482 - val_custom_loss: 1.6001\n",
            "Epoch 12/100\n",
            "1485/1485 [==============================] - 33s 22ms/step - loss: 0.2088 - custom_metric: 0.9377 - custom_loss: 0.2088 - val_loss: 1.6155 - val_custom_metric: 0.7470 - val_custom_loss: 1.6155\n",
            "Epoch 13/100\n",
            "1485/1485 [==============================] - 33s 22ms/step - loss: 0.1975 - custom_metric: 0.9410 - custom_loss: 0.1974 - val_loss: 1.6511 - val_custom_metric: 0.7472 - val_custom_loss: 1.6517\n",
            "Epoch 14/100\n",
            "1485/1485 [==============================] - 33s 22ms/step - loss: 0.1882 - custom_metric: 0.9440 - custom_loss: 0.1883 - val_loss: 1.6893 - val_custom_metric: 0.7460 - val_custom_loss: 1.6891\n",
            "Epoch 15/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1804 - custom_metric: 0.9464 - custom_loss: 0.1805 - val_loss: 1.7051 - val_custom_metric: 0.7463 - val_custom_loss: 1.7051\n",
            "Epoch 16/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1719 - custom_metric: 0.9491 - custom_loss: 0.1720 - val_loss: 1.7366 - val_custom_metric: 0.7444 - val_custom_loss: 1.7365\n",
            "Epoch 17/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1662 - custom_metric: 0.9502 - custom_loss: 0.1661 - val_loss: 1.7550 - val_custom_metric: 0.7466 - val_custom_loss: 1.7547\n",
            "Epoch 18/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1598 - custom_metric: 0.9522 - custom_loss: 0.1597 - val_loss: 1.7726 - val_custom_metric: 0.7460 - val_custom_loss: 1.7732\n",
            "Epoch 19/100\n",
            "1485/1485 [==============================] - 32s 22ms/step - loss: 0.1542 - custom_metric: 0.9540 - custom_loss: 0.1542 - val_loss: 1.7909 - val_custom_metric: 0.7445 - val_custom_loss: 1.7914\n",
            "Epoch 20/100\n",
            "1485/1485 [==============================] - 32s 22ms/step - loss: 0.1492 - custom_metric: 0.9557 - custom_loss: 0.1493 - val_loss: 1.8082 - val_custom_metric: 0.7444 - val_custom_loss: 1.8080\n",
            "Epoch 21/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1447 - custom_metric: 0.9567 - custom_loss: 0.1447 - val_loss: 1.8274 - val_custom_metric: 0.7466 - val_custom_loss: 1.8269\n",
            "Epoch 22/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1405 - custom_metric: 0.9581 - custom_loss: 0.1405 - val_loss: 1.8772 - val_custom_metric: 0.7464 - val_custom_loss: 1.8770\n",
            "Epoch 23/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1375 - custom_metric: 0.9585 - custom_loss: 0.1375 - val_loss: 1.8822 - val_custom_metric: 0.7450 - val_custom_loss: 1.8829\n",
            "Epoch 24/100\n",
            "1485/1485 [==============================] - 33s 22ms/step - loss: 0.1333 - custom_metric: 0.9598 - custom_loss: 0.1333 - val_loss: 1.8998 - val_custom_metric: 0.7431 - val_custom_loss: 1.8997\n",
            "Epoch 25/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1297 - custom_metric: 0.9605 - custom_loss: 0.1298 - val_loss: 1.9191 - val_custom_metric: 0.7446 - val_custom_loss: 1.9191\n",
            "Epoch 26/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1266 - custom_metric: 0.9617 - custom_loss: 0.1266 - val_loss: 1.9194 - val_custom_metric: 0.7433 - val_custom_loss: 1.9195\n",
            "Epoch 27/100\n",
            "1485/1485 [==============================] - 31s 21ms/step - loss: 0.1239 - custom_metric: 0.9622 - custom_loss: 0.1240 - val_loss: 1.9712 - val_custom_metric: 0.7467 - val_custom_loss: 1.9713\n",
            "Epoch 28/100\n",
            "1485/1485 [==============================] - 32s 22ms/step - loss: 0.1215 - custom_metric: 0.9630 - custom_loss: 0.1215 - val_loss: 1.9859 - val_custom_metric: 0.7460 - val_custom_loss: 1.9860\n",
            "Epoch 29/100\n",
            "1485/1485 [==============================] - 32s 22ms/step - loss: 0.1178 - custom_metric: 0.9637 - custom_loss: 0.1178 - val_loss: 2.0068 - val_custom_metric: 0.7446 - val_custom_loss: 2.0065\n",
            "Epoch 30/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1161 - custom_metric: 0.9641 - custom_loss: 0.1161 - val_loss: 1.9816 - val_custom_metric: 0.7443 - val_custom_loss: 1.9816\n",
            "Epoch 31/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1140 - custom_metric: 0.9645 - custom_loss: 0.1140 - val_loss: 2.0283 - val_custom_metric: 0.7443 - val_custom_loss: 2.0283\n",
            "Epoch 32/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1125 - custom_metric: 0.9652 - custom_loss: 0.1124 - val_loss: 2.0499 - val_custom_metric: 0.7442 - val_custom_loss: 2.0499\n",
            "Epoch 33/100\n",
            "1485/1485 [==============================] - 32s 22ms/step - loss: 0.1099 - custom_metric: 0.9653 - custom_loss: 0.1098 - val_loss: 2.0819 - val_custom_metric: 0.7449 - val_custom_loss: 2.0820\n",
            "Epoch 34/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1066 - custom_metric: 0.9663 - custom_loss: 0.1067 - val_loss: 2.1291 - val_custom_metric: 0.7441 - val_custom_loss: 2.1298\n",
            "Epoch 35/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1070 - custom_metric: 0.9661 - custom_loss: 0.1071 - val_loss: 2.0981 - val_custom_metric: 0.7441 - val_custom_loss: 2.0979\n",
            "Epoch 36/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1063 - custom_metric: 0.9661 - custom_loss: 0.1063 - val_loss: 2.1482 - val_custom_metric: 0.7432 - val_custom_loss: 2.1478\n",
            "Epoch 37/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1023 - custom_metric: 0.9671 - custom_loss: 0.1024 - val_loss: 2.1645 - val_custom_metric: 0.7418 - val_custom_loss: 2.1643\n",
            "Epoch 38/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1009 - custom_metric: 0.9673 - custom_loss: 0.1009 - val_loss: 2.1470 - val_custom_metric: 0.7434 - val_custom_loss: 2.1467\n",
            "Epoch 39/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.1013 - custom_metric: 0.9671 - custom_loss: 0.1013 - val_loss: 2.1878 - val_custom_metric: 0.7426 - val_custom_loss: 2.1887\n",
            "Epoch 40/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0985 - custom_metric: 0.9678 - custom_loss: 0.0985 - val_loss: 2.1993 - val_custom_metric: 0.7428 - val_custom_loss: 2.1994\n",
            "Epoch 41/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0977 - custom_metric: 0.9682 - custom_loss: 0.0977 - val_loss: 2.1834 - val_custom_metric: 0.7436 - val_custom_loss: 2.1832\n",
            "Epoch 42/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0972 - custom_metric: 0.9682 - custom_loss: 0.0972 - val_loss: 2.2198 - val_custom_metric: 0.7419 - val_custom_loss: 2.2195\n",
            "Epoch 43/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0949 - custom_metric: 0.9689 - custom_loss: 0.0949 - val_loss: 2.2548 - val_custom_metric: 0.7413 - val_custom_loss: 2.2546\n",
            "Epoch 44/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0946 - custom_metric: 0.9687 - custom_loss: 0.0946 - val_loss: 2.2466 - val_custom_metric: 0.7407 - val_custom_loss: 2.2467\n",
            "Epoch 45/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0938 - custom_metric: 0.9691 - custom_loss: 0.0938 - val_loss: 2.3040 - val_custom_metric: 0.7405 - val_custom_loss: 2.3039\n",
            "Epoch 46/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0929 - custom_metric: 0.9691 - custom_loss: 0.0928 - val_loss: 2.2418 - val_custom_metric: 0.7425 - val_custom_loss: 2.2429\n",
            "Epoch 47/100\n",
            "1485/1485 [==============================] - 31s 21ms/step - loss: 0.0910 - custom_metric: 0.9694 - custom_loss: 0.0910 - val_loss: 2.2880 - val_custom_metric: 0.7413 - val_custom_loss: 2.2876\n",
            "Epoch 48/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0911 - custom_metric: 0.9695 - custom_loss: 0.0911 - val_loss: 2.3000 - val_custom_metric: 0.7426 - val_custom_loss: 2.3007\n",
            "Epoch 49/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0896 - custom_metric: 0.9698 - custom_loss: 0.0896 - val_loss: 2.3069 - val_custom_metric: 0.7420 - val_custom_loss: 2.3073\n",
            "Epoch 50/100\n",
            "1485/1485 [==============================] - 31s 21ms/step - loss: 0.0893 - custom_metric: 0.9697 - custom_loss: 0.0893 - val_loss: 2.2861 - val_custom_metric: 0.7413 - val_custom_loss: 2.2867\n",
            "Epoch 51/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0882 - custom_metric: 0.9700 - custom_loss: 0.0883 - val_loss: 2.3189 - val_custom_metric: 0.7428 - val_custom_loss: 2.3192\n",
            "Epoch 52/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0867 - custom_metric: 0.9705 - custom_loss: 0.0867 - val_loss: 2.3254 - val_custom_metric: 0.7420 - val_custom_loss: 2.3253\n",
            "Epoch 53/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0878 - custom_metric: 0.9702 - custom_loss: 0.0878 - val_loss: 2.3447 - val_custom_metric: 0.7426 - val_custom_loss: 2.3443\n",
            "Epoch 54/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0864 - custom_metric: 0.9703 - custom_loss: 0.0864 - val_loss: 2.3521 - val_custom_metric: 0.7426 - val_custom_loss: 2.3519\n",
            "Epoch 55/100\n",
            "1485/1485 [==============================] - 31s 21ms/step - loss: 0.0852 - custom_metric: 0.9709 - custom_loss: 0.0852 - val_loss: 2.3900 - val_custom_metric: 0.7424 - val_custom_loss: 2.3894\n",
            "Epoch 56/100\n",
            "1485/1485 [==============================] - 31s 21ms/step - loss: 0.0852 - custom_metric: 0.9706 - custom_loss: 0.0852 - val_loss: 2.3665 - val_custom_metric: 0.7419 - val_custom_loss: 2.3668\n",
            "Epoch 57/100\n",
            "1485/1485 [==============================] - 31s 21ms/step - loss: 0.0848 - custom_metric: 0.9707 - custom_loss: 0.0848 - val_loss: 2.3818 - val_custom_metric: 0.7429 - val_custom_loss: 2.3808\n",
            "Epoch 58/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0831 - custom_metric: 0.9711 - custom_loss: 0.0831 - val_loss: 2.3832 - val_custom_metric: 0.7420 - val_custom_loss: 2.3825\n",
            "Epoch 59/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0835 - custom_metric: 0.9710 - custom_loss: 0.0836 - val_loss: 2.3695 - val_custom_metric: 0.7422 - val_custom_loss: 2.3696\n",
            "Epoch 60/100\n",
            "1485/1485 [==============================] - 32s 21ms/step - loss: 0.0821 - custom_metric: 0.9715 - custom_loss: 0.0822 - val_loss: 2.4321 - val_custom_metric: 0.7415 - val_custom_loss: 2.4335\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b7ba6b43e80>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2_s0ZQX5jmE",
        "outputId": "08dc99a4-7fb7-4ba7-821c-cd9565cc1f45"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'custom_metric', 'custom_loss', 'val_loss', 'val_custom_metric', 'val_custom_loss'])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(y=model.history.history['custom_loss'],mode=\"lines\"))\n",
        "fig.add_trace(go.Scatter(y=model.history.history['val_custom_loss'],mode=\"lines\"))\n",
        "fig.update_layout(title=\"Loss Train v/s Validation\")\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "JMwSURbZ5RQl",
        "outputId": "540459af-bc68-4975-8f79-c1fd41089d9c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"722f8798-f1b4-4a05-8b08-b7c81a29b421\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"722f8798-f1b4-4a05-8b08-b7c81a29b421\")) {                    Plotly.newPlot(                        \"722f8798-f1b4-4a05-8b08-b7c81a29b421\",                        [{\"mode\":\"lines\",\"y\":[0.5743511915206909,0.49807462096214294,0.4420662224292755,0.3954487442970276,0.3567962646484375,0.3223937153816223,0.29531699419021606,0.2713685631752014,0.25272834300994873,0.2352827936410904,0.22119352221488953,0.2088291198015213,0.1974325329065323,0.18826080858707428,0.18048839271068573,0.17195796966552734,0.16610966622829437,0.15973372757434845,0.15420259535312653,0.14928492903709412,0.14468064904212952,0.14047786593437195,0.1375197023153305,0.13332773745059967,0.12976840138435364,0.12656567990779877,0.1240052804350853,0.12152665853500366,0.11779902130365372,0.11609695106744766,0.11403190344572067,0.11244049668312073,0.10984960198402405,0.10665023326873779,0.10705273598432541,0.10633235424757004,0.1023833304643631,0.10089635103940964,0.1013278141617775,0.09850691258907318,0.09774597734212875,0.09720079600811005,0.09491581469774246,0.0946059301495552,0.09379414469003677,0.09284346550703049,0.09103798121213913,0.09110340476036072,0.08959763497114182,0.08934584259986877,0.08825770020484924,0.08667926490306854,0.08782869577407837,0.08639403432607651,0.08516586571931839,0.08522689342498779,0.08476319164037704,0.08308769762516022,0.08358065038919449,0.08215354382991791],\"type\":\"scatter\"},{\"mode\":\"lines\",\"y\":[1.1566065549850464,1.194671630859375,1.2341505289077759,1.2814234495162964,1.3210914134979248,1.3801506757736206,1.4272444248199463,1.4716174602508545,1.511279821395874,1.5626275539398193,1.600053071975708,1.61553156375885,1.6517218351364136,1.6890672445297241,1.7051341533660889,1.736456036567688,1.7547144889831543,1.7731629610061646,1.7914350032806396,1.808026671409607,1.8268516063690186,1.8769935369491577,1.8829153776168823,1.8996732234954834,1.9191114902496338,1.9195373058319092,1.9713128805160522,1.9860320091247559,2.006481885910034,1.9816454648971558,2.028251886367798,2.0498626232147217,2.0820136070251465,2.129793167114258,2.097911834716797,2.1477770805358887,2.1643424034118652,2.1467092037200928,2.1886847019195557,2.1993775367736816,2.1831908226013184,2.219541072845459,2.25461745262146,2.2466788291931152,2.3038787841796875,2.2429022789001465,2.2875871658325195,2.3007194995880127,2.3073103427886963,2.286712646484375,2.31916880607605,2.325331449508667,2.3442819118499756,2.35190749168396,2.3894410133361816,2.3667917251586914,2.380769729614258,2.3825409412384033,2.369560480117798,2.4334664344787598],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"title\":{\"text\":\"Loss Train v\\u002fs Validation\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('722f8798-f1b4-4a05-8b08-b7c81a29b421');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(y=model.history.history['custom_metric'],mode=\"lines\"))\n",
        "fig.add_trace(go.Scatter(y=model.history.history['val_custom_metric'],mode=\"lines\"))\n",
        "fig.update_layout(title=\"MaskedAccuracy Train v/s Validation\")\n",
        "fig.update_yaxes(range=[0,1])\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "a3iBRePM5_Gr",
        "outputId": "3e806212-7065-42ac-c356-214fcde8783c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"6a1fbfa3-8fbe-4b26-9c66-80a9d23a55bc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6a1fbfa3-8fbe-4b26-9c66-80a9d23a55bc\")) {                    Plotly.newPlot(                        \"6a1fbfa3-8fbe-4b26-9c66-80a9d23a55bc\",                        [{\"mode\":\"lines\",\"y\":[0.8450226783752441,0.8616483807563782,0.8749492168426514,0.8865371942520142,0.8965351581573486,0.9058247804641724,0.9128847122192383,0.9194928407669067,0.9251892566680908,0.9300760626792908,0.9342162609100342,0.9377322196960449,0.941024899482727,0.9439523816108704,0.9463502168655396,0.9490875005722046,0.9501996636390686,0.9522015452384949,0.9540415406227112,0.9556559324264526,0.9567273259162903,0.9580789804458618,0.9584853053092957,0.9597563147544861,0.9605019092559814,0.9617103934288025,0.9622474908828735,0.963032066822052,0.96372389793396,0.9640863537788391,0.9644798636436462,0.9651733636856079,0.965345025062561,0.9663233757019043,0.9660841226577759,0.966110348701477,0.9671097993850708,0.9673296213150024,0.9671451449394226,0.9677882194519043,0.968247652053833,0.9681674242019653,0.968897819519043,0.9686597585678101,0.9691168665885925,0.9690614938735962,0.9693571329116821,0.9694703221321106,0.969791829586029,0.9696556925773621,0.9700267910957336,0.9704760909080505,0.9701614379882812,0.9703323841094971,0.9708893895149231,0.970609724521637,0.970730185508728,0.9711226224899292,0.9709798097610474,0.971470057964325],\"type\":\"scatter\"},{\"mode\":\"lines\",\"y\":[0.7571958303451538,0.7568958401679993,0.755704939365387,0.7530760169029236,0.7522692680358887,0.752278745174408,0.7506859302520752,0.7496954202651978,0.7509436011314392,0.7486839890480042,0.7481839060783386,0.7470349073410034,0.7472073435783386,0.746043860912323,0.7463249564170837,0.7444424629211426,0.7466216683387756,0.7459768652915955,0.7445130348205566,0.7443896532058716,0.7466331124305725,0.7464242577552795,0.7449644207954407,0.7430694699287415,0.7445778846740723,0.7432668209075928,0.7467306852340698,0.7459839582443237,0.744586169719696,0.7442966103553772,0.7443116307258606,0.7441771626472473,0.7448830604553223,0.7441454529762268,0.7441227436065674,0.7431949973106384,0.7417834401130676,0.7433757185935974,0.7426283955574036,0.7428436875343323,0.7436145544052124,0.7419447302818298,0.7413477301597595,0.7406682372093201,0.7405138611793518,0.7424561977386475,0.74125075340271,0.7426477670669556,0.7420202493667603,0.7412601709365845,0.7428083419799805,0.7419623732566833,0.7425953149795532,0.7426018118858337,0.7423802018165588,0.7418906092643738,0.7429404258728027,0.7419771552085876,0.7421556115150452,0.7414976954460144],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"title\":{\"text\":\"MaskedAccuracy Train v\\u002fs Validation\"},\"yaxis\":{\"range\":[0,1]}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6a1fbfa3-8fbe-4b26-9c66-80a9d23a55bc');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}