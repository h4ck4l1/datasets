{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgdUPkLegOwqNwTGzqFTSk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h4ck4l1/datasets/blob/main/NLP_with_RNN_and_Attention/Transformers_subword_tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "U2DExYIq37KP"
      },
      "outputs": [],
      "source": [
        "import sys,os,warnings\n",
        "from zipfile import ZipFile\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "!pip3 install -q -U \"tensorflow-text==2.13.0\"\n",
        "!pip3 install -q -U einops\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_text as tftext\n",
        "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n",
        "import tensorflow_datasets as tfds\n",
        "import einops\n",
        "from IPython.display import clear_output\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "pio.templates.default == \"plotly_dark\"\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
        "file_path = keras.utils.get_file(fname=\"spa-eng.zip\",origin=url,extract=True)\n",
        "with ZipFile(file_path,\"r\") as f:\n",
        "    f.extractall(\"spa-eng\")\n",
        "with open(\"spa-eng/spa-eng/spa.txt\",\"r\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "en_text,es_text = zip(*[line.split(\"\\t\") for line in text.splitlines()])\n",
        "for en,es in zip(en_text[:10],es_text[:10]):\n",
        "    print(f\"{en} ----> {es}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u42XTMV_8ZJt",
        "outputId": "bc31b383-fa8b-437e-cbab-14a51f26f73b"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go. ----> Ve.\n",
            "Go. ----> Vete.\n",
            "Go. ----> Vaya.\n",
            "Go. ----> Váyase.\n",
            "Hi. ----> Hola.\n",
            "Run! ----> ¡Corre!\n",
            "Run. ----> Corred.\n",
            "Who? ----> ¿Quién?\n",
            "Fire! ----> ¡Fuego!\n",
            "Fire! ----> ¡Incendio!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting Dataset to vocabulary"
      ],
      "metadata": {
        "id": "xpIZkiORLgtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples,ds_info = tfds.load(\"ted_hrlr_translate/pt_to_en\",as_supervised=True,with_info=True)"
      ],
      "metadata": {
        "id": "0CnvHm5K-Qb_"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_pt,valid_ds_pt = examples['train'],examples['validation']"
      ],
      "metadata": {
        "id": "LQMrztpfJ6Ic"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for pt,en in train_ds_pt.take(10):\n",
        "    print(pt.numpy().decode(),\"----->\",en.numpy().decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fux4hFTmLAZ5",
        "outputId": "b523d8c8-39ab-4249-ad88-d988efdf385a"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade . -----> and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
            "mas e se estes fatores fossem ativos ? -----> but what if it were active ?\n",
            "mas eles não tinham a curiosidade de me testar . -----> but they did n't test for curiosity .\n",
            "e esta rebeldia consciente é a razão pela qual eu , como agnóstica , posso ainda ter fé . -----> and this conscious defiance is why i , as an agnostic , can still have faith .\n",
            "`` `` '' podem usar tudo sobre a mesa no meu corpo . '' -----> you can use everything on the table on me .\n",
            "`` eu escrevo muito acerca do `` '' teatro de segurança '' '' , que são produtos que fazem as pessoas sentirem-se seguras mas que , na realidade , não fazem nada . '' -----> `` i write a lot about `` '' security theater , '' '' which are products that make people feel secure , but do n't actually do anything . ''\n",
            "colocaram-no bem no fundo duma mina de ferro no minnesota , nos últimos dois dias anunciaram os resultados mais sensíveis até agora . -----> and they 've put it deep down in an iron mine in minnesota , ok , deep under the ground , and in fact , in the last couple of days announced the most sensitive results so far .\n",
            "algumas pessoas têm medo de que não gostem delas . -----> see , some people might fear girls not liking them back .\n",
            "não , o que nos aconteceu , chris , é que o poder , o preço está fixado fora da margem . -----> no , what happened to us , chris , is that power , it 's priced off the margin .\n",
            "de volta à minha pergunta : porque é que fiquei ? -----> back to my question : why did i stay ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer_params = dict(lower_case=True)\n",
        "reserved_tokens = [\"[PAD]\",\"[UNK]\",\"[START]\",\"[END]\"]\n",
        "bert_vocab_args = dict(\n",
        "    vocab_size=8000,\n",
        "    reserved_tokens=reserved_tokens,\n",
        "    bert_tokenizer_params=bert_tokenizer_params,\n",
        "    learn_params={}\n",
        ")"
      ],
      "metadata": {
        "id": "8mhTCNl6LZoY"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt_vocab = bert_vocab.bert_vocab_from_dataset(\n",
        "    train_ds_pt.map(lambda x,y:x).prefetch(2),\n",
        "    **bert_vocab_args\n",
        ")"
      ],
      "metadata": {
        "id": "WlSDKy3yMj07"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_vocab = bert_vocab.bert_vocab_from_dataset(\n",
        "    train_ds_pt.map(lambda x,y:y).prefetch(2),\n",
        "    **bert_vocab_args\n",
        ")"
      ],
      "metadata": {
        "id": "Zo10T-62Mwru"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pt_vocab[:10])\n",
        "print(pt_vocab[100:110])\n",
        "print(pt_vocab[1000:1010])\n",
        "print(pt_vocab[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSuh8VaANe3s",
        "outputId": "be2a913c-7f52-439d-cdaa-40a25fdc9e9b"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[PAD]', '[UNK]', '[START]', '[END]', '!', '#', '$', '%', '&', \"'\"]\n",
            "['no', 'por', 'mais', 'na', 'eu', 'esta', 'muito', 'isso', 'isto', 'sao']\n",
            "['90', 'desse', 'efeito', 'malaria', 'normalmente', 'palestra', 'recentemente', '##nca', 'bons', 'chave']\n",
            "['##–', '##—', '##‘', '##’', '##“', '##”', '##⁄', '##€', '##♪', '##♫']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(en_vocab[:10])\n",
        "print(en_vocab[100:110])\n",
        "print(en_vocab[1000:1010])\n",
        "print(en_vocab[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frcZFuTBO-KJ",
        "outputId": "fdc0a3fa-b92c-437c-8e34-92beb933ce16"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[PAD]', '[UNK]', '[START]', '[END]', '!', '#', '$', '%', '&', \"'\"]\n",
            "['as', 'all', 'at', 'one', 'people', 're', 'like', 'if', 'our', 'from']\n",
            "['choose', 'consider', 'extraordinary', 'focus', 'generation', 'killed', 'patterns', 'putting', 'scientific', 'wait']\n",
            "['##_', '##`', '##ย', '##ร', '##อ', '##–', '##—', '##’', '##♪', '##♫']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/pt_vocab.txt\",\"w\") as f:\n",
        "    for token in pt_vocab:\n",
        "        print(token,file=f)\n",
        "\n",
        "with open(\"/content/en_vocab.txt\",\"w\") as f:\n",
        "    for token in en_vocab:\n",
        "        print(token,file=f)"
      ],
      "metadata": {
        "id": "OKdD7Db_PjYW"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize(sentence:str):\n",
        "    sentence = tftext.normalize_utf8(sentence,\"NFKD\")\n",
        "    sentence = tf.strings.lower(sentence)\n",
        "    sentence = tf.strings.regex_replace(sentence,r\"[^ a-z.,?!¡]\",\"\")\n",
        "    sentence = tf.strings.regex_replace(sentence,r\"[.,?!¡]\",r\" \\0 \")\n",
        "    sentence = tf.strings.strip(sentence)\n",
        "    sentence = tf.strings.join([\"[START]\",sentence,\"[END]\"],\" \")\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "eSC9Vgc7dXob"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_vec_layer = keras.layers.TextVectorization(8000,standardize=standardize,ragged=True)\n",
        "es_vec_layer = keras.layers.TextVectorization(8000,standardize=standardize,ragged=True)\n",
        "en_vec_layer.adapt(np.array(en_text))\n",
        "es_vec_layer.adapt(np.array(es_text))"
      ],
      "metadata": {
        "id": "Fn9hvMibbH-M"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_vec_layer.get_vocabulary()[-10:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iYZNQ3QfDVj",
        "outputId": "4c79799b-5ee3-4d42-b166-9291fc90cff5"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['landlord',\n",
              " 'lame',\n",
              " 'lamb',\n",
              " 'lakes',\n",
              " 'lagoon',\n",
              " 'lactose',\n",
              " 'kumi',\n",
              " 'kublai',\n",
              " 'koalas',\n",
              " 'knitted']"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es_text = np.array(es_text)\n",
        "en_text = np.array(en_text)"
      ],
      "metadata": {
        "id": "WoXu11rSjHZn"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize(sentence:str):\n",
        "    sentence = tftext.normalize_utf8(sentence,\"NFKD\")\n",
        "    sentence = tf.strings.lower(sentence)\n",
        "    sentence = tf.strings.regex_replace(sentence,r\"[^ a-z.,?!¡]\",\"\")\n",
        "    sentence = tf.strings.regex_replace(sentence,r\"[.,?!¡]\",r\" \\0 \")\n",
        "    sentence = tf.strings.strip(sentence)\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "WKyhmthTjupq"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spa_ds = tf.data.Dataset.from_tensor_slices(es_text)\n",
        "spa_ds = spa_ds.map(standardize)\n",
        "\n",
        "en_ds = tf.data.Dataset.from_tensor_slices(en_text)\n",
        "en_ds = en_ds.map(standardize)"
      ],
      "metadata": {
        "id": "ugMl9e9vggyq"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer_params = dict(normalization_form=\"NFKD\")\n",
        "bert_vocab_args = dict(\n",
        "    vocab_size=5000,\n",
        "    reserved_tokens=[\"[PAD]\",\"[UNK]\",\"[START]\",\"[END]\"],\n",
        "    bert_tokenizer_params=bert_tokenizer_params,\n",
        "    learn_params={}\n",
        ")"
      ],
      "metadata": {
        "id": "B5XSkPQdlJyv"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spa_vocab = bert_vocab.bert_vocab_from_dataset(\n",
        "    spa_ds,\n",
        "    **bert_vocab_args\n",
        ")"
      ],
      "metadata": {
        "id": "yxdRZw7kk3Gb"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_vocab = bert_vocab.bert_vocab_from_dataset(\n",
        "    en_ds,\n",
        "    **bert_vocab_args\n",
        ")"
      ],
      "metadata": {
        "id": "Gb3Qqx4Hl2v2"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(spa_vocab))\n",
        "print(spa_vocab[:10])\n",
        "print(spa_vocab[100:110])\n",
        "print(spa_vocab[1000:1010])\n",
        "print(spa_vocab[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6c0SzyAlyMs",
        "outputId": "d74956af-5029-4d72-fd9f-69ed38825e3a"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4870\n",
            "['[PAD]', '[UNK]', '[START]', '[END]', '!', ',', '.', '?', 'a', 'b']\n",
            "['puede', 'he', 'bien', 'estas', 'mucho', '##mos', '##te', 'ellos', 'nos', 'quien']\n",
            "['supongo', 'caliente', 'cielo', 'empezar', 'jefe', 'mirando', 'ninguno', 'rojo', 'viendo', '##u']\n",
            "['volviera', '##!', '##,', '##.', '##?', '##f', '##j', '##q', '##v', '##¡']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(en_vocab))\n",
        "print(en_vocab[:10])\n",
        "print(en_vocab[100:110])\n",
        "print(en_vocab[1000:1010])\n",
        "print(en_vocab[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmrHtiajnOXE",
        "outputId": "4c21bf56-e867-40db-e133-bb7fcdb19f9b"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4563\n",
            "['[PAD]', '[UNK]', '[START]', '[END]', '!', ',', '.', '?', 'a', 'b']\n",
            "['one', 'doesnt', 'going', 'by', 'would', 'why', 'come', 'see', 'good', 'ill']\n",
            "['mustve', 'novel', 'shot', 'surprise', 'taxi', 'voice', '##man', 'cooking', 'enemy', 'honest']\n",
            "['yell', 'youngest', 'youth', '##!', '##,', '##.', '##?', '##j', '##q', '##v']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/spa_vocab.txt\",\"w\") as f:\n",
        "    for token in spa_vocab:\n",
        "        print(token,file=f)\n",
        "\n",
        "with open(\"/content/en_spa_vocab.txt\",\"w\") as f:\n",
        "    for token in en_vocab:\n",
        "        print(token,file=f)"
      ],
      "metadata": {
        "id": "6eaRCPz238PH"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spa_tokenizer = tftext.BertTokenizer(\"/content/spa_vocab.txt\",**bert_tokenizer_params)\n",
        "en_tokenizer = tftext.BertTokenizer(\"/content/en_spa_vocab.txt\",**bert_tokenizer_params)"
      ],
      "metadata": {
        "id": "aFqIi1095bXc"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for es_in in spa_ds.take(10):\n",
        "    print(es_in)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7EXpKAb8In_",
        "outputId": "ac7127a8-2345-4261-bee3-936aff33977b"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b've .', shape=(), dtype=string)\n",
            "tf.Tensor(b'vete .', shape=(), dtype=string)\n",
            "tf.Tensor(b'vaya .', shape=(), dtype=string)\n",
            "tf.Tensor(b'vayase .', shape=(), dtype=string)\n",
            "tf.Tensor(b'hola .', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xc2\\xa1 corre !', shape=(), dtype=string)\n",
            "tf.Tensor(b'corred .', shape=(), dtype=string)\n",
            "tf.Tensor(b'quien ?', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xc2\\xa1 fuego !', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xc2\\xa1 incendio !', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for en_in in en_ds.take(10):\n",
        "    print(en_in)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH5bNar08f0U",
        "outputId": "a42df3ce-b955-4616-e90d-cd5e355aa876"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'go .', shape=(), dtype=string)\n",
            "tf.Tensor(b'go .', shape=(), dtype=string)\n",
            "tf.Tensor(b'go .', shape=(), dtype=string)\n",
            "tf.Tensor(b'go .', shape=(), dtype=string)\n",
            "tf.Tensor(b'hi .', shape=(), dtype=string)\n",
            "tf.Tensor(b'run !', shape=(), dtype=string)\n",
            "tf.Tensor(b'run .', shape=(), dtype=string)\n",
            "tf.Tensor(b'who ?', shape=(), dtype=string)\n",
            "tf.Tensor(b'fire !', shape=(), dtype=string)\n",
            "tf.Tensor(b'fire !', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es_examples = tf.convert_to_tensor(standardize(es_text[1000:1010]))"
      ],
      "metadata": {
        "id": "rtGGIHON9U-Q"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es_tokenized = spa_tokenizer.tokenize(es_examples).merge_dims(-2,-1)\n",
        "es_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5yOb37l88e7",
        "outputId": "84361aec-f062-49f1-c439-e21f1ce5ae18"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[37, 42, 11, 4866, 6], [34, 37, 46, 77, 4], [37, 42, 14, 1566, 4656, 6],\n",
              " [37, 42, 981, 6], [37, 42, 14, 4107, 3382, 6],\n",
              " [37, 42, 45, 832, 4867, 4387, 6], [37, 42, 427, 6],\n",
              " [37, 44, 25, 136, 233, 6], [48, 163, 37, 6], [48, 2184, 6]]>"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in es_tokenized.to_list():\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XH0Ha3j90_h",
        "outputId": "e1e090a2-ca10-4685-821a-c144eed96ce6"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[37, 42, 11, 4866, 6]\n",
            "[34, 37, 46, 77, 4]\n",
            "[37, 42, 14, 1566, 4656, 6]\n",
            "[37, 42, 981, 6]\n",
            "[37, 42, 14, 4107, 3382, 6]\n",
            "[37, 42, 45, 832, 4867, 4387, 6]\n",
            "[37, 42, 427, 6]\n",
            "[37, 44, 25, 136, 233, 6]\n",
            "[48, 163, 37, 6]\n",
            "[48, 2184, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The strings got joined with the suffixe separator\n",
        "for i in tf.strings.reduce_join(tf.gather(spa_vocab,es_tokenized),separator=\" \",axis=-1):\n",
        "    print(i.numpy().decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6og6pVRZDhVA",
        "outputId": "a089c3f8-240b-403b-b3eb-74b2bb9f2d36"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el es d ##j .\n",
            "¡ el esta aqui !\n",
            "el es g ##en ##til .\n",
            "el es amable .\n",
            "el es g ##ene ##roso .\n",
            "el es me ##z ##q ##uino .\n",
            "el es alto .\n",
            "el se r ##e ##ia .\n",
            "lo hizo el .\n",
            "lo logro .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in tf.strings.reduce_join(spa_tokenizer.detokenize(es_tokenized),separator=\" \",axis=-1):\n",
        "    print(i.numpy().decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZtxnCMYEF5t",
        "outputId": "97ed663f-15a8-4578-e344-95583b8cbb8f"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el es dj .\n",
            "¡ el esta aqui !\n",
            "el es gentil .\n",
            "el es amable .\n",
            "el es generoso .\n",
            "el es mezquino .\n",
            "el es alto .\n",
            "el se reia .\n",
            "lo hizo el .\n",
            "lo logro .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in en_text[-10:]:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DmYyOWXj1Wo",
        "outputId": "c73caa6e-b2c9-4bb9-f96f-357d9e013f1e"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You can't view Flash content on an iPad. However, you can easily email yourself the URLs of these web pages and view that content on your regular computer when you get home.\n",
            "A mistake young people often make is to start learning too many languages at the same time, as they underestimate the difficulties and overestimate their own ability to learn them.\n",
            "No matter how much you try to convince people that chocolate is vanilla, it'll still be chocolate, even though you may manage to convince yourself and a few others that it's vanilla.\n",
            "In 1969, Roger Miller recorded a song called \"You Don't Want My Love.\" Today, this song is better known as \"In the Summer Time.\" It's the first song he wrote and sang that became popular.\n",
            "A child who is a native speaker usually knows many things about his or her language that a non-native speaker who has been studying for years still does not know and perhaps will never know.\n",
            "There are four main causes of alcohol-related death. Injury from car accidents or violence is one. Diseases like cirrhosis of the liver, cancer, heart and blood system diseases are the others.\n",
            "There are mothers and fathers who will lie awake after the children fall asleep and wonder how they'll make the mortgage, or pay their doctor's bills, or save enough for their child's college education.\n",
            "A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climate change.\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\n",
            "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_examples = en_tokenizer.tokenize(standardize(en_text[-10:]))\n",
        "en_examples = en_examples.merge_dims(-2,-1)\n",
        "for i in en_examples.to_list():\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "X0q9sZK3EhT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed64470-2f11-4c09-acf1-1f9b2eab61b1"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[36, 96, 1572, 13, 4252, 3586, 59, 98, 2698, 6, 2295, 5, 36, 71, 969, 1659, 409, 34, 28, 510, 1712, 41, 245, 2864, 2825, 65, 1572, 42, 3586, 59, 58, 3655, 612, 94, 36, 92, 140, 6]\n",
            "[8, 498, 357, 141, 293, 164, 38, 35, 442, 873, 127, 147, 945, 67, 34, 303, 79, 5, 82, 78, 3483, 34, 3064, 65, 212, 1108, 3723, 258, 381, 1894, 35, 331, 222, 6]\n",
            "[99, 423, 80, 133, 36, 294, 35, 1196, 141, 42, 1505, 38, 29, 994, 2328, 515, 5, 944, 189, 60, 1505, 5, 286, 906, 36, 217, 3089, 35, 1196, 409, 65, 8, 353, 634, 42, 76, 29, 994, 2328, 515, 6]\n",
            "[40, 5, 25, 2885, 309, 20, 2328, 309, 2199, 153, 8, 518, 445, 36, 52, 62, 49, 182, 6, 174, 5, 47, 518, 38, 219, 762, 82, 40, 34, 524, 79, 6, 76, 34, 230, 518, 39, 658, 65, 1334, 42, 586, 1110, 6]\n",
            "[8, 410, 113, 38, 8, 1103, 1394, 475, 292, 147, 291, 87, 55, 207, 73, 506, 42, 8, 99, 552, 3971, 1394, 113, 74, 114, 533, 50, 213, 189, 159, 63, 68, 65, 1637, 75, 124, 68, 6]\n",
            "[77, 53, 670, 2141, 2490, 41, 2404, 1576, 742, 1319, 574, 6, 40, 4560, 2478, 95, 137, 1748, 207, 1849, 38, 100, 6, 3801, 66, 10, 2267, 510, 1077, 1784, 1521, 41, 34, 218, 510, 5, 1292, 5, 756, 65, 1070, 1778, 3801, 53, 34, 634, 6]\n",
            "[77, 53, 1613, 65, 1174, 113, 75, 636, 1404, 211, 34, 243, 1146, 689, 65, 592, 80, 1397, 164, 34, 20, 1060, 485, 1934, 1088, 5, 207, 351, 258, 1658, 3359, 5, 207, 992, 272, 50, 258, 4034, 1017, 1792, 6]\n",
            "[8, 137, 2567, 979, 1034, 3985, 38, 34, 2030, 41, 137, 2567, 11, 2211, 3038, 2070, 4475, 42, 57, 23, 4289, 246, 2576, 82, 8, 1516, 41, 146, 1715, 854, 4562, 1981, 6, 128, 141, 294, 35, 3654, 258, 137, 2567, 979, 1034, 3985, 290, 78, 53, 2282, 87, 1689, 482, 6]\n",
            "[406, 77, 53, 475, 20, 3174, 485, 1710, 934, 1974, 69, 59, 155, 998, 3905, 5, 16, 475, 112, 10, 742, 2396, 34, 144, 1158, 94, 16, 838, 59, 155, 2864, 1034, 1088, 42, 74, 4476, 1937, 8, 246, 3342, 485, 3159, 6, 16, 112, 72, 35, 34, 233, 1801, 297, 103, 72, 2885, 934, 65, 325, 50, 130, 859, 16, 510, 510, 2744, 6]\n",
            "[97, 36, 62, 35, 772, 66, 8, 1103, 1394, 5, 36, 177, 60, 1573, 35, 2196, 638, 34, 303, 1136, 212, 65, 212, 40, 34, 303, 201, 42, 9, 994, 4560, 668, 2535, 2196, 34, 303, 23, 4234, 212, 65, 212, 385, 78, 71, 232, 43, 4044, 65, 67, 34, 11, 502, 1711, 246, 27, 3716, 1034, 668, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in tf.strings.reduce_join(en_tokenizer.detokenize(en_examples),separator=\" \",axis=-1):\n",
        "    print(i.numpy().decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXYqrBsOkUft",
        "outputId": "e22ed59f-77f9-4cb3-e21c-e9de5e0920d3"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you cant view flash content on an ipad . however , you can easily email yourself the urls of these web pages and view that content on your regular computer when you get home .\n",
            "a mistake young people often make is to start learning too many languages at the same time , as they underestimate the difficulties and overestimate their own ability to learn them .\n",
            "no matter how much you try to convince people that chocolate is vanilla , itll still be chocolate , even though you may manage to convince yourself and a few others that its vanilla .\n",
            "in , roger miller recorded a song called you dont want my love . today , this song is better known as in the summer time . its the first song he wrote and sang that became popular .\n",
            "a child who is a native speaker usually knows many things about his or her language that a nonnative speaker who has been studying for years still does not know and perhaps will never know .\n",
            "there are four main causes of alcoholrelated death . injury from car accidents or violence is one . diseases like cirrhosis of the liver , cancer , heart and blood system diseases are the others .\n",
            "there are mothers and fathers who will lie awake after the children fall asleep and wonder how theyll make the mortgage , or pay their doctors bills , or save enough for their childs college education .\n",
            "a carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities . some people try to reduce their carbon footprint because they are concerned about climate change .\n",
            "since there are usually multiple websites on any given topic , i usually just click the back button when i arrive on any webpage that has popup advertising . i just go to the next page found by google and hope for something less irritating .\n",
            "if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "START = tf.argmax(tf.constant(reserved_tokens) == \"[START]\")\n",
        "START"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt6OZDgRkuHW",
        "outputId": "5f2b2c32-72e6-4d00-ace4-69739b9a7e95"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=2>"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "END = tf.argmax(tf.constant(reserved_tokens) == \"[END]\")\n",
        "END"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29zx8mp6oHTo",
        "outputId": "8538f815-79f2-4f26-87e1-8a6d9b33787b"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=3>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = tf.fill(dims=[10,1],value=START)\n",
        "end_token = tf.fill(dims=[10,1],value=END)"
      ],
      "metadata": {
        "id": "BlXJigHXoLKv"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3thuTMCrrEcu",
        "outputId": "73b0bbfe-19d8-4c10-f135-fcf1867a4d5f"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=int64, numpy=\n",
              "array([[2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2]])>"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in tf.strings.reduce_join(spa_tokenizer.detokenize(tf.concat([start_token,es_tokenized,end_token],axis=-1)),separator=\" \",axis=-1).numpy():\n",
        "    print(i.decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPGXPR05sCEg",
        "outputId": "c9035d9c-05ff-4916-9435-e3224a7239e7"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[START] ve . [END]\n",
            "[START] vete . [END]\n",
            "[START] vaya . [END]\n",
            "[START] vayase . [END]\n",
            "[START] hola . [END]\n",
            "[START] ¡ corre ! [END]\n",
            "[START] corred . [END]\n",
            "[START] quien ? [END]\n",
            "[START] ¡ fuego ! [END]\n",
            "[START] ¡ incendio ! [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = en_tokenizer.detokenize(en_examples)\n",
        "all_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHtmvQ7N3Wlj",
        "outputId": "8752c2d2-26e2-4b3a-a540-152f4a54599d"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'you', b'cant', b'view', b'flash', b'content', b'on', b'an', b'ipad',\n",
              "  b'.', b'however', b',', b'you', b'can', b'easily', b'email', b'yourself',\n",
              "  b'the', b'urls', b'of', b'these', b'web', b'pages', b'and', b'view',\n",
              "  b'that', b'content', b'on', b'your', b'regular', b'computer', b'when',\n",
              "  b'you', b'get', b'home', b'.']                                           ,\n",
              " [b'a', b'mistake', b'young', b'people', b'often', b'make', b'is', b'to',\n",
              "  b'start', b'learning', b'too', b'many', b'languages', b'at', b'the',\n",
              "  b'same', b'time', b',', b'as', b'they', b'underestimate', b'the',\n",
              "  b'difficulties', b'and', b'overestimate', b'their', b'own', b'ability',\n",
              "  b'to', b'learn', b'them', b'.']                                        ,\n",
              " [b'no', b'matter', b'how', b'much', b'you', b'try', b'to', b'convince',\n",
              "  b'people', b'that', b'chocolate', b'is', b'vanilla', b',', b'itll',\n",
              "  b'still', b'be', b'chocolate', b',', b'even', b'though', b'you', b'may',\n",
              "  b'manage', b'to', b'convince', b'yourself', b'and', b'a', b'few',\n",
              "  b'others', b'that', b'its', b'vanilla', b'.']                           ,\n",
              " [b'in', b',', b'roger', b'miller', b'recorded', b'a', b'song', b'called',\n",
              "  b'you', b'dont', b'want', b'my', b'love', b'.', b'today', b',', b'this',\n",
              "  b'song', b'is', b'better', b'known', b'as', b'in', b'the', b'summer',\n",
              "  b'time', b'.', b'its', b'the', b'first', b'song', b'he', b'wrote', b'and',\n",
              "  b'sang', b'that', b'became', b'popular', b'.']                            ,\n",
              " [b'a', b'child', b'who', b'is', b'a', b'native', b'speaker', b'usually',\n",
              "  b'knows', b'many', b'things', b'about', b'his', b'or', b'her',\n",
              "  b'language', b'that', b'a', b'nonnative', b'speaker', b'who', b'has',\n",
              "  b'been', b'studying', b'for', b'years', b'still', b'does', b'not',\n",
              "  b'know', b'and', b'perhaps', b'will', b'never', b'know', b'.']         ,\n",
              " [b'there', b'are', b'four', b'main', b'causes', b'of', b'alcoholrelated',\n",
              "  b'death', b'.', b'injury', b'from', b'car', b'accidents', b'or',\n",
              "  b'violence', b'is', b'one', b'.', b'diseases', b'like', b'cirrhosis',\n",
              "  b'of', b'the', b'liver', b',', b'cancer', b',', b'heart', b'and',\n",
              "  b'blood', b'system', b'diseases', b'are', b'the', b'others', b'.']      ,\n",
              " [b'there', b'are', b'mothers', b'and', b'fathers', b'who', b'will', b'lie',\n",
              "  b'awake', b'after', b'the', b'children', b'fall', b'asleep', b'and',\n",
              "  b'wonder', b'how', b'theyll', b'make', b'the', b'mortgage', b',', b'or',\n",
              "  b'pay', b'their', b'doctors', b'bills', b',', b'or', b'save', b'enough',\n",
              "  b'for', b'their', b'childs', b'college', b'education', b'.']              ,\n",
              " [b'a', b'carbon', b'footprint', b'is', b'the', b'amount', b'of', b'carbon',\n",
              "  b'dioxide', b'pollution', b'that', b'we', b'produce', b'as', b'a',\n",
              "  b'result', b'of', b'our', b'activities', b'.', b'some', b'people', b'try',\n",
              "  b'to', b'reduce', b'their', b'carbon', b'footprint', b'because', b'they',\n",
              "  b'are', b'concerned', b'about', b'climate', b'change', b'.']              ,\n",
              " [b'since', b'there', b'are', b'usually', b'multiple', b'websites', b'on',\n",
              "  b'any', b'given', b'topic', b',', b'i', b'usually', b'just', b'click',\n",
              "  b'the', b'back', b'button', b'when', b'i', b'arrive', b'on', b'any',\n",
              "  b'webpage', b'that', b'has', b'popup', b'advertising', b'.', b'i',\n",
              "  b'just', b'go', b'to', b'the', b'next', b'page', b'found', b'by',\n",
              "  b'google', b'and', b'hope', b'for', b'something', b'less', b'irritating',\n",
              "  b'.']                                                                    ,\n",
              " [b'if', b'you', b'want', b'to', b'sound', b'like', b'a', b'native',\n",
              "  b'speaker', b',', b'you', b'must', b'be', b'willing', b'to', b'practice',\n",
              "  b'saying', b'the', b'same', b'sentence', b'over', b'and', b'over', b'in',\n",
              "  b'the', b'same', b'way', b'that', b'banjo', b'players', b'practice',\n",
              "  b'the', b'same', b'phrase', b'over', b'and', b'over', b'until', b'they',\n",
              "  b'can', b'play', b'it', b'correctly', b'and', b'at', b'the', b'desired',\n",
              "  b'tempo', b'.']                                                          ]>"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "bad_tokens = [re.escape(tok) for tok in reserved_tokens if not tok == \"[UNK]\"]\n",
        "bad_words = \"|\".join(bad_tokens)\n",
        "mask = tf.strings.regex_full_match(all_words,bad_words)\n",
        "filtered_words = tf.ragged.boolean_mask(all_words,~mask)\n",
        "tf.strings.reduce_join(filtered_words,separator=\" \",axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wROG75FAtWY2",
        "outputId": "fa55fac5-8cba-4fd4-ebd7-dc3c6f941bf9"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b'you cant view flash content on an ipad . however , you can easily email yourself the urls of these web pages and view that content on your regular computer when you get home .',\n",
              "       b'a mistake young people often make is to start learning too many languages at the same time , as they underestimate the difficulties and overestimate their own ability to learn them .',\n",
              "       b'no matter how much you try to convince people that chocolate is vanilla , itll still be chocolate , even though you may manage to convince yourself and a few others that its vanilla .',\n",
              "       b'in , roger miller recorded a song called you dont want my love . today , this song is better known as in the summer time . its the first song he wrote and sang that became popular .',\n",
              "       b'a child who is a native speaker usually knows many things about his or her language that a nonnative speaker who has been studying for years still does not know and perhaps will never know .',\n",
              "       b'there are four main causes of alcoholrelated death . injury from car accidents or violence is one . diseases like cirrhosis of the liver , cancer , heart and blood system diseases are the others .',\n",
              "       b'there are mothers and fathers who will lie awake after the children fall asleep and wonder how theyll make the mortgage , or pay their doctors bills , or save enough for their childs college education .',\n",
              "       b'a carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities . some people try to reduce their carbon footprint because they are concerned about climate change .',\n",
              "       b'since there are usually multiple websites on any given topic , i usually just click the back button when i arrive on any webpage that has popup advertising . i just go to the next page found by google and hope for something less irritating .',\n",
              "       b'if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo .'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJT1Qh-A9HUQ",
        "outputId": "12ad41d9-9604-4724-ef83-0a498e0934ee"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en_spa_vocab.txt  pt_vocab.txt\tspa-eng\n",
            "en_vocab.txt\t  sample_data\tspa_vocab.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_PcdfWHa-dki"
      },
      "execution_count": 152,
      "outputs": []
    }
  ]
}