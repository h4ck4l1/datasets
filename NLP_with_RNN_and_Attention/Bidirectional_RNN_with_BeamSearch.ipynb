{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM5xcX+UgrqYkxV9Fp8ZlH8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h4ck4l1/datasets/blob/main/NLP_with_RNN_and_Attention/Bidirectional_RNN_with_BeamSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J2Ymkj8050Gg"
      },
      "outputs": [],
      "source": [
        "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import os,warnings\n",
        "os.environ[\"TF_MIN_LOG_LEVEL\"] = \"3\"\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from zipfile import ZipFile\n",
        "import plotly.graph_objects as go\n",
        "tf.get_logger().setLevel(\"ERROR\")"
      ],
      "metadata": {
        "id": "5DUgYlif53o8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "metadata": {
        "id": "nhnNGhvh72zs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(\"/job:localhost\"):\n",
        "    file_path = keras.utils.get_file(fname=\"/content/spa-eng.zip\",origin=url,extract=True)\n",
        "    with ZipFile(file_path,\"r\") as f:\n",
        "        f.extractall(\"/content/spa-eng\")\n",
        "    with open(\"/content/spa-eng/spa-eng/spa.txt\",\"r\") as f:\n",
        "        text = f.read()\n",
        "    text = text.replace(\"¿\",\"\").replace(\"¡\",\"\")\n",
        "    en_text,es_text = zip(*[line.split(\"\\t\") for line in text.splitlines()])"
      ],
      "metadata": {
        "id": "7FDVsyEJ81ba"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_layers(en_text,es_text,vocab_size=1000,seq_length=50):\n",
        "\n",
        "    en_vec_layer = keras.layers.TextVectorization(vocab_size,output_sequence_length=seq_length)\n",
        "    es_vec_layer = keras.layers.TextVectorization(vocab_size,output_sequence_length=seq_length)\n",
        "    en_vec_layer.adapt(en_text)\n",
        "    es_vec_layer.adapt([f\"soseq {s} eoseq\" for s in es_text])\n",
        "    return en_vec_layer,es_vec_layer"
      ],
      "metadata": {
        "id": "camsk92k-KIr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(en_vec_layer,es_vec_layer,en_text,es_text,train_size):\n",
        "\n",
        "    x_train = en_vec_layer(tf.constant(en_text[:train_size]))\n",
        "    x_valid = en_vec_layer(tf.constant(en_text[train_size:]))\n",
        "    x_dec_train = es_vec_layer(tf.constant([f\"soseq {s}\" for s in es_text[:train_size]]))\n",
        "    x_dec_valid = es_vec_layer(tf.constant([f\"soseq {s}\" for s in es_text[train_size:]]))\n",
        "    y_train = es_vec_layer(tf.constant([f\"{s} eoseq\" for s in es_text[:train_size]]))\n",
        "    y_valid = es_vec_layer(tf.constant([f\"{s} eoseq\" for s in es_text[train_size:]]))\n",
        "    return (x_train,x_dec_train),y_train,(x_valid,x_dec_valid),y_valid"
      ],
      "metadata": {
        "id": "kZ6ScLGNMEGH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BeamSearch(keras.Model):\n",
        "\n",
        "    def __init__(self,vocab_size=1000,embed_size=128,**kwargs):\n",
        "\n",
        "        super(BeamSearch,self).__init__(**kwargs)\n",
        "        self.en_embed = keras.layers.Embedding(vocab_size,embed_size,mask_zero=True)\n",
        "        self.es_embed = keras.layers.Embedding(vocab_size,embed_size,mask_zero=True)\n",
        "        self.encoder = keras.layers.Bidirectional(keras.layers.LSTM(256,return_state=True))\n",
        "        self.decoder = keras.layers.LSTM(512,return_sequences=True)\n",
        "        self.out = keras.layers.Dense(vocab_size,\"softmax\")\n",
        "\n",
        "    def call(self,inputs):\n",
        "\n",
        "        encoder_inputs = inputs[0]\n",
        "        decoder_inputs = inputs[1]\n",
        "        encoder_embed_out = self.en_embed(encoder_inputs)\n",
        "        decoder_embed_out = self.es_embed(decoder_inputs)\n",
        "        encoder_out, *encoder_state_out = self.encoder(encoder_embed_out)\n",
        "        final_encoder_state = [tf.concat(encoder_state_out[::2],axis=-1),tf.concat(encoder_state_out[1::2],axis=-1)]\n",
        "        decoder_out = self.decoder(decoder_embed_out,initial_state=final_encoder_state)\n",
        "        return self.out(decoder_out)\n"
      ],
      "metadata": {
        "id": "mhqzPcV1NWWw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def piecewise(epoch,lr):\n",
        "    if epoch < 6:\n",
        "        return lr\n",
        "    elif epoch < 10:\n",
        "        return 5e-4\n",
        "    else:\n",
        "        return 5e-4 * tf.math.exp(-0.1695*(epoch-10))\n",
        "\n",
        "with strategy.scope():\n",
        "    BATCH_SIZE = 50*8\n",
        "    train_size = 100_000\n",
        "    valid_size = len(en_text) - train_size\n",
        "    train_steps = train_size//BATCH_SIZE\n",
        "    valid_steps = valid_size//BATCH_SIZE\n",
        "    en_vec_layer,es_vec_layer = get_layers(en_text,es_text)\n",
        "    X_train,y_train,X_valid,y_valid = get_data(en_vec_layer,es_vec_layer,en_text,es_text,train_size)\n",
        "    lr_call = keras.callbacks.LearningRateScheduler(piecewise)\n",
        "    beam_model = BeamSearch()\n",
        "    beam_model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=keras.optimizers.AdamW(learning_rate=1e-3),\n",
        "        metrics=[\"accuracy\"],\n",
        "        steps_per_execution=20\n",
        "    )"
      ],
      "metadata": {
        "id": "aEeu2I0mZsMx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beam_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=(X_valid,y_valid),\n",
        "    epochs=20,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_steps=valid_steps,\n",
        "    callbacks=[lr_call]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsZ89mh7eNLX",
        "outputId": "10fe1021-e7c4-477e-800e-12f4187d4d35"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 4.0647 - accuracy: 0.3141 - val_loss: 3.8022 - val_accuracy: 0.3098 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 2.9978 - accuracy: 0.4190 - val_loss: 3.2835 - val_accuracy: 0.3574 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 2.3922 - accuracy: 0.4984 - val_loss: 2.9097 - val_accuracy: 0.3945 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 1.9920 - accuracy: 0.5580 - val_loss: 2.6600 - val_accuracy: 0.4268 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 1.7211 - accuracy: 0.6038 - val_loss: 2.5402 - val_accuracy: 0.4440 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 5s 20ms/step - loss: 1.5226 - accuracy: 0.6402 - val_loss: 2.3995 - val_accuracy: 0.4634 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 1.3697 - accuracy: 0.6712 - val_loss: 2.3161 - val_accuracy: 0.4768 - lr: 5.0000e-04\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 1.3003 - accuracy: 0.6851 - val_loss: 2.2858 - val_accuracy: 0.4814 - lr: 5.0000e-04\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 1.2418 - accuracy: 0.6967 - val_loss: 2.2454 - val_accuracy: 0.4879 - lr: 5.0000e-04\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 1.1899 - accuracy: 0.7074 - val_loss: 2.2218 - val_accuracy: 0.4909 - lr: 5.0000e-04\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 1.1425 - accuracy: 0.7170 - val_loss: 2.1998 - val_accuracy: 0.4959 - lr: 5.0000e-04\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 1.0955 - accuracy: 0.7273 - val_loss: 2.2001 - val_accuracy: 0.4963 - lr: 4.2204e-04\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 1.0567 - accuracy: 0.7356 - val_loss: 2.1758 - val_accuracy: 0.4994 - lr: 3.5624e-04\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 1.0258 - accuracy: 0.7421 - val_loss: 2.1757 - val_accuracy: 0.5008 - lr: 3.0070e-04\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.9991 - accuracy: 0.7485 - val_loss: 2.1656 - val_accuracy: 0.5023 - lr: 2.5382e-04\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.9780 - accuracy: 0.7530 - val_loss: 2.1611 - val_accuracy: 0.5035 - lr: 2.1424e-04\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.9595 - accuracy: 0.7571 - val_loss: 2.1581 - val_accuracy: 0.5043 - lr: 1.8084e-04\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.9442 - accuracy: 0.7606 - val_loss: 2.1619 - val_accuracy: 0.5033 - lr: 1.5264e-04\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.9316 - accuracy: 0.7637 - val_loss: 2.1593 - val_accuracy: 0.5052 - lr: 1.2884e-04\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.9209 - accuracy: 0.7663 - val_loss: 2.1591 - val_accuracy: 0.5048 - lr: 1.0876e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7cc52438b0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_sentence(sentence:str,beam_width=3):\n",
        "\n",
        "    translation_list = []\n",
        "    X_inp = en_vec_layer(tf.constant([sentence]))\n",
        "    X_dec_inp = es_vec_layer(tf.constant([\"soseq\"]))\n",
        "    first_out = beam_model.predict((X_inp,X_dec_inp),verbose=0)[0,0]\n",
        "    top_beam_proba,top_beam_indices = tf.math.top_k(first_out,beam_width)\n",
        "\n",
        "    def get_translation_with_proba(translation:str):\n",
        "        proba_total = 0\n",
        "        for word_id in range(1,50):\n",
        "            X_dec_inp = es_vec_layer(tf.constant([\"soseq \"+translation]))\n",
        "            output = beam_model.predict((X_inp,X_dec_inp),verbose=0)[0,word_id]\n",
        "            pred_word = es_vec_layer.get_vocabulary()[np.argmax(output)]\n",
        "            if pred_word == \"eoseq\":\n",
        "                break\n",
        "            proba_total += np.math.log(np.max(output))\n",
        "            translation += \" \" + pred_word\n",
        "        return translation.strip(),proba_total\n",
        "\n",
        "    for i in range(beam_width):\n",
        "        first_word = es_vec_layer.get_vocabulary()[top_beam_indices[i]]\n",
        "        total_sentence,proba_total = get_translation_with_proba(first_word)\n",
        "        proba_total += np.math.log(top_beam_proba[i])\n",
        "        translation_list.append((proba_total,total_sentence))\n",
        "\n",
        "    return translation_list"
      ],
      "metadata": {
        "id": "CLich_6qIYXA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I love cats and dogs\"\n",
        "print(beam_sentence(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMJmImBnF680",
        "outputId": "cd08b745-be8b-4947-bdea-14e772f96a7e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(-3.478966907935391, 'amo a los perros y gatos'), (-8.099883536242025, 'me encanta la música y los gatos'), (-5.053357050505417, '[UNK] a los perros y los gatos')]\n"
          ]
        }
      ]
    }
  ]
}