{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h4ck4l1/datasets/blob/main/NLP_with_RNN_and_Attention/NMT_with_attention_google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 449,
      "metadata": {
        "id": "VRuR4P2evZaO"
      },
      "outputs": [],
      "source": [
        "import os,warnings,sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    !pip3 install -q -U \"tensorflow-text==2.13.0\"\n",
        "    !pip3 install -q -U einops\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from IPython.display import clear_output\n",
        "os.environ[\"TF_MIN_LOG_LEVEL\"] = \"3\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_text as text\n",
        "import typing\n",
        "from zipfile import ZipFile\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import einops\n",
        "pio.templates.default = \"plotly_dark\"\n",
        "import numpy as np\n",
        "np.set_printoptions(precision=2)\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "%xmode Minimal\n",
        "if \"google.colab\" in sys.modules:\n",
        "    clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 450,
      "metadata": {
        "id": "f2erXwlqwLBh"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ShapeCheck():\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.shapes = {}\n",
        "\n",
        "    def __call__(self,tensor,names,broadcast=False):\n",
        "\n",
        "        parsed = einops.parse_shape(tensor,names)\n",
        "\n",
        "        for name,new_dim in parsed.items():\n",
        "\n",
        "            old_dim = self.shapes.get(name,None)\n",
        "\n",
        "            if broadcast and (new_dim == 1):\n",
        "                continue\n",
        "\n",
        "            if old_dim is None:\n",
        "\n",
        "                self.shapes[name] = new_dim\n",
        "                continue\n",
        "\n",
        "            if new_dim != old_dim:\n",
        "\n",
        "                raise ValueError(f\"SHAPE MISTMATCH FOR DIMENSION: '{name}' FOUND: {new_dim} EXPECTED: {old_dim}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 451,
      "metadata": {
        "id": "lhHg7Efy9Mvo"
      },
      "outputs": [],
      "source": [
        "url = \"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 452,
      "metadata": {
        "id": "EDT6uPFe-i-0"
      },
      "outputs": [],
      "source": [
        "file_path = keras.utils.get_file(fname=\"spa-eng.zip\",origin=url,extract=True)\n",
        "\n",
        "with ZipFile(file_path,\"r\") as f:\n",
        "\n",
        "    f.extractall(\"spa-eng\")\n",
        "\n",
        "with open(\"spa-eng/spa-eng/spa.txt\",\"r\") as f:\n",
        "\n",
        "    total_text = f.read()\n",
        "    total_text = [line.split(\"\\t\") for line in total_text.splitlines()]\n",
        "    en_text,es_text = zip(*total_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 453,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5lrAdXx3_Q-M",
        "outputId": "6885cef4-fafa-41ea-c5ca-cefdfe7b1414"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 453
        }
      ],
      "source": [
        "en_text[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 454,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGKfYpb6AhS0",
        "outputId": "64548dfc-3e17-433d-cc06-7df0f64c6323"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 454
        }
      ],
      "source": [
        "es_text[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 455,
      "metadata": {
        "id": "mdA_HJWQAjDX"
      },
      "outputs": [],
      "source": [
        "en_array = np.array(en_text)\n",
        "es_array = np.array(es_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 456,
      "metadata": {
        "id": "t6-MP_RfCFqV"
      },
      "outputs": [],
      "source": [
        "is_train = np.random.uniform(size=(len(en_array),)) < 0.8\n",
        "\n",
        "raw_train = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((en_array[is_train],es_array[is_train]))\n",
        "    .shuffle(len(en_text))\n",
        "    .batch(64)\n",
        ")\n",
        "raw_valid = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((en_array[~is_train],es_array[~is_train]))\n",
        "    .shuffle(len(en_text))\n",
        "    .batch(64)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 457,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73KFDI7MC6OE",
        "outputId": "0eda2f23-09cc-44b6-e0e6-d005e2c7cc47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"Maybe Tom didn't have time.\"\n",
            " b'He came from one of the richest families in America.'\n",
            " b'Tom criticized Mary in front of everyone.'\n",
            " b\"I'm looking forward to seeing you next Sunday.\"], shape=(4,), dtype=string)\n",
            "translates to latin as \n",
            "tf.Tensor(\n",
            "[b'Puede que Tom no tuviera tiempo.'\n",
            " b'Vino de una de las familias m\\xc3\\xa1s ricas de Am\\xc3\\xa9rica.'\n",
            " b'Tom critic\\xc3\\xb3 a Mary delante de todo el mundo.'\n",
            " b'Espero con ganas a verte el pr\\xc3\\xb3ximo domingo.'], shape=(4,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for en,es in raw_train.take(1):\n",
        "    print(en[:4])\n",
        "    print(\"translates to latin as \")\n",
        "    print(es[:4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWoeMzZlKou5"
      },
      "source": [
        "# Standardize Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 458,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdPVTQtWmK4N",
        "outputId": "ba3fb75c-446a-4633-8efc-3fd7e9c115ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Ve.',\n",
              " 'Vete.',\n",
              " 'Vaya.',\n",
              " 'Váyase.',\n",
              " 'Hola.',\n",
              " '¡Corre!',\n",
              " 'Corred.',\n",
              " '¿Quién?',\n",
              " '¡Fuego!',\n",
              " '¡Incendio!')"
            ]
          },
          "metadata": {},
          "execution_count": 458
        }
      ],
      "source": [
        "es_text[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 459,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmaSDOGJWpgR",
        "outputId": "6e9a1489-6881-4933-9a4e-aa603d5aabd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b'Ve.', b'Vete.', b'Vaya.', b'V\\xc3\\xa1yase.', b'Hola.',\n",
              "       b'\\xc2\\xa1Corre!', b'Corred.', b'\\xc2\\xbfQui\\xc3\\xa9n?',\n",
              "       b'\\xc2\\xa1Fuego!', b'\\xc2\\xa1Incendio!'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 459
        }
      ],
      "source": [
        "tf.constant(es_text[:10]) # converting to tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 460,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUSK23dUYeGl",
        "outputId": "9bc4eb3a-ba99-48c6-e1b2-14adadfa69d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b'Ve.', b'Vete.', b'Vaya.', b'Va\\xcc\\x81yase.', b'Hola.',\n",
              "       b'\\xc2\\xa1Corre!', b'Corred.', b'\\xc2\\xbfQuie\\xcc\\x81n?',\n",
              "       b'\\xc2\\xa1Fuego!', b'\\xc2\\xa1Incendio!'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 460
        }
      ],
      "source": [
        "temp_text = text.normalize_utf8(es_text[:10],\"NFKD\") # Normalizing text so that it can be used in operations\n",
        "temp_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 461,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNjOpADzjK_q",
        "outputId": "e2f6a940-4170-434e-ed3a-9f2977f28403"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b've.', b'vete.', b'vaya.', b'va\\xcc\\x81yase.', b'hola.',\n",
              "       b'\\xc2\\xa1corre!', b'corred.', b'\\xc2\\xbfquie\\xcc\\x81n?',\n",
              "       b'\\xc2\\xa1fuego!', b'\\xc2\\xa1incendio!'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 461
        }
      ],
      "source": [
        "temp_text_1 = tf.strings.lower(temp_text) # Lower casing all the characters\n",
        "temp_text_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 462,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvtl-SerZ3zX",
        "outputId": "bd23f949-b1e7-443b-eda3-76b18b1305ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b've.', b'vete.', b'vaya.', b'vayase.', b'hola.', b'corre!',\n",
              "       b'corred.', b'\\xc2\\xbfquien?', b'fuego!', b'incendio!'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 462
        }
      ],
      "source": [
        "temp_text_2 = tf.strings.regex_replace(temp_text_1,\"[^ a-z.?!,¿]\",\"\")  # [^ ...] means exclude..so excluding all the a-z and rest\n",
        "temp_text_2                                                            # and replacing with noting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 463,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shZsU98Nk87Z",
        "outputId": "f2272c0e-9be8-4532-f044-0c7be662619e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b've . ', b'vete . ', b'vaya . ', b'vayase . ', b'hola . ',\n",
              "       b'corre ! ', b'corred . ', b' \\xc2\\xbf quien ? ', b'fuego ! ',\n",
              "       b'incendio ! '], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 463
        }
      ],
      "source": [
        "temp_text_3 = tf.strings.regex_replace(temp_text_2,\"[.¡¿,?!]\",r' \\0 ') # Placing a null character[raw_string : r'']\n",
        "temp_text_3                                                            # before and after every punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 464,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwz8o9kome63",
        "outputId": "df6e48b9-392d-48dd-e470-fc7c93235383"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b've .', b'vete .', b'vaya .', b'vayase .', b'hola .', b'corre !',\n",
              "       b'corred .', b'\\xc2\\xbf quien ?', b'fuego !', b'incendio !'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 464
        }
      ],
      "source": [
        "temp_text_4= tf.strings.strip(temp_text_3) # stripping any extra spaces\n",
        "temp_text_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 465,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZeMXXT_mkUw",
        "outputId": "7863113d-2c86-4b9e-9edf-bc7500f86cdc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b'[startofsequence] ve . [endofsequence]',\n",
              "       b'[startofsequence] vete . [endofsequence]',\n",
              "       b'[startofsequence] vaya . [endofsequence]',\n",
              "       b'[startofsequence] vayase . [endofsequence]',\n",
              "       b'[startofsequence] hola . [endofsequence]',\n",
              "       b'[startofsequence] corre ! [endofsequence]',\n",
              "       b'[startofsequence] corred . [endofsequence]',\n",
              "       b'[startofsequence] \\xc2\\xbf quien ? [endofsequence]',\n",
              "       b'[startofsequence] fuego ! [endofsequence]',\n",
              "       b'[startofsequence] incendio ! [endofsequence]'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 465
        }
      ],
      "source": [
        "temp_text_5 = tf.strings.join(['[startofsequence]',temp_text_4,'[endofsequence]'],separator=\" \")\n",
        "temp_text_5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 466,
      "metadata": {
        "id": "eNj9-XOmnDSB"
      },
      "outputs": [],
      "source": [
        "def text_preprocessor(input_text):\n",
        "\n",
        "    input_text = text.normalize_utf8(input_text,\"NFKD\")\n",
        "    input_text = tf.strings.lower(input_text)\n",
        "    input_text = tf.strings.regex_replace(input_text,\"[^ a-z?.!¿¡,]\",\"\")\n",
        "    input_text = tf.strings.regex_replace(input_text,\"[?.!¿¡,]\",r\" \\0 \")\n",
        "    input_text = tf.strings.strip(input_text)\n",
        "    input_text = tf.strings.join([\"[startofsequence]\",input_text,\"[endofsequence]\"],separator=\" \")\n",
        "    return input_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBd-bHWivIkj"
      },
      "source": [
        "# Text Vectorization of En and Es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 467,
      "metadata": {
        "id": "LYvLY4eBuTxT"
      },
      "outputs": [],
      "source": [
        "vocab_size = 5000\n",
        "\n",
        "en_vec_layer = keras.layers.TextVectorization(vocab_size,standardize=text_preprocessor,ragged=True)\n",
        "en_vec_layer.adapt(raw_train.map(lambda en,es:en))\n",
        "es_vec_layer = keras.layers.TextVectorization(vocab_size,standardize=text_preprocessor,ragged=True)\n",
        "es_vec_layer.adapt(raw_train.map(lambda en,es:es))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 468,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r2hLyWx0eRg",
        "outputId": "ebbc41ee-d249-4255-dc1c-0e096e8bfee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', '[startofsequence]', '[endofsequence]', '.', 'the', 'i', 'to', 'you', 'tom']\n",
            "['', '[UNK]', '[startofsequence]', '[endofsequence]', '.', 'que', 'de', 'el', 'a', 'no']\n"
          ]
        }
      ],
      "source": [
        "print(en_vec_layer.get_vocabulary()[:10])\n",
        "print(es_vec_layer.get_vocabulary()[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 469,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFsxkvFz2hZJ",
        "outputId": "3755a394-fd26-4fb3-c701-b9be44d16789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"Maybe Tom didn't have time.\" ----> tf.Tensor([  2 628   9  64  22  53   4   3], shape=(8,), dtype=int64)\n",
            "b'He came from one of the richest families in America.' ----> tf.Tensor([   2   13  197   69   73   15    5 3222 2186   14  545    4    3], shape=(13,), dtype=int64)\n",
            "b'Tom criticized Mary in front of everyone.' ----> tf.Tensor([   2    9 3561   31   14  752   15  298    4    3], shape=(10,), dtype=int64)\n",
            "b\"I'm looking forward to seeing you next Sunday.\" ----> tf.Tensor([  2  38 256 798   7 808   8 210 635   4   3], shape=(11,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for english_text,en_vectorized_out in zip(en.numpy()[:4],en_vec_layer(en[:4])):\n",
        "    print(english_text,\"---->\",en_vectorized_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 470,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1wRy9Os5cAd",
        "outputId": "0a17cc4e-3066-47f2-b44c-9b3836dd8c01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'Puede que Tom no tuviera tiempo.' ----> tf.Tensor([   2   73    5   10    9 1154   62    4    3], shape=(9,), dtype=int64)\n",
            "b'Vino de una de las familias m\\xc3\\xa1s ricas de Am\\xc3\\xa9rica.' ----> tf.Tensor([   2  232    6   23    6   33 2652   35 4341    6  983    4    3], shape=(13,), dtype=int64)\n",
            "b'Tom critic\\xc3\\xb3 a Mary delante de todo el mundo.' ----> tf.Tensor([   2   10 3929    8   32 1601    6   56    7  190    4    3], shape=(12,), dtype=int64)\n",
            "b'Espero con ganas a verte el pr\\xc3\\xb3ximo domingo.' ----> tf.Tensor([  2 251  27 439   8 435   7 617 914   4   3], shape=(11,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for latin_text,es_vectorized_out in zip(es.numpy()[:4],es_vec_layer(es[:4])):\n",
        "    print(latin_text,\"---->\",es_vectorized_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 471,
      "metadata": {
        "id": "Q8T1vTbG6DHc"
      },
      "outputs": [],
      "source": [
        "en_vocab = np.array(en_vec_layer.get_vocabulary())\n",
        "es_vocab = np.array(es_vec_layer.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 472,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ner_MaA60hs",
        "outputId": "90baf59b-1032-45e6-9d7e-766abd1b4eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[startofsequence] im looking forward to seeing you next sunday . [endofsequence]\n",
            "[startofsequence] espero con ganas a verte el proximo domingo . [endofsequence]\n"
          ]
        }
      ],
      "source": [
        "print(\" \".join(en_vocab[en_vectorized_out.numpy()]))\n",
        "print(\" \".join(es_vocab[es_vectorized_out.numpy()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 473,
      "metadata": {
        "id": "Nd_WwynD6-yg"
      },
      "outputs": [],
      "source": [
        "en_vec_out = en_vec_layer(en)\n",
        "es_vec_out = es_vec_layer(es)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 474,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "hxdFErDy7s1A",
        "outputId": "c86efa82-c667-40ff-ce68-07f617f56f0a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"696f1b7a-4f8b-4ded-ab34-914f9fc99ac5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"696f1b7a-4f8b-4ded-ab34-914f9fc99ac5\")) {                    Plotly.newPlot(                        \"696f1b7a-4f8b-4ded-ab34-914f9fc99ac5\",                        [{\"z\":[[2,628,9,64,22,53,4,3,0,0,0,0,0,0,0,0],[2,13,197,69,73,15,5,3222,2186,14,545,4,3,0,0,0],[2,9,3561,31,14,752,15,298,4,3,0,0,0,0,0,0],[2,38,256,798,7,808,8,210,635,4,3,0,0,0,0,0],[2,20,8,43,95,3654,381,12,75,7,36,11,3,0,0,0],[2,8,27,37,21,7,36,225,25,148,19,20,8,11,3,0],[2,13,668,21,1727,5,449,4,3,0,0,0,0,0,0,0],[2,344,36,741,62,4,3,0,0,0,0,0,0,0,0,0],[2,8,553,7,93,21,61,16,126,8,199,4,3,0,0,0],[2,13,616,245,7,3032,25,30,350,4,3,0,0,0,0,0],[2,8,183,161,4,3,0,0,0,0,0,0,0,0,0,0],[2,26,18,430,7,502,47,2622,4,3,0,0,0,0,0,0],[2,5,1159,18,39,10,835,14,303,4,3,0,0,0,0,0],[2,6,59,98,278,404,10,274,309,167,4,3,0,0,0,0],[2,179,12,92,447,96,53,4,3,0,0,0,0,0,0,0],[2,87,201,436,1344,11,3,0,0,0,0,0,0,0,0,0],[2,20,8,65,9,181,31,11,3,0,0,0,0,0,0,0],[2,6,1524,156,304,4,3,0,0,0,0,0,0,0,0,0],[2,9,136,60,16,995,4,3,0,0,0,0,0,0,0,0],[2,9,122,13,18,57,394,4,3,0,0,0,0,0,0,0],[2,143,677,238,136,9,4,3,0,0,0,0,0,0,0,0],[2,6,65,50,53,25,21,7,322,162,5,362,4,3,0,0],[2,6,292,32,412,188,1401,236,4,3,0,0,0,0,0,0],[2,13,986,21,1107,4,3,0,0,0,0,0,0,0,0,0],[2,23,157,1021,155,4,3,0,0,0,0,0,0,0,0,0],[2,9,18,123,7,1,69,509,40,787,4,3,0,0,0,0],[2,9,12,80,7,21,4,3,0,0,0,0,0,0,0,0],[2,13,4640,30,761,4,3,0,0,0,0,0,0,0,0,0],[2,13,505,5,1011,35,30,172,438,4,3,0,0,0,0,0],[2,6,230,7,221,10,2005,14,194,67,6,18,10,578,4,3],[2,9,354,7,36,4814,7,1,5,229,4,3,0,0,0,0],[2,13,12,657,40,1590,4,3,0,0,0,0,0,0,0,0],[2,46,128,15,24,36,302,11,3,0,0,0,0,0,0,0],[2,12,13,247,180,1033,11,3,0,0,0,0,0,0,0,0],[2,135,23,208,124,1724,21,4,3,0,0,0,0,0,0,0],[2,13,988,5,728,115,4,3,0,0,0,0,0,0,0,0],[2,211,41,2392,963,4,3,0,0,0,0,0,0,0,0,0],[2,83,2573,6,64,264,16,4,3,0,0,0,0,0,0,0],[2,8,141,149,36,205,4,3,0,0,0,0,0,0,0,0],[2,6,418,45,34,907,4,3,0,0,0,0,0,0,0,0],[2,6,27,43,67,83,36,118,4,3,0,0,0,0,0,0],[2,9,40,31,28,771,42,290,4,3,0,0,0,0,0,0],[2,20,8,37,44,7,43,61,17,11,3,0,0,0,0,0],[2,93,103,10,1064,4,3,0,0,0,0,0,0,0,0,0],[2,38,1264,698,4,3,0,0,0,0,0,0,0,0,0,0],[2,5,420,1,14,5,1182,4,3,0,0,0,0,0,0,0],[2,9,1041,1,4,3,0,0,0,0,0,0,0,0,0,0],[2,9,782,5,2415,4,3,0,0,0,0,0,0,0,0,0],[2,219,44,30,238,4,3,0,0,0,0,0,0,0,0,0],[2,28,8,75,7,1234,5,381,405,11,3,0,0,0,0,0],[2,13,567,5,881,14,760,4,3,0,0,0,0,0,0,0],[2,32,45,166,4,3,0,0,0,0,0,0,0,0,0,0],[2,32,149,221,1164,4,3,0,0,0,0,0,0,0,0,0],[2,28,8,116,234,11,3,0,0,0,0,0,0,0,0,0],[2,6,18,39,1331,4,3,0,0,0,0,0,0,0,0,0],[2,20,8,41,137,1,11,3,0,0,0,0,0,0,0,0],[2,9,12,2184,19,136,13,11,3,0,0,0,0,0,0,0],[2,14,5,1139,15,5,440,19,52,12,10,4131,4,3,0,0],[2,28,8,1260,563,61,333,247,188,42,33,520,11,3,0,0],[2,5,1845,12,10,4314,3401,15,202,40,1,4,3,0,0,0],[2,50,29,32,1490,4,3,0,0,0,0,0,0,0,0,0],[2,6,43,8,58,1413,4,3,0,0,0,0,0,0,0,0],[2,51,106,22,5,152,7,1073,25,1321,4,3,0,0,0,0],[2,368,1641,103,188,4,3,0,0,0,0,0,0,0,0,0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"z\":[[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Unmasked\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Masked\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('696f1b7a-4f8b-4ded-ab34-914f9fc99ac5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = make_subplots(cols=2,subplot_titles=[\"Unmasked\",\"Masked\"])\n",
        "fig.add_trace(go.Heatmap(z=en_vec_out.to_tensor().numpy()),row=1,col=1)\n",
        "fig.add_trace(go.Heatmap(z=np.array((en_vec_out.to_tensor() != 0).numpy(),dtype=np.int32)),row=1,col=2)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 475,
      "metadata": {
        "id": "OBAs6ISC_JOb"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataset(en,es):\n",
        "    X_train = en_vec_layer(en).to_tensor()\n",
        "    X_dec = es_vec_layer(es)\n",
        "    X_dec_train = X_dec[:,:-1].to_tensor()\n",
        "    y_train = X_dec[:,1:].to_tensor()\n",
        "\n",
        "    return (X_train,X_dec_train),y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 476,
      "metadata": {
        "id": "4b0AXYxOBEWT"
      },
      "outputs": [],
      "source": [
        "train_ds = raw_train.map(preprocess_dataset,tf.data.AUTOTUNE)\n",
        "valid_ds = raw_valid.map(preprocess_dataset,tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 477,
      "metadata": {
        "id": "YhaaOooEu31g",
        "outputId": "6f6eb307-6f0d-42e7-e01f-b935da1df3f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n"
          ]
        }
      ],
      "source": [
        "for (en_in,es_in),es_out in train_ds.take(1):\n",
        "    print(en_in.shape)\n",
        "    print(es_in.shape)\n",
        "    print(es_out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzeg0ZKku31h"
      },
      "source": [
        "# Encoder Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cauf7s0vu31h"
      },
      "source": [
        "- Embedding Layer\n",
        "- GRU/LSTM Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 478,
      "metadata": {
        "id": "iVc1hkwzu31h",
        "outputId": "eb917432-94c5-463c-98f8-40bb5ba7a7a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 478
        }
      ],
      "source": [
        "vocab_size = len(en_vec_layer.get_vocabulary())\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 479,
      "metadata": {
        "id": "vMetYW0gu31h"
      },
      "outputs": [],
      "source": [
        "embed_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 480,
      "metadata": {
        "id": "qyESzuiuu31i"
      },
      "outputs": [],
      "source": [
        "encoder_embed_layer = keras.layers.Embedding(vocab_size,embed_size,mask_zero=True)\n",
        "encoder = keras.layers.Bidirectional(\n",
        "    keras.layers.LSTM(256,return_sequences=True,recurrent_initializer=\"glorot_uniform\"),\n",
        "    merge_mode=\"sum\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 481,
      "metadata": {
        "id": "IjA7XtHEu31i"
      },
      "outputs": [],
      "source": [
        "shape_checker = ShapeCheck()\n",
        "shape_checker(en_in,\"batch s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 482,
      "metadata": {
        "id": "uPTSXjTju31i",
        "outputId": "9eb7e6c9-3320-477e-a3c5-237bec3961de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch': 64, 's': 20}"
            ]
          },
          "metadata": {},
          "execution_count": 482
        }
      ],
      "source": [
        "shape_checker.shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 483,
      "metadata": {
        "id": "gCSEes5Fu31i",
        "outputId": "b0ae75bc-3d79-4347-fa96-dfb1d4f9d227",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 20, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 483
        }
      ],
      "source": [
        "enc_embed_output = encoder_embed_layer(en_in)\n",
        "enc_embed_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 484,
      "metadata": {
        "id": "7H_C7UYnu31k",
        "outputId": "d8f495d8-5f28-43c9-b3ff-a9d9534ec65a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch': 64, 's': 20, 'units': 256}"
            ]
          },
          "metadata": {},
          "execution_count": 484
        }
      ],
      "source": [
        "shape_checker(enc_embed_output,\"batch s units\")\n",
        "shape_checker.shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 485,
      "metadata": {
        "id": "jJxSxCPlu31k",
        "outputId": "27136795-f846-4cbf-945c-2b25963d1d88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 20, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 485
        }
      ],
      "source": [
        "encoder_outputs = encoder(enc_embed_output)\n",
        "encoder_outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 486,
      "metadata": {
        "id": "MDGUACPku31k"
      },
      "outputs": [],
      "source": [
        "shape_checker(encoder_outputs,\"batch s units\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 487,
      "metadata": {
        "id": "ItyGpyOXu31l"
      },
      "outputs": [],
      "source": [
        "mha = keras.layers.MultiHeadAttention(num_heads=1,key_dim=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 488,
      "metadata": {
        "id": "L78F35PWu31l",
        "outputId": "040901d0-14d8-41ae-f1d4-0178c5eae684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 20)\n",
            "(64, 20, 256)\n"
          ]
        }
      ],
      "source": [
        "print(en_in.shape)\n",
        "print(encoder_outputs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 489,
      "metadata": {
        "id": "DQMoT_OYu31l",
        "outputId": "5e147f2c-5290-4327-fb5e-37699f848829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 489
        }
      ],
      "source": [
        "len(en_vec_layer.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 490,
      "metadata": {
        "id": "Hq-JrLxnu31m"
      },
      "outputs": [],
      "source": [
        "class Encoder(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,units=256,vec_layer=en_vec_layer,**kwargs):\n",
        "\n",
        "        super(Encoder,self).__init__(**kwargs)\n",
        "        self.vec_layer = vec_layer\n",
        "        self.embed = keras.layers.Embedding(vec_layer.vocabulary_size(),units,mask_zero=True)\n",
        "        self.Rnn = keras.layers.Bidirectional(\n",
        "            layer=keras.layers.LSTM(units,return_sequences=True,return_state=True,recurrent_initializer=\"glorot_uniform\"),\n",
        "            merge_mode=\"sum\"\n",
        "        )\n",
        "\n",
        "    def call(self,inputs):\n",
        "\n",
        "        shape_checker = ShapeCheck()\n",
        "        shape_checker(inputs,\"batch s\")\n",
        "        z = self.embed(inputs)\n",
        "        shape_checker(z,\"batch s units\")\n",
        "        z,*encoder_state = self.Rnn(z)\n",
        "        self.encoder_state = encoder_state\n",
        "        shape_checker(z,\"batch s units\")\n",
        "        return z\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVCnJqY_u31m"
      },
      "source": [
        "# CrossAttention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 491,
      "metadata": {
        "id": "TkDae6kru31m",
        "outputId": "320cf24a-0455-424a-814c-6ceeb7406895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 18, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 491
        }
      ],
      "source": [
        "decoder_embed_layer = keras.layers.Embedding(es_vec_layer.vocabulary_size(),256,mask_zero=True)\n",
        "decoder_embed_out = decoder_embed_layer(es_in)\n",
        "decoder_embed_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 492,
      "metadata": {
        "id": "4xtE65Q2u31m",
        "outputId": "48a7226d-c160-45b3-ae30-2d3a2f1d7795",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 18, 256)\n",
            "(64, 1, 18, 20)\n"
          ]
        }
      ],
      "source": [
        "mha = keras.layers.MultiHeadAttention(num_heads=1,key_dim=256)\n",
        "attention_output,attention_scores = mha(query=decoder_embed_out,value=encoder_outputs,return_attention_scores=True)\n",
        "print(attention_output.shape)\n",
        "print(attention_scores.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 493,
      "metadata": {
        "id": "CTdmUs1Cu31n"
      },
      "outputs": [],
      "source": [
        "shape_checker = ShapeCheck()\n",
        "shape_checker(decoder_embed_out,\"batch t units\")\n",
        "shape_checker(encoder_outputs,\"batch s units\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 494,
      "metadata": {
        "id": "gfTRerc-u31n",
        "outputId": "7d8cc37c-d8ac-4b83-b4a9-7eba0c050588",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 18, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 494
        }
      ],
      "source": [
        "attention_scores = tf.reduce_mean(attention_scores,axis=1)\n",
        "attention_scores.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 495,
      "metadata": {
        "id": "xr_8_3GRu31n",
        "outputId": "93cd5333-2cb9-4fc9-e0a0-426d39c0de25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 18, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 495
        }
      ],
      "source": [
        "adding_layer = keras.layers.Add()\n",
        "add_out = adding_layer([decoder_embed_out,attention_output])\n",
        "add_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 496,
      "metadata": {
        "id": "3vfHONdMu31o",
        "outputId": "e81ce13d-03bf-498f-b9c6-56773cc0638b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 18, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 496
        }
      ],
      "source": [
        "layer_norm = keras.layers.LayerNormalization()\n",
        "layer_out = layer_norm(add_out)\n",
        "layer_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 497,
      "metadata": {
        "id": "PqlxV4YXu31o"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,units=256,**kwargs):\n",
        "\n",
        "        super(CrossAttention,self).__init__(**kwargs)\n",
        "        self.mha = keras.layers.MultiHeadAttention(num_heads=1,key_dim=units)\n",
        "        self.add = keras.layers.Add()\n",
        "        self.layer_norm = keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self,decoder_out,encoder_out):\n",
        "\n",
        "        shape_checker = ShapeCheck()\n",
        "        shape_checker(decoder_out,\"batch t units\")\n",
        "        shape_checker(encoder_out,\"batch s units\")\n",
        "\n",
        "        attention_output,attention_scores = self.mha(query=decoder_out,value=encoder_out,return_attention_scores=True)\n",
        "        shape_checker(attention_output,\"batch t units\")\n",
        "        shape_checker(attention_scores,\"batch heads t s\")\n",
        "\n",
        "        add_and_layer_norm = self.layer_norm(self.add([decoder_out,attention_output]))\n",
        "        self.attention_scores = tf.reduce_mean(attention_scores,axis=1)\n",
        "\n",
        "        return add_and_layer_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 498,
      "metadata": {
        "id": "0QI5ozGiu31p",
        "outputId": "ab9e4c5f-19a5-4646-a38f-bea87c6a19aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 18, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 498
        }
      ],
      "source": [
        "attention_layer = CrossAttention()\n",
        "\n",
        "attention_out = attention_layer(decoder_embed_out,encoder_outputs)\n",
        "attention_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 499,
      "metadata": {
        "id": "EpZVIHIDu31r",
        "outputId": "4b3cf62d-8b54-4237-cd2e-59d9ce2e86c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 18, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 499
        }
      ],
      "source": [
        "attention_layer.attention_scores.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 500,
      "metadata": {
        "id": "V9aFzp0Xu31r",
        "outputId": "1da4357b-6539-461d-d021-d2299bc149ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 500
        }
      ],
      "source": [
        "np.sum(attention_layer.attention_scores,axis=-1)[:5,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 501,
      "metadata": {
        "id": "ycQVozJfu31r",
        "outputId": "9f00a408-92a7-46cc-c245-1e2e09d9af66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"e9474899-e2aa-4549-af6f-6ce9c16572fd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e9474899-e2aa-4549-af6f-6ce9c16572fd\")) {                    Plotly.newPlot(                        \"e9474899-e2aa-4549-af6f-6ce9c16572fd\",                        [{\"z\":[[0.12500019371509552,0.1249999850988388,0.12499988079071045,0.1249997466802597,0.1250000149011612,0.12500013411045074,0.12500004470348358,0.12499994039535522,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1000000536441803,0.10000020265579224,0.10000023990869522,0.10000019520521164,0.10000024735927582,0.10000012069940567,0.09999991953372955,0.09999966621398926,0.09999969601631165,0.09999965131282806,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1428571492433548,0.1428568959236145,0.14285722374916077,0.14285717904567719,0.14285743236541748,0.1428571194410324,0.14285697042942047,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.07692311704158783,0.07692313194274902,0.07692324370145798,0.07692312449216843,0.0769231766462326,0.07692310214042664,0.07692307233810425,0.0769229531288147,0.07692310214042664,0.07692303508520126,0.07692307233810425,0.07692301273345947,0.07692291587591171,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09090906381607056,0.09090909361839294,0.09090933948755264,0.09090914577245712,0.09090901166200638,0.09090905636548996,0.09090916067361832,0.09090922027826309,0.09090907126665115,0.09090892970561981,0.09090883284807205,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1250000298023224,0.1250000149011612,0.125,0.1250000149011612,0.12500011920928955,0.12500005960464478,0.125,0.12499971687793732,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.06249989569187164,0.0624997578561306,0.06249989941716194,0.06249981373548508,0.062499891966581345,0.06249992549419403,0.06250013411045074,0.06250015646219254,0.06250015646219254,0.06250012665987015,0.06250014901161194,0.06250012665987015,0.06249997392296791,0.06250005960464478,0.06250009685754776,0.06249992176890373,0.0,0.0,0.0,0.0],[0.14285671710968018,0.14285697042942047,0.1428573876619339,0.14285747706890106,0.14285749197006226,0.142857164144516,0.14285674691200256,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09090925008058548,0.0909091979265213,0.09090898185968399,0.09090899676084518,0.09090886265039444,0.09090913087129593,0.09090907126665115,0.09090907871723175,0.09090915322303772,0.0909091904759407,0.09090910106897354,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09090898185968399,0.0909089744091034,0.09090887010097504,0.09090916812419891,0.09090904146432877,0.09090910851955414,0.09090922772884369,0.09090930968523026,0.09090939164161682,0.09090900421142578,0.09090884774923325,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.06666669249534607,0.0666666328907013,0.06666657328605652,0.06666650623083115,0.06666649878025055,0.06666645407676697,0.06666658818721771,0.06666675209999084,0.06666678935289383,0.06666667014360428,0.06666673719882965,0.06666668504476547,0.0666668564081192,0.06666687875986099,0.06666669249534607,0.0,0.0,0.0,0.0,0.0],[0.1428574025630951,0.14285704493522644,0.14285676181316376,0.14285710453987122,0.14285753667354584,0.14285717904567719,0.14285700023174286,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0666666254401207,0.06666664779186249,0.06666669994592667,0.0666666030883789,0.06666667014360428,0.06666678190231323,0.06666676700115204,0.06666657328605652,0.06666669249534607,0.06666674464941025,0.06666672229766846,0.06666678935289383,0.06666675209999084,0.06666652113199234,0.06666641682386398,0.0,0.0,0.0,0.0,0.0],[0.14285704493522644,0.14285700023174286,0.14285749197006226,0.1428573876619339,0.1428571194410324,0.14285698533058167,0.14285686612129211,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09999997913837433,0.09999988228082657,0.09999995678663254,0.09999983757734299,0.10000014305114746,0.10000025480985641,0.10000026971101761,0.10000016540288925,0.0999998077750206,0.09999964386224747,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.12499978393316269,0.12499994784593582,0.1250002086162567,0.1250002384185791,0.1250002384185791,0.12500019371509552,0.12499978393316269,0.12499961256980896,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.07692315429449081,0.07692316174507141,0.07692334800958633,0.07692322134971619,0.07692296802997589,0.07692307978868484,0.07692303508520126,0.07692296802997589,0.07692297548055649,0.07692314684391022,0.0769231766462326,0.07692287862300873,0.07692278176546097,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.16666647791862488,0.16666635870933533,0.16666628420352936,0.1666669100522995,0.16666722297668457,0.16666679084300995,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09090902656316757,0.09090913832187653,0.09090901911258698,0.09090884774923325,0.09090900421142578,0.09090912342071533,0.09090915322303772,0.09090910106897354,0.09090936928987503,0.09090916812419891,0.09090900421142578,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.049999840557575226,0.049999840557575226,0.04999987781047821,0.05000000074505806,0.04999999329447746,0.05000000819563866,0.05000018700957298,0.05000010132789612,0.05000010132789612,0.05000007525086403,0.050000112503767014,0.05000000447034836,0.04999997094273567,0.049999989569187164,0.05000004544854164,0.04999997094273567,0.050000064074993134,0.05000007897615433,0.049999888986349106,0.04999980702996254],[0.14285746216773987,0.14285750687122345,0.14285728335380554,0.14285720884799957,0.14285707473754883,0.14285676181316376,0.142856627702713,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.16666686534881592,0.16666702926158905,0.16666674613952637,0.16666653752326965,0.16666653752326965,0.16666632890701294,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.14285705983638763,0.14285685122013092,0.14285705983638763,0.14285728335380554,0.1428569257259369,0.14285734295845032,0.14285744726657867,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09999980032444,0.09999996423721313,0.09999998658895493,0.09999999403953552,0.10000011324882507,0.10000006854534149,0.10000024735927582,0.10000021755695343,0.09999991208314896,0.09999975562095642,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.10000013560056686,0.09999999403953552,0.1000000610947609,0.10000024735927582,0.10000009089708328,0.09999994933605194,0.09999999403953552,0.10000014305114746,0.09999972581863403,0.09999961405992508,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.16666679084300995,0.16666680574417114,0.16666702926158905,0.16666662693023682,0.16666649281978607,0.16666629910469055,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09090890735387802,0.09090887010097504,0.09090892970561981,0.09090916812419891,0.09090913087129593,0.09090914577245712,0.09090914577245712,0.0909092053771019,0.09090927988290787,0.09090916067361832,0.09090898931026459,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.07692303508520126,0.07692314684391022,0.07692313939332962,0.07692313939332962,0.07692313939332962,0.07692298293113708,0.0769231915473938,0.07692304253578186,0.0769231766462326,0.07692311704158783,0.07692307978868484,0.07692290097475052,0.07692284137010574,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1250000298023224,0.12499985098838806,0.12499986588954926,0.1249999925494194,0.12500010430812836,0.1250002235174179,0.12500004470348358,0.12499989569187164,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.12499988079071045,0.12499985098838806,0.12500016391277313,0.1249999925494194,0.12499991059303284,0.12500017881393433,0.12500010430812836,0.12499996274709702,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0999997928738594,0.09999991208314896,0.10000016540288925,0.10000031441450119,0.10000023990869522,0.09999998658895493,0.09999985247850418,0.09999986737966537,0.09999997168779373,0.09999976307153702,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.14285686612129211,0.14285698533058167,0.14285728335380554,0.14285700023174286,0.1428574025630951,0.1428574174642563,0.14285703003406525,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.14285704493522644,0.14285728335380554,0.14285729825496674,0.142857164144516,0.1428573876619339,0.14285700023174286,0.14285677671432495,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.16666679084300995,0.16666671633720398,0.16666701436042786,0.16666720807552338,0.16666623950004578,0.16666606068611145,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.12499979883432388,0.12499977648258209,0.1250002086162567,0.12500035762786865,0.12500038743019104,0.1250002235174179,0.12499973177909851,0.12499959766864777,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09090887010097504,0.09090899676084518,0.09090909361839294,0.09090912342071533,0.09090926498174667,0.09090928733348846,0.0909092053771019,0.09090929478406906,0.09090922772884369,0.09090887755155563,0.09090875089168549,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09999978542327881,0.0999995693564415,0.09999975562095642,0.09999998658895493,0.10000009089708328,0.1000003069639206,0.10000044852495193,0.1000003069639206,0.09999991953372955,0.09999977797269821,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111094802618027,0.11111113429069519,0.11111125349998474,0.11111116409301758,0.11111100763082504,0.11111116409301758,0.11111117154359818,0.11111120879650116,0.11111094057559967,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111129820346832,0.11111097037792206,0.11111108958721161,0.11111103743314743,0.11111105978488922,0.11111123859882355,0.11111133545637131,0.11111102998256683,0.11111088842153549,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09999983012676239,0.0999997928738594,0.09999968111515045,0.09999991208314896,0.10000003129243851,0.10000026226043701,0.10000039637088776,0.10000047087669373,0.09999990463256836,0.09999972581863403,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111141741275787,0.11111152917146683,0.11111131310462952,0.11111124604940414,0.1111111119389534,0.11111103743314743,0.11111100763082504,0.11111077666282654,0.1111106127500534,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09999984502792358,0.0999998152256012,0.09999992698431015,0.10000003129243851,0.10000008344650269,0.10000018775463104,0.10000022500753403,0.10000013560056686,0.09999988228082657,0.09999975562095642,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.16666696965694427,0.1666664183139801,0.16666653752326965,0.16666683554649353,0.1666666865348816,0.16666656732559204,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.06250008195638657,0.06249992549419403,0.06249979883432388,0.06249973922967911,0.06249989941716194,0.06249985098838806,0.06249991059303284,0.062499817460775375,0.06249997392296791,0.062499914318323135,0.06250017881393433,0.0625002533197403,0.06250026822090149,0.06250039488077164,0.06250003725290298,0.06249993294477463,0.0,0.0,0.0,0.0],[0.08333339542150497,0.08333318680524826,0.08333306014537811,0.08333328366279602,0.0833333358168602,0.08333361893892288,0.08333338052034378,0.08333320915699005,0.08333338052034378,0.08333326876163483,0.08333346247673035,0.08333326876163483,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09999999403953552,0.09999996423721313,0.10000010579824448,0.10000021010637283,0.10000008344650269,0.09999995678663254,0.09999997168779373,0.09999998658895493,0.09999989718198776,0.09999977797269821,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.16666662693023682,0.16666656732559204,0.16666649281978607,0.1666668802499771,0.16666696965694427,0.16666653752326965,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.12499995529651642,0.1250000298023224,0.12499973922967911,0.12499996274709702,0.12500031292438507,0.12500031292438507,0.12499992549419403,0.12499971687793732,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.16666653752326965,0.16666674613952637,0.1666666865348816,0.16666708886623383,0.166666641831398,0.16666635870933533,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111102998256683,0.11111122369766235,0.11111120879650116,0.11111137270927429,0.11111116409301758,0.11111137270927429,0.1111111044883728,0.11111074686050415,0.11111065000295639,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.10000016540288925,0.1000002846121788,0.10000017285346985,0.10000009834766388,0.09999991208314896,0.09999975562095642,0.09999997913837433,0.09999995678663254,0.09999989718198776,0.09999977797269821,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1250000298023224,0.12499997019767761,0.12499989569187164,0.12499997019767761,0.12500019371509552,0.1250000298023224,0.12500011920928955,0.12499985098838806,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.14285720884799957,0.14285726845264435,0.1428571194410324,0.14285717904567719,0.1428573727607727,0.14285697042942047,0.14285679161548615,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.12499995529651642,0.12499994039535522,0.12499995529651642,0.12500019371509552,0.12500007450580597,0.12500041723251343,0.12499978393316269,0.12499965727329254,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.12500011920928955,0.12500011920928955,0.1250000298023224,0.1250000298023224,0.12500004470348358,0.12499994784593582,0.12499994784593582,0.12499979883432388,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.10000000149011612,0.0999998226761818,0.09999958425760269,0.0999995619058609,0.10000006854534149,0.10000041127204895,0.10000021755695343,0.10000032931566238,0.1000000461935997,0.09999988228082657,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.16666670143604279,0.16666699945926666,0.16666704416275024,0.1666668951511383,0.16666631400585175,0.16666604578495026,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09999989718198776,0.09999991208314896,0.09999983012676239,0.09999993443489075,0.10000043362379074,0.10000032931566238,0.10000010579824448,0.09999994188547134,0.0999997928738594,0.09999972581863403,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111090332269669,0.11111095547676086,0.11111129820346832,0.11111132055521011,0.1111111268401146,0.11111120879650116,0.11111119389533997,0.11111117154359818,0.11111085116863251,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09999978542327881,0.09999989718198776,0.10000001639127731,0.1000000536441803,0.1000000461935997,0.10000009834766388,0.10000017285346985,0.10000003129243851,0.10000001639127731,0.09999978542327881,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.14285755157470703,0.1428571492433548,0.14285710453987122,0.14285729825496674,0.14285697042942047,0.14285701513290405,0.14285695552825928,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.16666708886623383,0.16666662693023682,0.16666674613952637,0.16666674613952637,0.1666664481163025,0.16666628420352936,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0909089595079422,0.09090891480445862,0.09090898185968399,0.09090905636548996,0.0909092128276825,0.09090904146432877,0.0909089520573616,0.09090925753116608,0.090909443795681,0.09090914577245712,0.09090899676084518,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1250002235174179,0.1250002384185791,0.1250002235174179,0.1250002235174179,0.12499994784593582,0.12499988824129105,0.12499961256980896,0.12499959021806717,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"z\":[[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Attention Output\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Masked Output\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e9474899-e2aa-4549-af6f-6ce9c16572fd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = make_subplots(cols=2,subplot_titles=[\"Attention Output\",\"Masked Output\"])\n",
        "fig.add_trace(go.Heatmap(z=attention_layer.attention_scores[:,0,:]),row=1,col=1)\n",
        "fig.add_trace(go.Heatmap(z=np.array((en_vec_out.to_tensor() != 0).numpy(),dtype=np.int32)),row=1,col=2)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder"
      ],
      "metadata": {
        "id": "K0Ogl9GE4zZX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 502,
      "metadata": {
        "id": "FqDEvc0Mu31s"
      },
      "outputs": [],
      "source": [
        "class Decoder(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,units=256,vec_layer=es_vec_layer,**kwargs):\n",
        "\n",
        "        super(Decoder,self).__init__(**kwargs)\n",
        "\n",
        "        '''Preprocessing Section'''\n",
        "        self.vec_layer = vec_layer\n",
        "        self.vocab_size = vec_layer.vocabulary_size()\n",
        "        self.word_to_id = keras.layers.StringLookup(\n",
        "            vocabulary=vec_layer.get_vocabulary(),\n",
        "            oov_token=\"[UNK]\",\n",
        "            mask_token=\"\"\n",
        "        )\n",
        "        self.id_to_word = keras.layers.StringLookup(\n",
        "            vocabulary=vec_layer.get_vocabulary(),\n",
        "            oov_token=\"[UNK]\",\n",
        "            mask_token=\"\",\n",
        "            invert=True\n",
        "        )\n",
        "        self.start_token = self.word_to_id('[startofsequence]')\n",
        "        self.end_token = self.word_to_id('[endofsequence]')\n",
        "        self.units = units\n",
        "\n",
        "\n",
        "        '''Model Layers section'''\n",
        "        self.es_embed = keras.layers.Embedding(vec_layer.vocabulary_size(),units,mask_zero=True)\n",
        "        self.decoder_cell = keras.layers.LSTM(units,return_sequences=True,return_state=True,recurrent_initializer=\"glorot_uniform\")\n",
        "        self.attention = CrossAttention()\n",
        "        self.out = keras.layers.Dense(vec_layer.vocabulary_size())\n",
        "\n",
        "\n",
        "    def call(self,encoder_outputs,decoder_inputs,encoder_state=None,return_state=False):\n",
        "\n",
        "        shape_checker = ShapeCheck()\n",
        "        shape_checker(encoder_outputs,\"batch s units\")\n",
        "        shape_checker(decoder_inputs,\"batch t\")\n",
        "        if encoder_state is not None:\n",
        "            shape_checker(encoder_state[0],\"batch units\")\n",
        "            shape_checker(encoder_state[1],\"batch units\")\n",
        "\n",
        "        es_embed_out = self.es_embed(decoder_inputs)\n",
        "        shape_checker(es_embed_out,\"batch t units\")\n",
        "\n",
        "\n",
        "\n",
        "        decoder_outputs,*decoder_state = self.decoder_cell(es_embed_out,initial_state=encoder_state)\n",
        "        shape_checker(decoder_outputs,\"batch t units\")\n",
        "        shape_checker(decoder_state[0],\"batch units\")\n",
        "        shape_checker(decoder_state[1],\"batch units\")\n",
        "\n",
        "        attention_out = self.attention(decoder_outputs,encoder_outputs)\n",
        "        shape_checker(attention_out,\"batch t units\")\n",
        "        shape_checker(self.attention.attention_scores,\"batch t s\")\n",
        "\n",
        "        total_out = self.out(attention_out)\n",
        "\n",
        "        if return_state:\n",
        "            return total_out,decoder_state\n",
        "        else:\n",
        "            return total_out\n",
        "\n",
        "\n",
        "    def get_initial_state(self,encoder_outputs):\n",
        "        batch_size = tf.shape(encoder_outputs)[0]\n",
        "        start_tokens = tf.fill(dims=[batch_size,1],value=self.start_token)\n",
        "        done = tf.zeros(shape=[batch_size,1],dtype=tf.bool)\n",
        "        embedding = self.es_embed(start_tokens)\n",
        "        return start_tokens,done,self.decoder_cell.get_initial_state(embedding)\n",
        "\n",
        "\n",
        "    def tokens_to_text(self,tokens):\n",
        "        text_ = self.id_to_word(tokens)\n",
        "        text_ = tf.strings.reduce_join(text_,axis=-1,separator=\" \")\n",
        "        text_ = tf.strings.regex_replace(text_,\"^ *\\[startofsequence\\] *\",\"\")\n",
        "        text_ = tf.strings.regex_replace(text_,\" *\\[endofsequence\\] *$\",\"\")\n",
        "        return text_\n",
        "\n",
        "    def get_next_tokens(self,encoder_outputs,next_token,done,state,temperature=0.0):\n",
        "        total_output,state = self(encoder_outputs,next_token,encoder_state=state,return_state=True)\n",
        "\n",
        "        if temperature:\n",
        "            next_token = tf.argmax(total_output,axis=-1)\n",
        "        else:\n",
        "            scaled_out = total_output/temperature\n",
        "            next_token = tf.random.categorical(scaled_out[:,-1,:],num_samples=1,seed=42)\n",
        "\n",
        "        done = done | (next_token == self.end_token)\n",
        "        next_token = tf.where(done,tf.constant(0,dtype=tf.int64),next_token)\n",
        "        return next_token,done,state"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder()"
      ],
      "metadata": {
        "id": "zojmxnj-MUQv"
      },
      "execution_count": 503,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_token,done,state = decoder.get_initial_state(encoder_outputs)\n",
        "tokens_list = []\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "    next_token,done,state = decoder.get_next_tokens(encoder_outputs,next_token,done,state,temperature=1)\n",
        "    tokens_list.append(next_token)"
      ],
      "metadata": {
        "id": "KqEltGL3212T"
      },
      "execution_count": 504,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder.tokens_to_text(tf.concat(tokens_list,axis=-1))[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxkmkZT-V7I7",
        "outputId": "3173b57a-ac7e-4855-9884-572f547a36fd"
      },
      "execution_count": 505,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=string, numpy=\n",
              "array([b'opinas medianoche pierdas pierdas ataque ataque estudiantes estudiantes ! podias',\n",
              "       b'opinas medianoche pierdas pierdas ataque ataque estudiantes estudiantes espectaculo camisa',\n",
              "       b'opinas medianoche pierdas pierdas ataque ataque estudiantes estudiantes ! podias'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 505
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translator Total Model"
      ],
      "metadata": {
        "id": "Qn7D__FYX5cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%xmode Context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iJ1SOH20XlW",
        "outputId": "16b42090-2218-4b5e-c70f-16612341d370"
      },
      "execution_count": 506,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception reporting mode: Context\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(keras.models.Model):\n",
        "\n",
        "    @classmethod\n",
        "    def add_method(cls,func):\n",
        "        setattr(cls,func.__name__,func)\n",
        "        return func\n",
        "\n",
        "    def __init__(self,units=256,en_layer=en_vec_layer,es_layer=es_vec_layer,**kwargs):\n",
        "\n",
        "        super(Translator,self).__init__(**kwargs)\n",
        "\n",
        "        self.encoder = Encoder(units,en_layer)\n",
        "        self.decoder = Decoder(units,es_layer)\n",
        "\n",
        "\n",
        "    def call(self,inputs):\n",
        "\n",
        "        encoder_inputs,decoder_inputs = inputs\n",
        "\n",
        "        encoder_outputs = self.encoder(encoder_inputs)\n",
        "        total_out = self.decoder(encoder_outputs,decoder_inputs)\n",
        "\n",
        "        try:\n",
        "            del total_out._keras_mask\n",
        "        except AssertionError as error:\n",
        "            pass\n",
        "\n",
        "\n",
        "        return total_out"
      ],
      "metadata": {
        "cellView": "code",
        "id": "lQ3eOQ_JXSMA"
      },
      "execution_count": 507,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator()\n",
        "out = translator((en_in,es_in))\n",
        "print(\"english inputs (batch s)\",en_in.shape)\n",
        "print(\"spanish inputs (batch t)\",es_in.shape)\n",
        "print(\"logits outputs (batch t vocab_size)\",out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYxJLfFiv07R",
        "outputId": "29ed0fa2-3677-4735-8df1-ed9e6191ae1c"
      },
      "execution_count": 508,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "english inputs (batch s) (64, 20)\n",
            "spanish inputs (batch t) (64, 18)\n",
            "logits outputs (batch t vocab_size) (64, 18, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (en_in,es_in),y_in in train_ds.take(1):\n",
        "    print(en_in.shape)\n",
        "    print(es_in.shape)\n",
        "    print(y_in.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SMTpXN2-gJQ",
        "outputId": "ae4e480b-48ce-444c-ad5b-b93d0487f183"
      },
      "execution_count": 509,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction=\"none\")\n",
        "y_pred = translator((en_in,es_in))\n",
        "y_true = y_in\n",
        "calc_loss = loss_fn(y_true,y_pred)\n",
        "calc_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NYYqiU--qmJ",
        "outputId": "45753361-90ea-48a5-e5b2-09e3240e0f9a"
      },
      "execution_count": 510,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 15), dtype=float32, numpy=\n",
              "array([[8.51, 8.4 , 8.46, 8.61, 8.5 , 8.43, 8.42, 8.44, 8.53, 8.53, 8.53,\n",
              "        8.53, 8.53, 8.53, 8.53],\n",
              "       [8.59, 8.57, 8.55, 8.46, 8.51, 8.52, 8.52, 8.52, 8.52, 8.52, 8.52,\n",
              "        8.52, 8.52, 8.52, 8.52],\n",
              "       [8.57, 8.56, 8.47, 8.61, 8.52, 8.5 , 8.44, 8.49, 8.49, 8.49, 8.49,\n",
              "        8.49, 8.49, 8.49, 8.49],\n",
              "       [8.6 , 8.61, 8.5 , 8.56, 8.5 , 8.53, 8.5 , 8.5 , 8.5 , 8.5 , 8.5 ,\n",
              "        8.5 , 8.5 , 8.5 , 8.5 ],\n",
              "       [8.51, 8.45, 8.52, 8.52, 8.45, 8.54, 8.51, 8.48, 8.51, 8.46, 8.46,\n",
              "        8.46, 8.46, 8.46, 8.46],\n",
              "       [8.67, 8.57, 8.57, 8.64, 8.53, 8.67, 8.58, 8.56, 8.53, 8.52, 8.46,\n",
              "        8.46, 8.46, 8.46, 8.46],\n",
              "       [8.5 , 8.59, 8.5 , 8.55, 8.37, 8.48, 8.53, 8.46, 8.49, 8.44, 8.57,\n",
              "        8.57, 8.57, 8.57, 8.57],\n",
              "       [8.52, 8.49, 8.46, 8.51, 8.67, 8.55, 8.56, 8.48, 8.52, 8.51, 8.44,\n",
              "        8.6 , 8.58, 8.67, 8.59],\n",
              "       [8.55, 8.51, 8.57, 8.57, 8.44, 8.5 , 8.5 , 8.58, 8.58, 8.58, 8.58,\n",
              "        8.58, 8.58, 8.58, 8.58],\n",
              "       [8.48, 8.49, 8.54, 8.53, 8.5 , 8.49, 8.51, 8.53, 8.47, 8.47, 8.47,\n",
              "        8.47, 8.47, 8.47, 8.47],\n",
              "       [8.53, 8.49, 8.54, 8.6 , 8.53, 8.59, 8.59, 8.59, 8.59, 8.59, 8.59,\n",
              "        8.59, 8.59, 8.59, 8.59],\n",
              "       [8.53, 8.42, 8.51, 8.66, 8.47, 8.53, 8.58, 8.48, 8.57, 8.57, 8.57,\n",
              "        8.57, 8.57, 8.57, 8.57],\n",
              "       [8.52, 8.49, 8.57, 8.59, 8.57, 8.4 , 8.45, 8.53, 8.55, 8.55, 8.55,\n",
              "        8.55, 8.55, 8.55, 8.55],\n",
              "       [8.56, 8.46, 8.53, 8.44, 8.55, 8.49, 8.48, 8.48, 8.48, 8.48, 8.48,\n",
              "        8.48, 8.48, 8.48, 8.48],\n",
              "       [8.58, 8.55, 8.54, 8.54, 8.48, 8.58, 8.52, 8.5 , 8.44, 8.45, 8.56,\n",
              "        8.56, 8.56, 8.56, 8.56],\n",
              "       [8.57, 8.42, 8.57, 8.44, 8.62, 8.56, 8.6 , 8.47, 8.53, 8.51, 8.51,\n",
              "        8.51, 8.51, 8.51, 8.51],\n",
              "       [8.52, 8.44, 8.54, 8.51, 8.51, 8.54, 8.45, 8.45, 8.45, 8.45, 8.45,\n",
              "        8.45, 8.45, 8.45, 8.45],\n",
              "       [8.58, 8.47, 8.54, 8.5 , 8.48, 8.59, 8.43, 8.42, 8.52, 8.52, 8.52,\n",
              "        8.52, 8.52, 8.52, 8.52],\n",
              "       [8.49, 8.52, 8.49, 8.52, 8.49, 8.52, 8.49, 8.47, 8.52, 8.52, 8.52,\n",
              "        8.52, 8.52, 8.52, 8.52],\n",
              "       [8.57, 8.51, 8.55, 8.52, 8.55, 8.49, 8.55, 8.51, 8.53, 8.51, 8.51,\n",
              "        8.51, 8.51, 8.51, 8.51],\n",
              "       [8.49, 8.57, 8.6 , 8.57, 8.58, 8.52, 8.58, 8.58, 8.58, 8.58, 8.58,\n",
              "        8.58, 8.58, 8.58, 8.58],\n",
              "       [8.5 , 8.49, 8.47, 8.53, 8.58, 8.45, 8.54, 8.49, 8.52, 8.48, 8.48,\n",
              "        8.48, 8.48, 8.48, 8.48],\n",
              "       [8.57, 8.48, 8.44, 8.59, 8.41, 8.56, 8.51, 8.51, 8.51, 8.51, 8.51,\n",
              "        8.51, 8.51, 8.51, 8.51],\n",
              "       [8.53, 8.43, 8.47, 8.51, 8.5 , 8.4 , 8.56, 8.53, 8.53, 8.53, 8.53,\n",
              "        8.53, 8.53, 8.53, 8.53],\n",
              "       [8.52, 8.58, 8.52, 8.46, 8.49, 8.52, 8.42, 8.42, 8.42, 8.42, 8.42,\n",
              "        8.42, 8.42, 8.42, 8.42],\n",
              "       [8.5 , 8.45, 8.57, 8.54, 8.49, 8.6 , 8.51, 8.5 , 8.5 , 8.5 , 8.5 ,\n",
              "        8.5 , 8.5 , 8.5 , 8.5 ],\n",
              "       [8.54, 8.54, 8.49, 8.55, 8.51, 8.5 , 8.56, 8.55, 8.46, 8.55, 8.55,\n",
              "        8.55, 8.55, 8.55, 8.55],\n",
              "       [8.59, 8.55, 8.5 , 8.59, 8.64, 8.43, 8.53, 8.53, 8.53, 8.53, 8.53,\n",
              "        8.53, 8.53, 8.53, 8.53],\n",
              "       [8.51, 8.61, 8.62, 8.37, 8.55, 8.51, 8.48, 8.48, 8.48, 8.48, 8.48,\n",
              "        8.48, 8.48, 8.48, 8.48],\n",
              "       [8.49, 8.59, 8.53, 8.56, 8.65, 8.52, 8.48, 8.51, 8.51, 8.51, 8.51,\n",
              "        8.51, 8.51, 8.51, 8.51],\n",
              "       [8.49, 8.56, 8.43, 8.54, 8.54, 8.46, 8.48, 8.48, 8.48, 8.48, 8.48,\n",
              "        8.48, 8.48, 8.48, 8.48],\n",
              "       [8.53, 8.39, 8.64, 8.44, 8.51, 8.51, 8.49, 8.49, 8.49, 8.49, 8.49,\n",
              "        8.49, 8.49, 8.49, 8.49],\n",
              "       [8.52, 8.55, 8.68, 8.53, 8.53, 8.51, 8.49, 8.49, 8.49, 8.49, 8.49,\n",
              "        8.49, 8.49, 8.49, 8.49],\n",
              "       [8.47, 8.68, 8.41, 8.46, 8.54, 8.48, 8.47, 8.62, 8.62, 8.53, 8.51,\n",
              "        8.54, 8.47, 8.52, 8.6 ],\n",
              "       [8.58, 8.49, 8.41, 8.58, 8.52, 8.59, 8.53, 8.49, 8.53, 8.53, 8.53,\n",
              "        8.53, 8.53, 8.53, 8.53],\n",
              "       [8.51, 8.42, 8.48, 8.51, 8.35, 8.61, 8.55, 8.55, 8.49, 8.49, 8.49,\n",
              "        8.49, 8.49, 8.49, 8.49],\n",
              "       [8.51, 8.45, 8.54, 8.47, 8.4 , 8.48, 8.52, 8.52, 8.52, 8.52, 8.52,\n",
              "        8.52, 8.52, 8.52, 8.52],\n",
              "       [8.52, 8.43, 8.42, 8.47, 8.5 , 8.5 , 8.5 , 8.5 , 8.5 , 8.5 , 8.5 ,\n",
              "        8.5 , 8.5 , 8.5 , 8.5 ],\n",
              "       [8.55, 8.51, 8.43, 8.49, 8.54, 8.53, 8.45, 8.45, 8.45, 8.45, 8.45,\n",
              "        8.45, 8.45, 8.45, 8.45],\n",
              "       [8.52, 8.49, 8.51, 8.57, 8.49, 8.54, 8.53, 8.38, 8.52, 8.48, 8.52,\n",
              "        8.52, 8.52, 8.52, 8.52],\n",
              "       [8.59, 8.51, 8.5 , 8.33, 8.67, 8.56, 8.46, 8.6 , 8.52, 8.48, 8.5 ,\n",
              "        8.5 , 8.5 , 8.5 , 8.5 ],\n",
              "       [8.51, 8.43, 8.52, 8.58, 8.53, 8.46, 8.52, 8.4 , 8.66, 8.58, 8.52,\n",
              "        8.5 , 8.5 , 8.5 , 8.5 ],\n",
              "       [8.61, 8.52, 8.48, 8.52, 8.46, 8.46, 8.46, 8.46, 8.46, 8.46, 8.46,\n",
              "        8.46, 8.46, 8.46, 8.46],\n",
              "       [8.58, 8.55, 8.45, 8.56, 8.47, 8.5 , 8.48, 8.47, 8.47, 8.47, 8.47,\n",
              "        8.47, 8.47, 8.47, 8.47],\n",
              "       [8.49, 8.52, 8.54, 8.45, 8.54, 8.58, 8.36, 8.48, 8.53, 8.53, 8.53,\n",
              "        8.53, 8.53, 8.53, 8.53],\n",
              "       [8.43, 8.54, 8.58, 8.61, 8.57, 8.53, 8.45, 8.45, 8.45, 8.45, 8.45,\n",
              "        8.45, 8.45, 8.45, 8.45],\n",
              "       [8.56, 8.55, 8.63, 8.53, 8.48, 8.49, 8.43, 8.43, 8.43, 8.43, 8.43,\n",
              "        8.43, 8.43, 8.43, 8.43],\n",
              "       [8.56, 8.39, 8.47, 8.53, 8.48, 8.47, 8.58, 8.47, 8.45, 8.45, 8.45,\n",
              "        8.45, 8.45, 8.45, 8.45],\n",
              "       [8.5 , 8.54, 8.49, 8.4 , 8.45, 8.62, 8.51, 8.41, 8.48, 8.5 , 8.5 ,\n",
              "        8.5 , 8.5 , 8.5 , 8.5 ],\n",
              "       [8.48, 8.55, 8.64, 8.49, 8.42, 8.52, 8.56, 8.53, 8.53, 8.53, 8.53,\n",
              "        8.53, 8.53, 8.53, 8.53],\n",
              "       [8.56, 8.45, 8.53, 8.47, 8.52, 8.48, 8.55, 8.55, 8.55, 8.55, 8.55,\n",
              "        8.55, 8.55, 8.55, 8.55],\n",
              "       [8.58, 8.58, 8.55, 8.58, 8.57, 8.43, 8.48, 8.64, 8.47, 8.52, 8.48,\n",
              "        8.48, 8.51, 8.49, 8.49],\n",
              "       [8.52, 8.56, 8.49, 8.55, 8.55, 8.55, 8.54, 8.54, 8.54, 8.54, 8.54,\n",
              "        8.54, 8.54, 8.54, 8.54],\n",
              "       [8.58, 8.54, 8.44, 8.49, 8.52, 8.55, 8.61, 8.53, 8.5 , 8.44, 8.54,\n",
              "        8.54, 8.54, 8.54, 8.54],\n",
              "       [8.58, 8.5 , 8.56, 8.57, 8.56, 8.55, 8.37, 8.43, 8.49, 8.54, 8.54,\n",
              "        8.54, 8.54, 8.54, 8.54],\n",
              "       [8.56, 8.36, 8.45, 8.45, 8.36, 8.53, 8.66, 8.49, 8.51, 8.38, 8.38,\n",
              "        8.38, 8.38, 8.38, 8.38],\n",
              "       [8.62, 8.49, 8.54, 8.48, 8.4 , 8.43, 8.61, 8.57, 8.58, 8.6 , 8.57,\n",
              "        8.52, 8.48, 8.45, 8.45],\n",
              "       [8.63, 8.5 , 8.55, 8.63, 8.62, 8.52, 8.57, 8.52, 8.47, 8.47, 8.47,\n",
              "        8.47, 8.47, 8.47, 8.47],\n",
              "       [8.52, 8.52, 8.56, 8.46, 8.3 , 8.55, 8.61, 8.5 , 8.57, 8.57, 8.57,\n",
              "        8.57, 8.57, 8.57, 8.57],\n",
              "       [8.43, 8.5 , 8.45, 8.58, 8.54, 8.74, 8.55, 8.47, 8.56, 8.45, 8.47,\n",
              "        8.47, 8.47, 8.47, 8.47],\n",
              "       [8.57, 8.49, 8.47, 8.5 , 8.42, 8.58, 8.59, 8.54, 8.47, 8.49, 8.49,\n",
              "        8.49, 8.49, 8.49, 8.49],\n",
              "       [8.5 , 8.43, 8.5 , 8.49, 8.49, 8.58, 8.47, 8.48, 8.51, 8.59, 8.59,\n",
              "        8.59, 8.59, 8.59, 8.59],\n",
              "       [8.48, 8.47, 8.66, 8.49, 8.49, 8.48, 8.56, 8.56, 8.56, 8.56, 8.56,\n",
              "        8.56, 8.56, 8.56, 8.56],\n",
              "       [8.47, 8.54, 8.56, 8.48, 8.56, 8.47, 8.46, 8.45, 8.45, 8.45, 8.45,\n",
              "        8.45, 8.45, 8.45, 8.45]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 510
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = tf.cast(y_true != 0,calc_loss.dtype)\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cViz0vs0__Gd",
        "outputId": "06bdef2a-347b-4f4b-de32-05c1d0411809"
      },
      "execution_count": 511,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 15), dtype=float32, numpy=\n",
              "array([[1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 511
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_loss *= mask\n",
        "calc_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hnfeK25AH33",
        "outputId": "30ea5c0d-569a-452e-9750-b1420c773ba0"
      },
      "execution_count": 512,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 15), dtype=float32, numpy=\n",
              "array([[8.51, 8.4 , 8.46, 8.61, 8.5 , 8.43, 8.42, 8.44, 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.59, 8.57, 8.55, 8.46, 8.51, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.57, 8.56, 8.47, 8.61, 8.52, 8.5 , 8.44, 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.6 , 8.61, 8.5 , 8.56, 8.5 , 8.53, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.51, 8.45, 8.52, 8.52, 8.45, 8.54, 8.51, 8.48, 8.51, 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.67, 8.57, 8.57, 8.64, 8.53, 8.67, 8.58, 8.56, 8.53, 8.52, 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.5 , 8.59, 8.5 , 8.55, 8.37, 8.48, 8.53, 8.46, 8.49, 8.44, 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.52, 8.49, 8.46, 8.51, 8.67, 8.55, 8.56, 8.48, 8.52, 8.51, 8.44,\n",
              "        8.6 , 8.58, 8.67, 8.59],\n",
              "       [8.55, 8.51, 8.57, 8.57, 8.44, 8.5 , 8.5 , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.48, 8.49, 8.54, 8.53, 8.5 , 8.49, 8.51, 8.53, 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.53, 8.49, 8.54, 8.6 , 8.53, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.53, 8.42, 8.51, 8.66, 8.47, 8.53, 8.58, 8.48, 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.52, 8.49, 8.57, 8.59, 8.57, 8.4 , 8.45, 8.53, 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.56, 8.46, 8.53, 8.44, 8.55, 8.49, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.58, 8.55, 8.54, 8.54, 8.48, 8.58, 8.52, 8.5 , 8.44, 8.45, 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.57, 8.42, 8.57, 8.44, 8.62, 8.56, 8.6 , 8.47, 8.53, 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.52, 8.44, 8.54, 8.51, 8.51, 8.54, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.58, 8.47, 8.54, 8.5 , 8.48, 8.59, 8.43, 8.42, 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.49, 8.52, 8.49, 8.52, 8.49, 8.52, 8.49, 8.47, 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.57, 8.51, 8.55, 8.52, 8.55, 8.49, 8.55, 8.51, 8.53, 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.49, 8.57, 8.6 , 8.57, 8.58, 8.52, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.5 , 8.49, 8.47, 8.53, 8.58, 8.45, 8.54, 8.49, 8.52, 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.57, 8.48, 8.44, 8.59, 8.41, 8.56, 8.51, 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.53, 8.43, 8.47, 8.51, 8.5 , 8.4 , 8.56, 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.52, 8.58, 8.52, 8.46, 8.49, 8.52, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.5 , 8.45, 8.57, 8.54, 8.49, 8.6 , 8.51, 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.54, 8.54, 8.49, 8.55, 8.51, 8.5 , 8.56, 8.55, 8.46, 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.59, 8.55, 8.5 , 8.59, 8.64, 8.43, 8.53, 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.51, 8.61, 8.62, 8.37, 8.55, 8.51, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.49, 8.59, 8.53, 8.56, 8.65, 8.52, 8.48, 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.49, 8.56, 8.43, 8.54, 8.54, 8.46, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.53, 8.39, 8.64, 8.44, 8.51, 8.51, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.52, 8.55, 8.68, 8.53, 8.53, 8.51, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.47, 8.68, 8.41, 8.46, 8.54, 8.48, 8.47, 8.62, 8.62, 8.53, 8.51,\n",
              "        8.54, 8.47, 8.52, 0.  ],\n",
              "       [8.58, 8.49, 8.41, 8.58, 8.52, 8.59, 8.53, 8.49, 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.51, 8.42, 8.48, 8.51, 8.35, 8.61, 8.55, 8.55, 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.51, 8.45, 8.54, 8.47, 8.4 , 8.48, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.52, 8.43, 8.42, 8.47, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.55, 8.51, 8.43, 8.49, 8.54, 8.53, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.52, 8.49, 8.51, 8.57, 8.49, 8.54, 8.53, 8.38, 8.52, 8.48, 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.59, 8.51, 8.5 , 8.33, 8.67, 8.56, 8.46, 8.6 , 8.52, 8.48, 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.51, 8.43, 8.52, 8.58, 8.53, 8.46, 8.52, 8.4 , 8.66, 8.58, 8.52,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.61, 8.52, 8.48, 8.52, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.58, 8.55, 8.45, 8.56, 8.47, 8.5 , 8.48, 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.49, 8.52, 8.54, 8.45, 8.54, 8.58, 8.36, 8.48, 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.43, 8.54, 8.58, 8.61, 8.57, 8.53, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.56, 8.55, 8.63, 8.53, 8.48, 8.49, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.56, 8.39, 8.47, 8.53, 8.48, 8.47, 8.58, 8.47, 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.5 , 8.54, 8.49, 8.4 , 8.45, 8.62, 8.51, 8.41, 8.48, 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.48, 8.55, 8.64, 8.49, 8.42, 8.52, 8.56, 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.56, 8.45, 8.53, 8.47, 8.52, 8.48, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.58, 8.58, 8.55, 8.58, 8.57, 8.43, 8.48, 8.64, 8.47, 8.52, 8.48,\n",
              "        8.48, 8.51, 0.  , 0.  ],\n",
              "       [8.52, 8.56, 8.49, 8.55, 8.55, 8.55, 8.54, 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.58, 8.54, 8.44, 8.49, 8.52, 8.55, 8.61, 8.53, 8.5 , 8.44, 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.58, 8.5 , 8.56, 8.57, 8.56, 8.55, 8.37, 8.43, 8.49, 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.56, 8.36, 8.45, 8.45, 8.36, 8.53, 8.66, 8.49, 8.51, 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.62, 8.49, 8.54, 8.48, 8.4 , 8.43, 8.61, 8.57, 8.58, 8.6 , 8.57,\n",
              "        8.52, 8.48, 0.  , 0.  ],\n",
              "       [8.63, 8.5 , 8.55, 8.63, 8.62, 8.52, 8.57, 8.52, 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.52, 8.52, 8.56, 8.46, 8.3 , 8.55, 8.61, 8.5 , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.43, 8.5 , 8.45, 8.58, 8.54, 8.74, 8.55, 8.47, 8.56, 8.45, 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.57, 8.49, 8.47, 8.5 , 8.42, 8.58, 8.59, 8.54, 8.47, 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.5 , 8.43, 8.5 , 8.49, 8.49, 8.58, 8.47, 8.48, 8.51, 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.48, 8.47, 8.66, 8.49, 8.49, 8.48, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ],\n",
              "       [8.47, 8.54, 8.56, 8.48, 8.56, 8.47, 8.46, 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 512
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_loss = tf.reduce_sum(calc_loss)\n",
        "reduced_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8ZaiCWHAMvP",
        "outputId": "f74e8009-90b5-4509-c7d5-eea269f90d15"
      },
      "execution_count": 513,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=4318.413>"
            ]
          },
          "metadata": {},
          "execution_count": 513
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_mask = tf.reduce_sum(mask)\n",
        "reduced_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcbROPF2Aj1j",
        "outputId": "266acb75-44e8-4c7a-957b-63e19cdaf34b"
      },
      "execution_count": 514,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=507.0>"
            ]
          },
          "metadata": {},
          "execution_count": 514
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_loss/reduced_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnTBg2VMAtc9",
        "outputId": "6daeb386-ca12-4509-f90a-2c46dce14b6e"
      },
      "execution_count": 515,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.51758>"
            ]
          },
          "metadata": {},
          "execution_count": 515
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn_reduced = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "loss_fn_reduced(y_true,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg-z0xfIA4KC",
        "outputId": "9393cfe1-4d44-4a4a-fd17-48ed12fd43a6"
      },
      "execution_count": 516,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.511817>"
            ]
          },
          "metadata": {},
          "execution_count": 516
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = tf.argmax(y_true,axis=-1)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbS0lrIcBQEF",
        "outputId": "e117fca1-f7be-41bd-e60d-a44ae21c64b8"
      },
      "execution_count": 517,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
              "array([ 5,  1,  2,  0,  0,  1,  1, 12,  4,  5,  2,  2,  2,  2,  5,  5,  3,\n",
              "        2,  2,  4,  2,  1,  0,  4,  1,  2,  6,  4,  1,  1,  1,  1,  3, 11,\n",
              "        3,  2,  1,  1,  3,  3,  2,  8,  1,  4,  5,  2,  3,  4,  3,  2,  2,\n",
              "       10,  2,  4,  2,  3,  9,  5,  3,  6,  6,  6,  3,  0])>"
            ]
          },
          "metadata": {},
          "execution_count": 517
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = tf.cast(y_pred,y_true.dtype)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WQ1nAz4BcB8",
        "outputId": "bf155ba2-3446-4e34-e5bb-fba817872f01"
      },
      "execution_count": 518,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
              "array([ 5,  1,  2,  0,  0,  1,  1, 12,  4,  5,  2,  2,  2,  2,  5,  5,  3,\n",
              "        2,  2,  4,  2,  1,  0,  4,  1,  2,  6,  4,  1,  1,  1,  1,  3, 11,\n",
              "        3,  2,  1,  1,  3,  3,  2,  8,  1,  4,  5,  2,  3,  4,  3,  2,  2,\n",
              "       10,  2,  4,  2,  3,  9,  5,  3,  6,  6,  6,  3,  0])>"
            ]
          },
          "metadata": {},
          "execution_count": 518
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_tensor = tf.cast(y_true == y_pred, tf.float32)\n",
        "accuracy_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H8Yg4sGBrhZ",
        "outputId": "5ed941c6-d12d-406d-a162-3f3432282102"
      },
      "execution_count": 519,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "metadata": {},
          "execution_count": 519
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = tf.cast(y_true != 0,tf.float32)\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTsnuw6CCH1Z",
        "outputId": "99fb229e-80d5-4007-fec5-ebe9362ad48f"
      },
      "execution_count": 520,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 15), dtype=float32, numpy=\n",
              "array([[1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 520
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reduce_sum(accuracy_tensor)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H_dqSr4CSU6",
        "outputId": "41a3bce0-5fb3-484a-b27a-d57b79487d1c"
      },
      "execution_count": 521,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "metadata": {},
          "execution_count": 521
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(y_true,y_pred):\n",
        "    loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction=\"none\")\n",
        "    loss = loss_fn(y_true,y_pred)\n",
        "    mask = tf.cast(y_true != 0,y_true.dtype)\n",
        "    loss *= mask\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "\n",
        "def masked_accuracy(y_true,y_pred):\n",
        "    y_pred = tf.argmax(y_pred,axis=-1,output_type=y_true.dtype)\n",
        "    accuracy = tf.cast(y_true == y_pred,tf.float32)\n",
        "    mask = tf.cast(y_true != 0,tf.float32)\n",
        "    return tf.reduce_sum(accuracy)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "Fqr7N4dxCYsI"
      },
      "execution_count": 522,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_accuracy(y_in,translator((en_in,es_in)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdII50aoHKlw",
        "outputId": "9dbae759-70ea-46b7-c886-29867ff4b2ba"
      },
      "execution_count": 523,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "metadata": {},
          "execution_count": 523
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator.compile(optimizer=\"adam\",loss=masked_loss,metrics=[masked_accuracy,masked_loss])"
      ],
      "metadata": {
        "id": "ql4WX01hKCl5"
      },
      "execution_count": 524,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,y in valid_ds:\n",
        "    print(i[0].shape)\n",
        "    print(i[1].shape)\n",
        "    print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e6KAQGzLLxe",
        "outputId": "63ce3f6c-8d7d-46d5-b615-0af54ca523b6"
      },
      "execution_count": 525,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 22)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 29)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 25)\n",
            "(64, 27)\n",
            "(64, 27)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 26)\n",
            "(64, 27)\n",
            "(64, 27)\n",
            "(64, 14)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 22)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 14)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 17)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 20)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 37)\n",
            "(64, 38)\n",
            "(64, 38)\n",
            "(64, 19)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 19)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 39)\n",
            "(64, 45)\n",
            "(64, 45)\n",
            "(64, 24)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 23)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 24)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 24)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 21)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 51)\n",
            "(64, 52)\n",
            "(64, 52)\n",
            "(64, 21)\n",
            "(64, 24)\n",
            "(64, 24)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 23)\n",
            "(64, 27)\n",
            "(64, 27)\n",
            "(64, 23)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 22)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 26)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 23)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 26)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 21)\n",
            "(64, 27)\n",
            "(64, 27)\n",
            "(64, 26)\n",
            "(64, 37)\n",
            "(64, 37)\n",
            "(64, 24)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 21)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 22)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 18)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 22)\n",
            "(64, 27)\n",
            "(64, 27)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 21)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 24)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 20)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 28)\n",
            "(64, 28)\n",
            "(64, 19)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 28)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 18)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 22)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 15)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 21)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 22)\n",
            "(64, 24)\n",
            "(64, 24)\n",
            "(64, 22)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 13)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 21)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 14)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 20)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 21)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 29)\n",
            "(64, 27)\n",
            "(64, 27)\n",
            "(64, 20)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 24)\n",
            "(64, 24)\n",
            "(64, 26)\n",
            "(64, 27)\n",
            "(64, 27)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 14)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 23)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 20)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 24)\n",
            "(64, 27)\n",
            "(64, 27)\n",
            "(64, 17)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 22)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 21)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 21)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 21)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 20)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 14)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 21)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 22)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 22)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 22)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 23)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 24)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 29)\n",
            "(64, 24)\n",
            "(64, 24)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 22)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 18)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 15)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 18)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 29)\n",
            "(64, 28)\n",
            "(64, 28)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 24)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 31)\n",
            "(64, 31)\n",
            "(64, 31)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 26)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 17)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 20)\n",
            "(64, 26)\n",
            "(64, 26)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 22)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 22)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 26)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 20)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 22)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 22)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(41, 18)\n",
            "(41, 18)\n",
            "(41, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator.evaluate(valid_ds,steps=20,return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rnIfBg-kKUze",
        "outputId": "31ea5afa-547f-4f2f-d2e8-265046407752"
      },
      "execution_count": 526,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-526-b78fdd38bfd5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filep67as5yu.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0mtotal_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file7_irrwf4.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_checker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_checker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch s units'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mencoder_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filesrdqdiv5.py\u001b[0m in \u001b[0;36mtf____call__\u001b[0;34m(self, tensor, names, broadcast)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mnew_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'new_dim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mcontinue_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'continue_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'(name, new_dim)'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf____call__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filesrdqdiv5.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     90\u001b[0m                         \u001b[0;32mnonlocal\u001b[0m \u001b[0mcontinue_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinue_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'self.shapes[name]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'continue_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0mold_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'old_dim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filesrdqdiv5.py\u001b[0m in \u001b[0;36mif_body_4\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0melse_body_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                         \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinue_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0;32mdef\u001b[0m \u001b[0melse_body_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filesrdqdiv5.py\u001b[0m in \u001b[0;36mif_body_3\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m                             \u001b[0;32mdef\u001b[0m \u001b[0melse_body_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                             \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0melse_body_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filesrdqdiv5.py\u001b[0m in \u001b[0;36mif_body_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                             \u001b[0;32mdef\u001b[0m \u001b[0mif_body_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                                 \u001b[0;32mraise\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf\"SHAPE MISTMATCH FOR DIMENSION: '{ag__.ld(name)}' FOUND: {ag__.ld(new_dim)} EXPECTED: {ag__.ld(old_dim)}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                             \u001b[0;32mdef\u001b[0m \u001b[0melse_body_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1972, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1956, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1944, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1850, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filep67as5yu.py\", line 11, in tf__call\n        encoder_outputs = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(encoder_inputs),), None, fscope)\n    File \"/tmp/__autograph_generated_file7_irrwf4.py\", line 13, in tf__call\n        ag__.converted_call(ag__.ld(shape_checker), (ag__.ld(z), 'batch s units'), None, fscope)\n    File \"/tmp/__autograph_generated_filesrdqdiv5.py\", line 97, in tf____call__\n        ag__.for_stmt(ag__.converted_call(ag__.ld(parsed).items, (), None, fscope), None, loop_body, get_state_5, set_state_5, (), {'iterate_names': '(name, new_dim)'})\n    File \"/tmp/__autograph_generated_filesrdqdiv5.py\", line 92, in loop_body\n        ag__.if_stmt(ag__.not_(continue_), if_body_4, else_body_4, get_state_4, set_state_4, ('self.shapes[name]', 'continue_'), 1)\n    File \"/tmp/__autograph_generated_filesrdqdiv5.py\", line 87, in if_body_4\n        ag__.if_stmt(ag__.not_(continue_), if_body_3, else_body_3, get_state_3, set_state_3, (), 0)\n    File \"/tmp/__autograph_generated_filesrdqdiv5.py\", line 83, in if_body_3\n        ag__.if_stmt(ag__.ld(new_dim) != ag__.ld(old_dim), if_body_2, else_body_2, get_state_2, set_state_2, (), 0)\n    File \"/tmp/__autograph_generated_filesrdqdiv5.py\", line 79, in if_body_2\n        raise ag__.converted_call(ag__.ld(ValueError), (f\"SHAPE MISTMATCH FOR DIMENSION: '{ag__.ld(name)}' FOUND: {ag__.ld(new_dim)} EXPECTED: {ag__.ld(old_dim)}\",), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'translator_7' (type Translator).\n    \n    in user code:\n    \n        File \"<ipython-input-406-b5d868797a19>\", line 20, in call  *\n            encoder_outputs = self.encoder(encoder_inputs)\n        File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/tmp/__autograph_generated_file7_irrwf4.py\", line 13, in tf__call\n            ag__.converted_call(ag__.ld(shape_checker), (ag__.ld(z), 'batch s units'), None, fscope)\n        File \"/tmp/__autograph_generated_filesrdqdiv5.py\", line 97, in tf____call__\n            ag__.for_stmt(ag__.converted_call(ag__.ld(parsed).items, (), None, fscope), None, loop_body, get_state_5, set_state_5, (), {'iterate_names': '(name, new_dim)'})\n        File \"/tmp/__autograph_generated_filesrdqdiv5.py\", line 92, in loop_body\n            ag__.if_stmt(ag__.not_(continue_), if_body_4, else_body_4, get_state_4, set_state_4, ('self.shapes[name]', 'continue_'), 1)\n        File \"/tmp/__autograph_generated_filesrdqdiv5.py\", line 87, in if_body_4\n            ag__.if_stmt(ag__.not_(continue_), if_body_3, else_body_3, get_state_3, set_state_3, (), 0)\n        File \"/tmp/__autograph_generated_filesrdqdiv5.py\", line 83, in if_body_3\n            ag__.if_stmt(ag__.ld(new_dim) != ag__.ld(old_dim), if_body_2, else_body_2, get_state_2, set_state_2, (), 0)\n        File \"/tmp/__autograph_generated_filesrdqdiv5.py\", line 79, in if_body_2\n            raise ag__.converted_call(ag__.ld(ValueError), (f\"SHAPE MISTMATCH FOR DIMENSION: '{ag__.ld(name)}' FOUND: {ag__.ld(new_dim)} EXPECTED: {ag__.ld(old_dim)}\",), None, fscope)\n    \n        ValueError: Exception encountered when calling layer 'encoder_7' (type Encoder).\n        \n        in user code:\n        \n            File \"<ipython-input-389-cbc2b06f27ff>\", line 18, in call  *\n                shape_checker(z,\"batch s units\")\n            File \"<ipython-input-450-5b7e6fdfd84a>\", line 25, in __call__  *\n                raise ValueError(f\"SHAPE MISTMATCH FOR DIMENSION: '{name}' FOUND: {new_dim} EXPECTED: {old_dim}\")\n        \n            ValueError: SHAPE MISTMATCH FOR DIMENSION: 'batch' FOUND: Tensor(\"translator_7/encoder_7/strided_slice_2:0\", shape=(), dtype=int32) EXPECTED: Tensor(\"translator_7/encoder_7/strided_slice:0\", shape=(), dtype=int32)\n        \n        \n        Call arguments received by layer 'encoder_7' (type Encoder):\n          • inputs=tf.Tensor(shape=(None, None), dtype=int64)\n    \n    \n    Call arguments received by layer 'translator_7' (type Translator):\n      • inputs=('tf.Tensor(shape=(None, None), dtype=int64)', 'tf.Tensor(shape=(None, None), dtype=int64)')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}