{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h4ck4l1/datasets/blob/main/NLP_with_RNN_and_Attention/NMT_with_attention_google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {
        "id": "VRuR4P2evZaO"
      },
      "outputs": [],
      "source": [
        "import os,warnings,sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    !pip3 install -q -U \"tensorflow-text==2.13.0\"\n",
        "    !pip3 install -q -U einops\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from IPython.display import clear_output\n",
        "os.environ[\"TF_MIN_LOG_LEVEL\"] = \"3\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_text as text\n",
        "import typing\n",
        "from zipfile import ZipFile\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import einops\n",
        "pio.templates.default = \"plotly_dark\"\n",
        "import numpy as np\n",
        "np.set_printoptions(precision=2)\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "%xmode Minimal\n",
        "if \"google.colab\" in sys.modules:\n",
        "    clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {
        "id": "f2erXwlqwLBh"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ShapeCheck():\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.shapes = {}\n",
        "\n",
        "    def __call__(self,tensor,names,broadcast=False):\n",
        "\n",
        "        parsed = einops.parse_shape(tensor,names)\n",
        "\n",
        "        for name,new_dim in parsed.items():\n",
        "\n",
        "            old_dim = self.shapes.get(name,None)\n",
        "\n",
        "            if broadcast and (new_dim == 1):\n",
        "                continue\n",
        "\n",
        "            if old_dim is None:\n",
        "\n",
        "                self.shapes[name] = new_dim\n",
        "                continue\n",
        "\n",
        "            if new_dim != old_dim:\n",
        "\n",
        "                raise ValueError(f\"SHAPE MISTMATCH FOR DIMENSION: '{name}' FOUND: {new_dim} EXPECTED: {old_dim}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {
        "id": "lhHg7Efy9Mvo"
      },
      "outputs": [],
      "source": [
        "url = \"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "metadata": {
        "id": "EDT6uPFe-i-0"
      },
      "outputs": [],
      "source": [
        "file_path = keras.utils.get_file(fname=\"spa-eng.zip\",origin=url,extract=True)\n",
        "\n",
        "with ZipFile(file_path,\"r\") as f:\n",
        "\n",
        "    f.extractall(\"spa-eng\")\n",
        "\n",
        "with open(\"spa-eng/spa-eng/spa.txt\",\"r\") as f:\n",
        "\n",
        "    total_text = f.read()\n",
        "    total_text = [line.split(\"\\t\") for line in total_text.splitlines()]\n",
        "    en_text,es_text = zip(*total_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5lrAdXx3_Q-M",
        "outputId": "4ba3c0fc-322e-492a-86da-721ee4cded02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 352
        }
      ],
      "source": [
        "en_text[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGKfYpb6AhS0",
        "outputId": "b5886a61-cc3d-4c19-ec40-7cef39479f51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 353
        }
      ],
      "source": [
        "es_text[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "metadata": {
        "id": "mdA_HJWQAjDX"
      },
      "outputs": [],
      "source": [
        "en_array = np.array(en_text)\n",
        "es_array = np.array(es_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 355,
      "metadata": {
        "id": "t6-MP_RfCFqV"
      },
      "outputs": [],
      "source": [
        "is_train = np.random.uniform(size=(len(en_array),)) < 0.8\n",
        "\n",
        "raw_train = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((en_array[is_train],es_array[is_train]))\n",
        "    .shuffle(len(en_text))\n",
        "    .batch(64)\n",
        ")\n",
        "raw_valid = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((en_array[~is_train],es_array[~is_train]))\n",
        "    .shuffle(len(en_text))\n",
        "    .batch(64)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 356,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73KFDI7MC6OE",
        "outputId": "caf7196b-1f7f-400b-8805-3ed047895a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'You were in a coma.' b'Come back here.'\n",
            " b'Tom said I looked interested.' b'Are you sure you want to go with Tom?'], shape=(4,), dtype=string)\n",
            "translates to latin as \n",
            "tf.Tensor(\n",
            "[b'Estuvisteis en coma.' b'Vuelve aqu\\xc3\\xad.'\n",
            " b'Tom dijo que yo parec\\xc3\\xada interesado.'\n",
            " b'\\xc2\\xbfEst\\xc3\\xa1s segura que quer\\xc3\\xa9s ir con Tom?'], shape=(4,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for en,es in raw_train.take(1):\n",
        "    print(en[:4])\n",
        "    print(\"translates to latin as \")\n",
        "    print(es[:4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWoeMzZlKou5"
      },
      "source": [
        "# Standardize Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 357,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdPVTQtWmK4N",
        "outputId": "a5c8f1bb-77d7-4bc9-8447-643b058adcff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Ve.',\n",
              " 'Vete.',\n",
              " 'Vaya.',\n",
              " 'Váyase.',\n",
              " 'Hola.',\n",
              " '¡Corre!',\n",
              " 'Corred.',\n",
              " '¿Quién?',\n",
              " '¡Fuego!',\n",
              " '¡Incendio!')"
            ]
          },
          "metadata": {},
          "execution_count": 357
        }
      ],
      "source": [
        "es_text[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmaSDOGJWpgR",
        "outputId": "2117af53-d097-4c57-93d6-2c98fa4e3a01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b'Ve.', b'Vete.', b'Vaya.', b'V\\xc3\\xa1yase.', b'Hola.',\n",
              "       b'\\xc2\\xa1Corre!', b'Corred.', b'\\xc2\\xbfQui\\xc3\\xa9n?',\n",
              "       b'\\xc2\\xa1Fuego!', b'\\xc2\\xa1Incendio!'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 358
        }
      ],
      "source": [
        "tf.constant(es_text[:10]) # converting to tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUSK23dUYeGl",
        "outputId": "97ea1d25-ece0-4793-f6a9-f26f7142db95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b'Ve.', b'Vete.', b'Vaya.', b'Va\\xcc\\x81yase.', b'Hola.',\n",
              "       b'\\xc2\\xa1Corre!', b'Corred.', b'\\xc2\\xbfQuie\\xcc\\x81n?',\n",
              "       b'\\xc2\\xa1Fuego!', b'\\xc2\\xa1Incendio!'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 359
        }
      ],
      "source": [
        "temp_text = text.normalize_utf8(es_text[:10],\"NFKD\") # Normalizing text so that it can be used in operations\n",
        "temp_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 360,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNjOpADzjK_q",
        "outputId": "6196c911-c7a0-44ad-a624-e003623b193b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b've.', b'vete.', b'vaya.', b'va\\xcc\\x81yase.', b'hola.',\n",
              "       b'\\xc2\\xa1corre!', b'corred.', b'\\xc2\\xbfquie\\xcc\\x81n?',\n",
              "       b'\\xc2\\xa1fuego!', b'\\xc2\\xa1incendio!'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 360
        }
      ],
      "source": [
        "temp_text_1 = tf.strings.lower(temp_text) # Lower casing all the characters\n",
        "temp_text_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 361,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvtl-SerZ3zX",
        "outputId": "9ac25b35-56e0-4eed-b3c9-a4e43a6fda9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b've.', b'vete.', b'vaya.', b'vayase.', b'hola.', b'corre!',\n",
              "       b'corred.', b'\\xc2\\xbfquien?', b'fuego!', b'incendio!'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 361
        }
      ],
      "source": [
        "temp_text_2 = tf.strings.regex_replace(temp_text_1,\"[^ a-z.?!,¿]\",\"\")  # [^ ...] means exclude..so excluding all the a-z and rest\n",
        "temp_text_2                                                            # and replacing with noting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 362,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shZsU98Nk87Z",
        "outputId": "c3bfb8e0-b642-42b3-d0d5-42e93c44c8cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b've . ', b'vete . ', b'vaya . ', b'vayase . ', b'hola . ',\n",
              "       b'corre ! ', b'corred . ', b' \\xc2\\xbf quien ? ', b'fuego ! ',\n",
              "       b'incendio ! '], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 362
        }
      ],
      "source": [
        "temp_text_3 = tf.strings.regex_replace(temp_text_2,\"[.¡¿,?!]\",r' \\0 ') # Placing a null character[raw_string : r'']\n",
        "temp_text_3                                                            # before and after every punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 363,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwz8o9kome63",
        "outputId": "c7c490da-95f0-460b-a439-95b15e64d8b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b've .', b'vete .', b'vaya .', b'vayase .', b'hola .', b'corre !',\n",
              "       b'corred .', b'\\xc2\\xbf quien ?', b'fuego !', b'incendio !'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 363
        }
      ],
      "source": [
        "temp_text_4= tf.strings.strip(temp_text_3) # stripping any extra spaces\n",
        "temp_text_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZeMXXT_mkUw",
        "outputId": "5d6da7d1-f0fb-4c4d-ce86-8eb161e20836"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b'[startofsequence] ve . [endofsequence]',\n",
              "       b'[startofsequence] vete . [endofsequence]',\n",
              "       b'[startofsequence] vaya . [endofsequence]',\n",
              "       b'[startofsequence] vayase . [endofsequence]',\n",
              "       b'[startofsequence] hola . [endofsequence]',\n",
              "       b'[startofsequence] corre ! [endofsequence]',\n",
              "       b'[startofsequence] corred . [endofsequence]',\n",
              "       b'[startofsequence] \\xc2\\xbf quien ? [endofsequence]',\n",
              "       b'[startofsequence] fuego ! [endofsequence]',\n",
              "       b'[startofsequence] incendio ! [endofsequence]'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 364
        }
      ],
      "source": [
        "temp_text_5 = tf.strings.join(['[startofsequence]',temp_text_4,'[endofsequence]'],separator=\" \")\n",
        "temp_text_5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {
        "id": "eNj9-XOmnDSB"
      },
      "outputs": [],
      "source": [
        "def text_preprocessor(input_text):\n",
        "\n",
        "    input_text = text.normalize_utf8(input_text,\"NFKD\")\n",
        "    input_text = tf.strings.lower(input_text)\n",
        "    input_text = tf.strings.regex_replace(input_text,\"[^ a-z?.!¿¡,]\",\"\")\n",
        "    input_text = tf.strings.regex_replace(input_text,\"[?.!¿¡,]\",r\" \\0 \")\n",
        "    input_text = tf.strings.strip(input_text)\n",
        "    input_text = tf.strings.join([\"[startofsequence]\",input_text,\"[endofsequence]\"],separator=\" \")\n",
        "    return input_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBd-bHWivIkj"
      },
      "source": [
        "# Text Vectorization of En and Es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 366,
      "metadata": {
        "id": "LYvLY4eBuTxT"
      },
      "outputs": [],
      "source": [
        "vocab_size = 5000\n",
        "\n",
        "en_vec_layer = keras.layers.TextVectorization(vocab_size,standardize=text_preprocessor,ragged=True)\n",
        "en_vec_layer.adapt(raw_train.map(lambda en,es:en))\n",
        "es_vec_layer = keras.layers.TextVectorization(vocab_size,standardize=text_preprocessor,ragged=True)\n",
        "es_vec_layer.adapt(raw_train.map(lambda en,es:es))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 367,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r2hLyWx0eRg",
        "outputId": "27ce991e-47d0-4eae-c646-e4aaa67d65b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', '[startofsequence]', '[endofsequence]', '.', 'the', 'i', 'to', 'you', 'tom']\n",
            "['', '[UNK]', '[startofsequence]', '[endofsequence]', '.', 'que', 'de', 'el', 'a', 'no']\n"
          ]
        }
      ],
      "source": [
        "print(en_vec_layer.get_vocabulary()[:10])\n",
        "print(es_vec_layer.get_vocabulary()[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 368,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFsxkvFz2hZJ",
        "outputId": "cc7c81c1-16de-4ca8-fb9f-bc2e72872cf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'You were in a coma.' ----> tf.Tensor([   2    8   57   14   10 4223    4    3], shape=(8,), dtype=int64)\n",
            "b'Come back here.' ----> tf.Tensor([  2  79 119  63   4   3], shape=(6,), dtype=int64)\n",
            "b'Tom said I looked interested.' ----> tf.Tensor([  2   9 122   6 354 659   4   3], shape=(8,), dtype=int64)\n",
            "b'Are you sure you want to go with Tom?' ----> tf.Tensor([  2  28   8 238   8  37   7  46  36   9  11   3], shape=(12,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for english_text,en_vectorized_out in zip(en.numpy()[:4],en_vec_layer(en[:4])):\n",
        "    print(english_text,\"---->\",en_vectorized_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 369,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1wRy9Os5cAd",
        "outputId": "b48aac3b-b518-49de-fdea-0a6da406ae53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'Estuvisteis en coma.' ----> tf.Tensor([   2    1   14 2380    4    3], shape=(6,), dtype=int64)\n",
            "b'Vuelve aqu\\xc3\\xad.' ----> tf.Tensor([   2 1016   52    4    3], shape=(5,), dtype=int64)\n",
            "b'Tom dijo que yo parec\\xc3\\xada interesado.' ----> tf.Tensor([   2   10   92    5   39  513 1303    4    3], shape=(9,), dtype=int64)\n",
            "b'\\xc2\\xbfEst\\xc3\\xa1s segura que quer\\xc3\\xa9s ir con Tom?' ----> tf.Tensor([   2   13   77 1017    5  465   68   27   10   12    3], shape=(11,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for latin_text,es_vectorized_out in zip(es.numpy()[:4],es_vec_layer(es[:4])):\n",
        "    print(latin_text,\"---->\",es_vectorized_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 370,
      "metadata": {
        "id": "Q8T1vTbG6DHc"
      },
      "outputs": [],
      "source": [
        "en_vocab = np.array(en_vec_layer.get_vocabulary())\n",
        "es_vocab = np.array(es_vec_layer.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 371,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ner_MaA60hs",
        "outputId": "c2439413-e133-4180-a25d-6b946f99c96d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[startofsequence] are you sure you want to go with tom ? [endofsequence]\n",
            "[startofsequence] ¿ estas segura que queres ir con tom ? [endofsequence]\n"
          ]
        }
      ],
      "source": [
        "print(\" \".join(en_vocab[en_vectorized_out.numpy()]))\n",
        "print(\" \".join(es_vocab[es_vectorized_out.numpy()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 372,
      "metadata": {
        "id": "Nd_WwynD6-yg"
      },
      "outputs": [],
      "source": [
        "en_vec_out = en_vec_layer(en)\n",
        "es_vec_out = es_vec_layer(es)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 373,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "hxdFErDy7s1A",
        "outputId": "0ae4f081-b97e-49db-ae5a-abc3361a1d59"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"f35e6a39-37f6-43b8-b0a9-25fd209154cf\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f35e6a39-37f6-43b8-b0a9-25fd209154cf\")) {                    Plotly.newPlot(                        \"f35e6a39-37f6-43b8-b0a9-25fd209154cf\",                        [{\"z\":[[2,8,57,14,10,4223,4,3,0,0,0,0,0,0,0,0,0],[2,79,119,63,4,3,0,0,0,0,0,0,0,0,0,0,0],[2,9,122,6,354,659,4,3,0,0,0,0,0,0,0,0,0],[2,28,8,238,8,37,7,46,36,9,11,3,0,0,0,0,0],[2,29,20,8,65,15,22,1260,11,3,0,0,0,0,0,0,0],[2,191,5,2896,800,14,5,317,11,3,0,0,0,0,0,0,0],[2,20,8,43,81,308,90,382,11,3,0,0,0,0,0,0,0],[2,5,1508,15,5,445,19,30,1776,1,4,3,0,0,0,0,0],[2,6,27,37,22,74,4,3,0,0,0,0,0,0,0,0,0],[2,86,742,7,35,822,4,3,0,0,0,0,0,0,0,0,0],[2,13,275,611,4,3,0,0,0,0,0,0,0,0,0,0,0],[2,5,1,388,187,5,3049,4,3,0,0,0,0,0,0,0,0],[2,5,384,12,324,179,4,3,0,0,0,0,0,0,0,0,0],[2,6,177,14,305,4,3,0,0,0,0,0,0,0,0,0,0],[2,6,64,540,7,1997,130,4,3,0,0,0,0,0,0,0,0],[2,8,378,10,3684,18,28,8,11,3,0,0,0,0,0,0,0],[2,3279,5,4269,10,182,4,3,0,0,0,0,0,0,0,0,0],[2,6,101,62,335,55,1127,4,3,0,0,0,0,0,0,0,0],[2,6,37,342,15,8,7,92,23,670,29,8,58,105,835,4,3],[2,127,39,24,963,4,127,24,297,4,3,0,0,0,0,0,0],[2,280,75,7,10,2630,3561,4,3,0,0,0,0,0,0,0,0],[2,183,13,60,267,30,463,18,13,121,7,257,4,3,0,0,0],[2,28,52,898,11,3,0,0,0,0,0,0,0,0,0,0,0],[2,9,12,162,103,330,7,215,16,4,3,0,0,0,0,0,0],[2,52,58,17,4,3,0,0,0,0,0,0,0,0,0,0,0],[2,24,1302,235,23,5,1,38,631,4,3,0,0,0,0,0,0],[2,172,97,133,108,41,16,4,3,0,0,0,0,0,0,0,0],[2,6,243,3498,77,16,4,3,0,0,0,0,0,0,0,0,0],[2,13,402,41,10,1163,4,3,0,0,0,0,0,0,0,0,0],[2,13,224,10,138,1176,15,439,4,3,0,0,0,0,0,0,0],[2,86,75,7,66,379,71,86,39,602,4,3,0,0,0,0,0],[2,52,1322,13,19,947,4,3,0,0,0,0,0,0,0,0,0],[2,20,8,21,10,1187,1402,25,2810,11,3,0,0,0,0,0,0],[2,6,65,144,1269,12,103,156,7,723,10,1,4,3,0,0,0],[2,6,21,39,637,130,25,5,105,161,312,4,3,0,0,0,0],[2,6,37,358,4,3,0,0,0,0,0,0,0,0,0,0,0],[2,494,478,102,738,4,3,0,0,0,0,0,0,0,0,0,0],[2,31,45,59,20,22,4,3,0,0,0,0,0,0,0,0,0],[2,24,159,19,18,6,65,18,10,182,728,497,4,3,0,0,0],[2,6,27,999,357,130,4,3,0,0,0,0,0,0,0,0,0],[2,53,12,10,83,552,15,883,4,3,0,0,0,0,0,0,0],[2,13,121,2966,5,619,4,3,0,0,0,0,0,0,0,0,0],[2,16,12,81,26,64,1083,196,4,3,0,0,0,0,0,0,0],[2,17,12,2989,480,22,223,4,3,0,0,0,0,0,0,0,0],[2,87,104,17,935,4,3,0,0,0,0,0,0,0,0,0,0],[2,5,1,1413,4,3,0,0,0,0,0,0,0,0,0,0,0],[2,6,87,37,7,104,10,1846,165,4,3,0,0,0,0,0,0],[2,17,19,56,283,16,790,4,3,0,0,0,0,0,0,0,0],[2,53,12,73,51,25,1250,4,3,0,0,0,0,0,0,0,0],[2,12,22,994,11,3,0,0,0,0,0,0,0,0,0,0,0],[2,6,27,65,6,457,132,696,4,3,0,0,0,0,0,0,0],[2,1842,1370,69,8,218,81,40,54,4,3,0,0,0,0,0,0],[2,17,273,4283,4,3,0,0,0,0,0,0,0,0,0,0,0],[2,6,70,240,29,30,242,12,4,3,0,0,0,0,0,0,0],[2,52,135,374,42,1512,581,4,3,0,0,0,0,0,0,0,0],[2,54,125,15,8,371,7,35,63,176,170,11,3,0,0,0,0],[2,9,409,39,7,1185,5,384,4,3,0,0,0,0,0,0,0],[2,13,101,34,5,294,4,3,0,0,0,0,0,0,0,0,0],[2,9,1677,86,198,4,3,0,0,0,0,0,0,0,0,0,0],[2,143,1,4,3,0,0,0,0,0,0,0,0,0,0,0,0],[2,9,572,192,10,588,14,30,2801,4,3,0,0,0,0,0,0],[2,6,64,1159,8,57,1414,4,3,0,0,0,0,0,0,0,0],[2,16,322,12,1,18,95,94,26,402,14,5,730,775,4,3,0],[2,8,21,7,1483,1,4,3,0,0,0,0,0,0,0,0,0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"z\":[[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Unmasked\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Masked\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f35e6a39-37f6-43b8-b0a9-25fd209154cf');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = make_subplots(cols=2,subplot_titles=[\"Unmasked\",\"Masked\"])\n",
        "fig.add_trace(go.Heatmap(z=en_vec_out.to_tensor().numpy()),row=1,col=1)\n",
        "fig.add_trace(go.Heatmap(z=np.array((en_vec_out.to_tensor() != 0).numpy(),dtype=np.int32)),row=1,col=2)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 374,
      "metadata": {
        "id": "OBAs6ISC_JOb"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataset(en,es):\n",
        "    X_train = en_vec_layer(en).to_tensor()\n",
        "    X_dec = es_vec_layer(es)\n",
        "    X_dec_train = X_dec[:,:-1].to_tensor()\n",
        "    y_train = X_dec[:,1:].to_tensor()\n",
        "\n",
        "    return (X_train,X_dec_train),y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 375,
      "metadata": {
        "id": "4b0AXYxOBEWT"
      },
      "outputs": [],
      "source": [
        "train_ds = raw_train.map(preprocess_dataset,tf.data.AUTOTUNE)\n",
        "valid_ds = raw_valid.map(preprocess_dataset,tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {
        "id": "YhaaOooEu31g",
        "outputId": "7dd69c2a-2907-4ab7-e008-dc75fe2c27af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n"
          ]
        }
      ],
      "source": [
        "for (en_in,es_in),es_out in train_ds.take(1):\n",
        "    print(en_in.shape)\n",
        "    print(es_in.shape)\n",
        "    print(es_out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzeg0ZKku31h"
      },
      "source": [
        "# Encoder Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cauf7s0vu31h"
      },
      "source": [
        "- Embedding Layer\n",
        "- GRU/LSTM Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 377,
      "metadata": {
        "id": "iVc1hkwzu31h",
        "outputId": "2b5a8ae5-1148-4830-da89-1a73aabdf4fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 377
        }
      ],
      "source": [
        "vocab_size = len(en_vec_layer.get_vocabulary())\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {
        "id": "vMetYW0gu31h"
      },
      "outputs": [],
      "source": [
        "embed_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {
        "id": "qyESzuiuu31i"
      },
      "outputs": [],
      "source": [
        "encoder_embed_layer = keras.layers.Embedding(vocab_size,embed_size,mask_zero=True)\n",
        "encoder = keras.layers.Bidirectional(\n",
        "    keras.layers.LSTM(256,return_sequences=True,recurrent_initializer=\"glorot_uniform\"),\n",
        "    merge_mode=\"sum\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 380,
      "metadata": {
        "id": "IjA7XtHEu31i"
      },
      "outputs": [],
      "source": [
        "shape_checker = ShapeCheck()\n",
        "shape_checker(en_in,\"batch s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {
        "id": "uPTSXjTju31i",
        "outputId": "b2c69746-f489-4832-97f3-831b898fc113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch': 64, 's': 18}"
            ]
          },
          "metadata": {},
          "execution_count": 381
        }
      ],
      "source": [
        "shape_checker.shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {
        "id": "gCSEes5Fu31i",
        "outputId": "205d2f23-bc05-42cb-ac7a-f1efeea9e945",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 18, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 382
        }
      ],
      "source": [
        "enc_embed_output = encoder_embed_layer(en_in)\n",
        "enc_embed_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 383,
      "metadata": {
        "id": "7H_C7UYnu31k",
        "outputId": "0c108e2b-497f-444a-c455-28568b7591f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch': 64, 's': 18, 'units': 256}"
            ]
          },
          "metadata": {},
          "execution_count": 383
        }
      ],
      "source": [
        "shape_checker(enc_embed_output,\"batch s units\")\n",
        "shape_checker.shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {
        "id": "jJxSxCPlu31k",
        "outputId": "f282c0c9-80c5-456e-db06-3bc977815003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 18, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 384
        }
      ],
      "source": [
        "encoder_outputs = encoder(enc_embed_output)\n",
        "encoder_outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 385,
      "metadata": {
        "id": "MDGUACPku31k"
      },
      "outputs": [],
      "source": [
        "shape_checker(encoder_outputs,\"batch s units\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 386,
      "metadata": {
        "id": "ItyGpyOXu31l"
      },
      "outputs": [],
      "source": [
        "mha = keras.layers.MultiHeadAttention(num_heads=1,key_dim=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 387,
      "metadata": {
        "id": "L78F35PWu31l",
        "outputId": "9c813fbc-9fb6-4c24-c352-4e141699af8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 18)\n",
            "(64, 18, 256)\n"
          ]
        }
      ],
      "source": [
        "print(en_in.shape)\n",
        "print(encoder_outputs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 388,
      "metadata": {
        "id": "DQMoT_OYu31l",
        "outputId": "1ead2116-9158-460c-d8ba-a2799d05b1d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 388
        }
      ],
      "source": [
        "len(en_vec_layer.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 389,
      "metadata": {
        "id": "Hq-JrLxnu31m"
      },
      "outputs": [],
      "source": [
        "class Encoder(keras.Model):\n",
        "\n",
        "    def __init__(self,units=256,vec_layer=en_vec_layer,**kwargs):\n",
        "\n",
        "        super(Encoder,self).__init__(**kwargs)\n",
        "        self.vec_layer = vec_layer\n",
        "        self.embed = keras.layers.Embedding(vec_layer.vocabulary_size(),units,mask_zero=True)\n",
        "        self.Rnn = keras.layers.Bidirectional(\n",
        "            layer=keras.layers.LSTM(units,return_sequences=True,return_state=True,recurrent_initializer=\"glorot_uniform\"),\n",
        "            merge_mode=\"sum\"\n",
        "        )\n",
        "\n",
        "    def call(self,inputs):\n",
        "\n",
        "        shape_checker = ShapeCheck()\n",
        "        shape_checker(inputs,\"batch s\")\n",
        "        z = self.embed(inputs)\n",
        "        shape_checker(z,\"batch s units\")\n",
        "        z,*encoder_state = self.Rnn(z)\n",
        "        self.encoder_state = encoder_state\n",
        "        shape_checker(z,\"batch s units\")\n",
        "        return z\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVCnJqY_u31m"
      },
      "source": [
        "# CrossAttention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 390,
      "metadata": {
        "id": "TkDae6kru31m",
        "outputId": "6ccc79da-5b00-47a7-8f98-26ddf62d973f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 17, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 390
        }
      ],
      "source": [
        "decoder_embed_layer = keras.layers.Embedding(es_vec_layer.vocabulary_size(),256,mask_zero=True)\n",
        "decoder_embed_out = decoder_embed_layer(es_in)\n",
        "decoder_embed_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 391,
      "metadata": {
        "id": "4xtE65Q2u31m",
        "outputId": "3b54b3ed-9e3a-4c54-eeb8-504d2b6726f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 17, 256)\n",
            "(64, 1, 17, 18)\n"
          ]
        }
      ],
      "source": [
        "mha = keras.layers.MultiHeadAttention(num_heads=1,key_dim=256)\n",
        "attention_output,attention_scores = mha(query=decoder_embed_out,value=encoder_outputs,return_attention_scores=True)\n",
        "print(attention_output.shape)\n",
        "print(attention_scores.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 392,
      "metadata": {
        "id": "CTdmUs1Cu31n"
      },
      "outputs": [],
      "source": [
        "shape_checker = ShapeCheck()\n",
        "shape_checker(decoder_embed_out,\"batch t units\")\n",
        "shape_checker(encoder_outputs,\"batch s units\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 393,
      "metadata": {
        "id": "gfTRerc-u31n",
        "outputId": "7f91393d-2158-48a4-e601-8a17ea6b4c69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 17, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 393
        }
      ],
      "source": [
        "attention_scores = tf.reduce_mean(attention_scores,axis=1)\n",
        "attention_scores.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 394,
      "metadata": {
        "id": "xr_8_3GRu31n",
        "outputId": "9289dbd8-d489-47e3-d820-0a749af60fbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 17, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 394
        }
      ],
      "source": [
        "adding_layer = keras.layers.Add()\n",
        "add_out = adding_layer([decoder_embed_out,attention_output])\n",
        "add_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 395,
      "metadata": {
        "id": "3vfHONdMu31o",
        "outputId": "6e290284-c097-4ff2-9fbf-e634cbf1cfcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 17, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 395
        }
      ],
      "source": [
        "layer_norm = keras.layers.LayerNormalization()\n",
        "layer_out = layer_norm(add_out)\n",
        "layer_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 396,
      "metadata": {
        "id": "PqlxV4YXu31o"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,units=256,**kwargs):\n",
        "\n",
        "        super(CrossAttention,self).__init__(**kwargs)\n",
        "        self.mha = keras.layers.MultiHeadAttention(num_heads=1,key_dim=units)\n",
        "        self.add = keras.layers.Add()\n",
        "        self.layer_norm = keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self,decoder_out,encoder_out):\n",
        "\n",
        "        shape_checker = ShapeCheck()\n",
        "        shape_checker(decoder_out,\"batch t units\")\n",
        "        shape_checker(encoder_out,\"batch s units\")\n",
        "\n",
        "        attention_output,attention_scores = self.mha(query=decoder_out,value=encoder_out,return_attention_scores=True)\n",
        "        shape_checker(attention_output,\"batch t units\")\n",
        "        shape_checker(attention_scores,\"batch heads t s\")\n",
        "\n",
        "        add_and_layer_norm = self.layer_norm(self.add([decoder_out,attention_output]))\n",
        "        self.attention_scores = tf.reduce_mean(attention_scores,axis=1)\n",
        "\n",
        "        return add_and_layer_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 397,
      "metadata": {
        "id": "0QI5ozGiu31p",
        "outputId": "543fb894-fb86-458d-b37c-384c312383cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 17, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 397
        }
      ],
      "source": [
        "attention_layer = CrossAttention()\n",
        "\n",
        "attention_out = attention_layer(decoder_embed_out,encoder_outputs)\n",
        "attention_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 398,
      "metadata": {
        "id": "EpZVIHIDu31r",
        "outputId": "3665a235-bb79-45f4-f6e2-cb18b00f2266",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 17, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 398
        }
      ],
      "source": [
        "attention_layer.attention_scores.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 399,
      "metadata": {
        "id": "V9aFzp0Xu31r",
        "outputId": "39eb1780-e8d0-42ed-d9f0-5aff6e06add8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1.],\n",
              "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 399
        }
      ],
      "source": [
        "np.sum(attention_layer.attention_scores,axis=-1)[:5,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 400,
      "metadata": {
        "id": "ycQVozJfu31r",
        "outputId": "b988fd00-bc74-4f14-da1b-4bca96d83507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"230e4e83-a2b4-4ae3-b70b-5e63471ed950\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"230e4e83-a2b4-4ae3-b70b-5e63471ed950\")) {                    Plotly.newPlot(                        \"230e4e83-a2b4-4ae3-b70b-5e63471ed950\",                        [{\"z\":[[0.20000013709068298,0.19999977946281433,0.20000042021274567,0.1999998241662979,0.1999998837709427,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111102998256683,0.11111114919185638,0.11111102998256683,0.1111111119389534,0.11111125349998474,0.11111116409301758,0.11111125349998474,0.11111098527908325,0.11111101508140564,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1428573727607727,0.1428574025630951,0.1428574174642563,0.14285719394683838,0.1428568959236145,0.14285679161548615,0.1428569257259369,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09090917557477951,0.09090925753116608,0.09090918302536011,0.09090913087129593,0.09090907871723175,0.09090892225503922,0.09090901166200638,0.09090901166200638,0.09090904891490936,0.09090901166200638,0.09090909361839294,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111120134592056,0.11111122369766235,0.11111117154359818,0.11111105233430862,0.11111138761043549,0.1111111044883728,0.11111102998256683,0.11111089587211609,0.11111094057559967,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.12500005960464478,0.12500017881393433,0.1249999850988388,0.12499986588954926,0.12500005960464478,0.12499988824129105,0.12499991059303284,0.1250000149011612,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.10000012814998627,0.1000003069639206,0.10000017285346985,0.10000025480985641,0.10000014305114746,0.1000000461935997,0.09999985992908478,0.09999968856573105,0.09999963641166687,0.09999975562095642,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1250002235174179,0.12500019371509552,0.12500004470348358,0.125,0.12499980628490448,0.12499982118606567,0.12499991804361343,0.1249999925494194,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.12500011920928955,0.12500014901161194,0.1249999850988388,0.1250002533197403,0.12500014901161194,0.12499983608722687,0.1249997466802597,0.12499983608722687,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.08333321660757065,0.08333317935466766,0.08333323895931244,0.08333338052034378,0.08333354443311691,0.08333353698253632,0.08333326876163483,0.08333319425582886,0.08333330601453781,0.08333342522382736,0.0833333432674408,0.08333337306976318,0.0,0.0,0.0,0.0,0.0,0.0],[0.1111111044883728,0.11111093312501907,0.111111119389534,0.11111114174127579,0.11111102253198624,0.11111115664243698,0.11111121624708176,0.11111106723546982,0.11111117899417877,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111120134592056,0.11111108213663101,0.11111115664243698,0.11111099272966385,0.11111114919185638,0.11111120134592056,0.11111105978488922,0.11111105233430862,0.11111115664243698,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111117154359818,0.1111111044883728,0.11111097037792206,0.11111105978488922,0.11111120879650116,0.11111125349998474,0.11111116409301758,0.11111104488372803,0.11111105978488922,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111107468605042,0.111111119389534,0.11111122369766235,0.11111126840114594,0.11111138761043549,0.11111100018024445,0.11111106723546982,0.11111083626747131,0.11111088842153549,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.12500013411045074,0.12500013411045074,0.12499993294477463,0.12499988079071045,0.1250000149011612,0.12500010430812836,0.12499993294477463,0.12499995529651642,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.12500010430812836,0.1250002384185791,0.12500013411045074,0.12500011920928955,0.12499996274709702,0.12499983608722687,0.1249997541308403,0.12499985843896866,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.055555686354637146,0.05555565282702446,0.05555559694766998,0.05555552989244461,0.05555559694766998,0.05555562674999237,0.05555553734302521,0.05555550381541252,0.05555550754070282,0.05555551126599312,0.05555552616715431,0.05555552989244461,0.05555558204650879,0.05555557459592819,0.05555548146367073,0.05555548146367073,0.055555518716573715,0.0555555522441864],[0.10000023245811462,0.10000031441450119,0.10000006854534149,0.10000008344650269,0.10000012814998627,0.1000000610947609,0.09999977797269821,0.09999976307153702,0.09999967366456985,0.0999998152256012,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.07142860442399979,0.0714285597205162,0.0714285671710968,0.07142865657806396,0.071428582072258,0.07142871618270874,0.07142873108386993,0.07142862677574158,0.07142862677574158,0.07142850756645203,0.07142846286296844,0.07142841070890427,0.07142844051122665,0.07142850011587143,0.0,0.0,0.0,0.0],[0.12500013411045074,0.12500007450580597,0.12500008940696716,0.12500008940696716,0.12500007450580597,0.125,0.12499972432851791,0.12499979883432388,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1111113429069519,0.11111145466566086,0.11111116409301758,0.11111113429069519,0.11111106723546982,0.11111085116863251,0.11111101508140564,0.11111098527908325,0.11111106723546982,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.125,0.12500007450580597,0.1250002682209015,0.12500013411045074,0.1250000298023224,0.12499986588954926,0.12499979883432388,0.12499986588954926,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1428571492433548,0.14285722374916077,0.1428571492433548,0.14285726845264435,0.14285734295845032,0.14285685122013092,0.14285694062709808,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1000000387430191,0.10000000149011612,0.09999998658895493,0.09999993443489075,0.10000008344650269,0.10000011324882507,0.09999997913837433,0.09999997913837433,0.09999986737966537,0.09999997913837433,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09090906381607056,0.09090913832187653,0.09090918302536011,0.0909091904759407,0.09090925008058548,0.09090906381607056,0.09090912342071533,0.09090911597013474,0.09090900421142578,0.09090887010097504,0.0909089669585228,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111129820346832,0.11111133545637131,0.11111126840114594,0.11111117154359818,0.11111097037792206,0.11111105233430862,0.11111097037792206,0.11111094802618027,0.11111100763082504,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.16666674613952637,0.16666673123836517,0.16666674613952637,0.16666661202907562,0.16666653752326965,0.166666641831398,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.07692313194274902,0.07692324370145798,0.07692323625087738,0.07692323625087738,0.07692313194274902,0.0769231915473938,0.07692310959100723,0.07692307233810425,0.07692299038171768,0.07692304998636246,0.07692296802997589,0.07692281156778336,0.07692284137010574,0.0,0.0,0.0,0.0,0.0],[0.08333338052034378,0.08333350718021393,0.08333345502614975,0.08333351463079453,0.08333364129066467,0.083333320915699,0.0833333358168602,0.08333330601453781,0.0833331048488617,0.08333315700292587,0.0833330824971199,0.08333315700292587,0.0,0.0,0.0,0.0,0.0,0.0],[0.07692310959100723,0.0769231766462326,0.07692308723926544,0.07692334055900574,0.07692326605319977,0.0769231915473938,0.0769231915473938,0.07692307233810425,0.07692287117242813,0.07692298293113708,0.07692283391952515,0.07692289352416992,0.07692296802997589,0.0,0.0,0.0,0.0,0.0],[0.16666686534881592,0.16666676104068756,0.16666680574417114,0.16666661202907562,0.16666646301746368,0.16666653752326965,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09090918302536011,0.09090922772884369,0.09090907126665115,0.0909091904759407,0.09090925008058548,0.09090900421142578,0.09090900421142578,0.09090913087129593,0.09090904891490936,0.09090888500213623,0.09090901911258698,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.07692322134971619,0.07692321389913559,0.0769231840968132,0.07692322134971619,0.07692326605319977,0.07692304253578186,0.07692305743694305,0.07692292332649231,0.07692302018404007,0.07692303508520126,0.07692299783229828,0.07692289352416992,0.0769229531288147,0.0,0.0,0.0,0.0,0.0],[0.09090925753116608,0.0909092053771019,0.09090910851955414,0.09090910851955414,0.09090904891490936,0.09090885519981384,0.0909089520573616,0.09090913087129593,0.09090911597013474,0.09090901166200638,0.09090904891490936,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.14285734295845032,0.14285729825496674,0.14285720884799957,0.14285697042942047,0.14285701513290405,0.14285700023174286,0.1428571343421936,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.111111119389534,0.11111092567443848,0.11111105233430862,0.11111120134592056,0.11111126840114594,0.111111119389534,0.11111104488372803,0.11111102998256683,0.11111114919185638,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.14285708963871002,0.14285710453987122,0.14285726845264435,0.14285729825496674,0.14285720884799957,0.14285703003406525,0.14285710453987122,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1000000461935997,0.10000009089708328,0.10000000894069672,0.10000016540288925,0.1000000536441803,0.09999995678663254,0.09999994933605194,0.09999988228082657,0.09999984502792358,0.09999990463256836,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1428571194410324,0.142857164144516,0.1428571194410324,0.14285719394683838,0.14285726845264435,0.14285701513290405,0.14285707473754883,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.12500016391277313,0.1250002235174179,0.1249999925494194,0.12499995529651642,0.125,0.12499996274709702,0.12499982118606567,0.12499993294477463,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.08333340287208557,0.08333335816860199,0.08333348482847214,0.08333349972963333,0.08333325386047363,0.08333326876163483,0.08333314955234528,0.08333320915699005,0.08333319425582886,0.08333341032266617,0.0833333283662796,0.08333337306976318,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111125349998474,0.11111128330230713,0.11111122369766235,0.11111116409301758,0.11111120879650116,0.11111099272966385,0.11111101508140564,0.1111108586192131,0.11111096292734146,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.12499991804361343,0.12500008940696716,0.1250000298023224,0.12500013411045074,0.12500010430812836,0.12500004470348358,0.12499985098838806,0.12499985843896866,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.10000009834766388,0.09999999403953552,0.10000011324882507,0.10000000894069672,0.09999985992908478,0.09999971091747284,0.1000000387430191,0.1000000536441803,0.09999998658895493,0.10000006854534149,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111116409301758,0.11111116409301758,0.1111110970377922,0.1111108660697937,0.11111100018024445,0.11111140996217728,0.11111119389533997,0.11111100018024445,0.11111104488372803,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09999987483024597,0.09999978542327881,0.09999966621398926,0.09999983012676239,0.10000019520521164,0.1000003069639206,0.10000025480985641,0.1000000536441803,0.10000001639127731,0.1000000461935997,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.12499997764825821,0.12499997764825821,0.1250002533197403,0.1250000298023224,0.12500010430812836,0.125,0.12499978393316269,0.12499994039535522,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09999995678663254,0.10000000149011612,0.1000000536441803,0.09999997913837433,0.09999996423721313,0.1000000461935997,0.09999991208314896,0.10000009089708328,0.09999993443489075,0.09999995678663254,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09090907871723175,0.09090906381607056,0.09090900421142578,0.09090915322303772,0.09090917557477951,0.09090904891490936,0.09090898185968399,0.09090912342071533,0.09090914577245712,0.09090907871723175,0.09090916812419891,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1250002384185791,0.1250002533197403,0.125,0.12499988079071045,0.12499994784593582,0.12499989569187164,0.12499986588954926,0.12499991804361343,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09999998658895493,0.09999999403953552,0.09999998658895493,0.09999995678663254,0.10000013560056686,0.10000015050172806,0.10000014305114746,0.09999994188547134,0.09999978542327881,0.0999998226761818,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.083333320915699,0.0833333432674408,0.08333317935466766,0.08333317935466766,0.08333326876163483,0.08333328366279602,0.08333313465118408,0.08333344757556915,0.08333360403776169,0.08333352208137512,0.08333341032266617,0.08333344757556915,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111108213663101,0.1111111044883728,0.1111111044883728,0.11111133545637131,0.11111129820346832,0.1111110970377922,0.11111098527908325,0.11111097037792206,0.11111104488372803,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.11111124604940414,0.11111118644475937,0.11111117899417877,0.11111132055521011,0.1111111119389534,0.1111110970377922,0.11111097782850266,0.11111084371805191,0.11111096292734146,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.07692301273345947,0.07692298293113708,0.07692309468984604,0.07692310959100723,0.07692314684391022,0.0769231840968132,0.0769231840968132,0.07692299038171768,0.07692307978868484,0.07692306488752365,0.07692310214042664,0.07692297548055649,0.07692301273345947,0.0,0.0,0.0,0.0,0.0],[0.09090914577245712,0.09090916067361832,0.09090913832187653,0.0909091904759407,0.09090922027826309,0.09090901166200638,0.0909089520573616,0.09090885519981384,0.09090910851955414,0.09090907126665115,0.09090910851955414,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1111113578081131,0.11111126095056534,0.11111097037792206,0.11111099272966385,0.11111113429069519,0.111111119389534,0.1111111268401146,0.11111097037792206,0.11111105233430862,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1428571194410324,0.14285707473754883,0.1428571343421936,0.14285732805728912,0.142857164144516,0.14285701513290405,0.14285707473754883,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.08333326876163483,0.08333320915699005,0.08333320915699005,0.08333336561918259,0.08333330601453781,0.0833333432674408,0.08333337306976318,0.08333337306976318,0.08333345502614975,0.08333338797092438,0.0833333283662796,0.08333341032266617,0.0,0.0,0.0,0.0,0.0,0.0],[0.1250000298023224,0.1249999925494194,0.12500007450580597,0.12500010430812836,0.1249999850988388,0.125,0.12499989569187164,0.12499996274709702,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.125,0.1250000298023224,0.12499995529651642,0.1250002682209015,0.12499996274709702,0.12499997019767761,0.12499990314245224,0.12499994039535522,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.16666682064533234,0.1666669249534607,0.16666682064533234,0.16666646301746368,0.1666664481163025,0.16666655242443085,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.07692300528287888,0.07692307233810425,0.07692304998636246,0.07692302763462067,0.07692289352416992,0.07692320644855499,0.07692310214042664,0.07692316174507141,0.0769231989979744,0.07692321389913559,0.07692310214042664,0.07692298293113708,0.07692297548055649,0.0,0.0,0.0,0.0,0.0],[0.11111132800579071,0.11111143976449966,0.11111140251159668,0.1111113652586937,0.11111096292734146,0.11111082881689072,0.11111077666282654,0.11111090332269669,0.11111104488372803,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"z\":[[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Attention Output\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Masked Output\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('230e4e83-a2b4-4ae3-b70b-5e63471ed950');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = make_subplots(cols=2,subplot_titles=[\"Attention Output\",\"Masked Output\"])\n",
        "fig.add_trace(go.Heatmap(z=attention_layer.attention_scores[:,0,:]),row=1,col=1)\n",
        "fig.add_trace(go.Heatmap(z=np.array((en_vec_out.to_tensor() != 0).numpy(),dtype=np.int32)),row=1,col=2)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder"
      ],
      "metadata": {
        "id": "K0Ogl9GE4zZX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 401,
      "metadata": {
        "id": "FqDEvc0Mu31s"
      },
      "outputs": [],
      "source": [
        "class Decoder(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,units=256,vec_layer=es_vec_layer,**kwargs):\n",
        "\n",
        "        super(Decoder,self).__init__(**kwargs)\n",
        "\n",
        "        '''Preprocessing Section'''\n",
        "        self.vec_layer = vec_layer\n",
        "        self.vocab_size = vec_layer.vocabulary_size()\n",
        "        self.word_to_id = keras.layers.StringLookup(\n",
        "            vocabulary=vec_layer.get_vocabulary(),\n",
        "            oov_token=\"[UNK]\",\n",
        "            mask_token=\"\"\n",
        "        )\n",
        "        self.id_to_word = keras.layers.StringLookup(\n",
        "            vocabulary=vec_layer.get_vocabulary(),\n",
        "            oov_token=\"[UNK]\",\n",
        "            mask_token=\"\",\n",
        "            invert=True\n",
        "        )\n",
        "        self.start_token = self.word_to_id('[startofsequence]')\n",
        "        self.end_token = self.word_to_id('[endofsequence]')\n",
        "        self.units = units\n",
        "\n",
        "\n",
        "        '''Model Layers section'''\n",
        "        self.es_embed = keras.layers.Embedding(vec_layer.vocabulary_size(),units,mask_zero=True)\n",
        "        self.decoder_cell = keras.layers.LSTM(units,return_sequences=True,return_state=True,recurrent_initializer=\"glorot_uniform\")\n",
        "        self.attention = CrossAttention()\n",
        "        self.out = keras.layers.Dense(vec_layer.vocabulary_size())\n",
        "\n",
        "\n",
        "    def call(self,encoder_outputs,decoder_inputs,encoder_state=None,return_state=False):\n",
        "\n",
        "        shape_checker = ShapeCheck()\n",
        "        shape_checker(encoder_outputs,\"batch s units\")\n",
        "        shape_checker(decoder_inputs,\"batch t\")\n",
        "        if encoder_state is not None:\n",
        "            shape_checker(encoder_state[0],\"batch units\")\n",
        "            shape_checker(encoder_state[1],\"batch units\")\n",
        "\n",
        "        es_embed_out = self.es_embed(decoder_inputs)\n",
        "        shape_checker(es_embed_out,\"batch t units\")\n",
        "\n",
        "\n",
        "\n",
        "        decoder_outputs,*decoder_state = self.decoder_cell(es_embed_out,initial_state=encoder_state)\n",
        "        shape_checker(decoder_outputs,\"batch t units\")\n",
        "        shape_checker(decoder_state[0],\"batch units\")\n",
        "        shape_checker(decoder_state[1],\"batch units\")\n",
        "\n",
        "        attention_out = self.attention(decoder_outputs,encoder_outputs)\n",
        "        shape_checker(attention_out,\"batch t units\")\n",
        "        shape_checker(self.attention.attention_scores,\"batch t s\")\n",
        "\n",
        "        total_out = self.out(attention_out)\n",
        "\n",
        "        if return_state:\n",
        "            return total_out,decoder_state\n",
        "        else:\n",
        "            return total_out\n",
        "\n",
        "\n",
        "    def get_initial_state(self,encoder_outputs):\n",
        "        batch_size = tf.shape(encoder_outputs)[0]\n",
        "        start_tokens = tf.fill(dims=[batch_size,1],value=self.start_token)\n",
        "        done = tf.zeros(shape=[batch_size,1],dtype=tf.bool)\n",
        "        embedding = self.es_embed(start_tokens)\n",
        "        return start_tokens,done,self.decoder_cell.get_initial_state(embedding)\n",
        "\n",
        "\n",
        "    def tokens_to_text(self,tokens):\n",
        "        text_ = self.id_to_word(tokens)\n",
        "        text_ = tf.strings.reduce_join(text_,axis=-1,separator=\" \")\n",
        "        text_ = tf.strings.regex_replace(text_,\"^ *\\[startofsequence\\] *\",\"\")\n",
        "        text_ = tf.strings.regex_replace(text_,\" *\\[endofsequence\\] *$\",\"\")\n",
        "        return text_\n",
        "\n",
        "    def get_next_tokens(self,encoder_outputs,next_token,done,state,temperature=0.0):\n",
        "        total_output,state = self(encoder_outputs,next_token,encoder_state=state,return_state=True)\n",
        "\n",
        "        if temperature:\n",
        "            next_token = tf.argmax(total_output,axis=-1)\n",
        "        else:\n",
        "            scaled_out = total_output/temperature\n",
        "            next_token = tf.random.categorical(scaled_out[:,-1,:],num_samples=1,seed=42)\n",
        "\n",
        "        done = done | (next_token == self.end_token)\n",
        "        next_token = tf.where(done,tf.constant(0,dtype=tf.int64),next_token)\n",
        "        return next_token,done,state"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder()"
      ],
      "metadata": {
        "id": "zojmxnj-MUQv"
      },
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_token,done,state = decoder.get_initial_state(encoder_outputs)\n",
        "tokens_list = []\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "    next_token,done,state = decoder.get_next_tokens(encoder_outputs,next_token,done,state,temperature=1)\n",
        "    tokens_list.append(next_token)"
      ],
      "metadata": {
        "id": "KqEltGL3212T"
      },
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder.tokens_to_text(tf.concat(tokens_list,axis=-1))[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxkmkZT-V7I7",
        "outputId": "2ed5fae3-8791-4d4e-a642-fc164a252f7b"
      },
      "execution_count": 404,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=string, numpy=\n",
              "array([b'pidele pronunciar y pasaje sabeis estos finales gusto gusto linda',\n",
              "       b'estupidos pulsar almuerzo documento mudo eches compone barco eches barco',\n",
              "       b'pidele pronunciar y pasaje estos fea enfadados enfadados peces peces'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 404
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translator Total Model"
      ],
      "metadata": {
        "id": "Qn7D__FYX5cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%xmode Context"
      ],
      "metadata": {
        "id": "-iJ1SOH20XlW",
        "outputId": "aa495a4c-a1ce-42d7-9155-8338b6a44d94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception reporting mode: Context\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(keras.models.Model):\n",
        "\n",
        "    @classmethod\n",
        "    def add_method(cls,func):\n",
        "        setattr(cls,func.__name__,func)\n",
        "        return func\n",
        "\n",
        "    def __init__(self,units=256,en_layer=en_vec_layer,es_layer=es_vec_layer,**kwargs):\n",
        "\n",
        "        super(Translator,self).__init__(**kwargs)\n",
        "\n",
        "        self.encoder = Encoder(units,en_layer)\n",
        "        self.decoder = Decoder(units,es_layer)\n",
        "\n",
        "\n",
        "    def call(self,inputs):\n",
        "\n",
        "        encoder_inputs,decoder_inputs = inputs\n",
        "\n",
        "        encoder_outputs = self.encoder(encoder_inputs)\n",
        "        total_out = self.decoder(encoder_outputs,decoder_inputs)\n",
        "\n",
        "        try:\n",
        "            del total_out._keras_mask\n",
        "        except AssertionError as error:\n",
        "            pass\n",
        "\n",
        "\n",
        "        return total_out"
      ],
      "metadata": {
        "cellView": "code",
        "id": "lQ3eOQ_JXSMA"
      },
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator()\n",
        "out = translator((en_in,es_in))\n",
        "print(\"english inputs (batch s)\",en_in.shape)\n",
        "print(\"spanish inputs (batch t)\",es_in.shape)\n",
        "print(\"logits outputs (batch t vocab_size)\",out.shape)"
      ],
      "metadata": {
        "id": "BYxJLfFiv07R",
        "outputId": "b082d664-78cf-4d82-f806-a92d324af278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "english inputs (batch s) (64, 18)\n",
            "spanish inputs (batch t) (64, 17)\n",
            "logits outputs (batch t vocab_size) (64, 17, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (en_in,es_in),y_in in train_ds.take(1):\n",
        "    print(en_in.shape)\n",
        "    print(es_in.shape)\n",
        "    print(y_in.shape)"
      ],
      "metadata": {
        "id": "2SMTpXN2-gJQ",
        "outputId": "20c49e7d-228b-41a9-e9ae-85dae4b81832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction=\"none\")\n",
        "y_pred = translator((en_in,es_in))\n",
        "y_true = y_in\n",
        "calc_loss = loss_fn(y_true,y_pred)\n",
        "calc_loss"
      ],
      "metadata": {
        "id": "6NYYqiU--qmJ",
        "outputId": "c64fd133-258e-42bb-e4d3-a57e2f07fddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 17), dtype=float32, numpy=\n",
              "array([[8.53, 8.57, 8.48, ..., 8.37, 8.37, 8.37],\n",
              "       [8.51, 8.53, 8.57, ..., 8.47, 8.47, 8.47],\n",
              "       [8.51, 8.44, 8.54, ..., 8.44, 8.44, 8.44],\n",
              "       ...,\n",
              "       [8.44, 8.49, 8.48, ..., 8.4 , 8.4 , 8.4 ],\n",
              "       [8.54, 8.43, 8.63, ..., 8.61, 8.61, 8.61],\n",
              "       [8.49, 8.51, 8.58, ..., 8.39, 8.39, 8.39]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = tf.cast(y_true != 0,calc_loss.dtype)\n",
        "mask"
      ],
      "metadata": {
        "id": "cViz0vs0__Gd",
        "outputId": "ecea5cd6-f0c1-4c04-8a0d-b5f448d1face",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 424,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 17), dtype=float32, numpy=\n",
              "array([[1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 424
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_loss *= mask\n",
        "calc_loss"
      ],
      "metadata": {
        "id": "3hnfeK25AH33",
        "outputId": "7618817b-743c-4baf-eaf8-62eadd595773",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 425,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 17), dtype=float32, numpy=\n",
              "array([[8.53, 8.57, 8.48, ..., 0.  , 0.  , 0.  ],\n",
              "       [8.51, 8.53, 8.57, ..., 0.  , 0.  , 0.  ],\n",
              "       [8.51, 8.44, 8.54, ..., 0.  , 0.  , 0.  ],\n",
              "       ...,\n",
              "       [8.44, 8.49, 8.48, ..., 0.  , 0.  , 0.  ],\n",
              "       [8.54, 8.43, 8.63, ..., 0.  , 0.  , 0.  ],\n",
              "       [8.49, 8.51, 8.58, ..., 0.  , 0.  , 0.  ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 425
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_loss = tf.reduce_sum(calc_loss)\n",
        "reduced_loss"
      ],
      "metadata": {
        "id": "-8ZaiCWHAMvP",
        "outputId": "00502e4e-6c63-42dd-d1c6-80c8dda1211d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 426,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=4298.2666>"
            ]
          },
          "metadata": {},
          "execution_count": 426
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_mask = tf.reduce_sum(mask)\n",
        "reduced_mask"
      ],
      "metadata": {
        "id": "ZcbROPF2Aj1j",
        "outputId": "3d54d523-286c-48b3-e5c0-ae9fd62b65e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 427,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=505.0>"
            ]
          },
          "metadata": {},
          "execution_count": 427
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_loss/reduced_mask"
      ],
      "metadata": {
        "id": "DnTBg2VMAtc9",
        "outputId": "89b73c24-0afc-4f6f-e79e-573bd6f4b8e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 428,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.511419>"
            ]
          },
          "metadata": {},
          "execution_count": 428
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn_reduced = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "loss_fn_reduced(y_true,y_pred)"
      ],
      "metadata": {
        "id": "Jg-z0xfIA4KC",
        "outputId": "062f32f8-2b03-4cc5-e48c-11b8d32606e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 429,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.473401>"
            ]
          },
          "metadata": {},
          "execution_count": 429
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = tf.argmax(y_true,axis=-1)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "YbS0lrIcBQEF",
        "outputId": "1604084b-cfe1-4ef8-af38-efdaf934fa20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
              "array([ 2,  5,  5,  5,  7,  3,  6,  3,  9,  2,  1,  8,  6,  0,  1,  3,  1,\n",
              "        0,  4,  3,  4,  1,  1,  5,  2,  3,  1,  3,  1,  3,  1,  3,  8,  3,\n",
              "        8,  1,  3,  3,  2,  4, 12,  1,  1, 14,  3,  3,  4,  1,  4,  1,  1,\n",
              "        2,  2,  0, 10,  0,  3,  3,  7,  2,  2,  1,  2,  2])>"
            ]
          },
          "metadata": {},
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = tf.cast(y_pred,y_true.dtype)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "4WQ1nAz4BcB8",
        "outputId": "aa454345-0a0b-49a1-fcfd-40689282917b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 431,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
              "array([ 2,  5,  5,  5,  7,  3,  6,  3,  9,  2,  1,  8,  6,  0,  1,  3,  1,\n",
              "        0,  4,  3,  4,  1,  1,  5,  2,  3,  1,  3,  1,  3,  1,  3,  8,  3,\n",
              "        8,  1,  3,  3,  2,  4, 12,  1,  1, 14,  3,  3,  4,  1,  4,  1,  1,\n",
              "        2,  2,  0, 10,  0,  3,  3,  7,  2,  2,  1,  2,  2])>"
            ]
          },
          "metadata": {},
          "execution_count": 431
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_tensor = tf.cast(y_true == y_pred, tf.float32)\n",
        "accuracy_tensor"
      ],
      "metadata": {
        "id": "4H8Yg4sGBrhZ",
        "outputId": "49568b26-7b3c-4ada-8ca8-23e6898d872f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "metadata": {},
          "execution_count": 432
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = tf.cast(y_true != 0,tf.float32)\n",
        "mask"
      ],
      "metadata": {
        "id": "QTsnuw6CCH1Z",
        "outputId": "5bbe62f1-6ae3-4291-e7fe-0c581ff270f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 17), dtype=float32, numpy=\n",
              "array([[1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 435
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reduce_sum(accuracy_tensor)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "2H_dqSr4CSU6",
        "outputId": "9fb62490-6167-4d45-81b0-068ae23d20dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 436,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "metadata": {},
          "execution_count": 436
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(y_true,y_pred):\n",
        "    loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction=\"none\")\n",
        "    loss = loss_fn(y_true,y_pred)\n",
        "    mask = tf.cast(y_true != 0,y_true.dtype)\n",
        "    loss *= mask\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "\n",
        "def masked_accuracy(y_true,y_pred):\n",
        "    y_pred = tf.argmax(y_pred,axis=-1,output_type=y_true.dtype)\n",
        "    accuracy = tf.cast(y_true == y_pred,tf.float32)\n",
        "    mask = tf.cast(y_true != 0,tf.float32)\n",
        "    return tf.reduce_sum(accuracy)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "Fqr7N4dxCYsI"
      },
      "execution_count": 439,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_accuracy(y_in,translator((en_in,es_in)))"
      ],
      "metadata": {
        "id": "sdII50aoHKlw",
        "outputId": "b0b37737-e98a-4264-ef54-2af2930e0f23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 441,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "metadata": {},
          "execution_count": 441
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator.compile(optimizer=\"adam\",loss=masked_loss,metrics=[masked_accuracy,masked_loss])"
      ],
      "metadata": {
        "id": "ql4WX01hKCl5"
      },
      "execution_count": 443,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,y in valid_ds:\n",
        "    print(i[0].shape)\n",
        "    print(i[1].shape)\n",
        "    print(y.shape)"
      ],
      "metadata": {
        "id": "5e6KAQGzLLxe",
        "outputId": "832cda55-c81f-4f5f-c0ad-249bca0e143d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 448,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 13)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 14)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 17)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 21)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 24)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 27)\n",
            "(64, 31)\n",
            "(64, 31)\n",
            "(64, 21)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 28)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 21)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 17)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 25)\n",
            "(64, 27)\n",
            "(64, 27)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 25)\n",
            "(64, 24)\n",
            "(64, 24)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 27)\n",
            "(64, 26)\n",
            "(64, 26)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 25)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 19)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 28)\n",
            "(64, 28)\n",
            "(64, 28)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 21)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 27)\n",
            "(64, 26)\n",
            "(64, 26)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 20)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 25)\n",
            "(64, 27)\n",
            "(64, 27)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 26)\n",
            "(64, 26)\n",
            "(64, 26)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 24)\n",
            "(64, 31)\n",
            "(64, 31)\n",
            "(64, 20)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 48)\n",
            "(64, 48)\n",
            "(64, 48)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 27)\n",
            "(64, 32)\n",
            "(64, 32)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 25)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 20)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 21)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 13)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 21)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 21)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 35)\n",
            "(64, 31)\n",
            "(64, 31)\n",
            "(64, 19)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 26)\n",
            "(64, 37)\n",
            "(64, 37)\n",
            "(64, 21)\n",
            "(64, 24)\n",
            "(64, 24)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 13)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 22)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 13)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 22)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 20)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 21)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 24)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 21)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 25)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 28)\n",
            "(64, 27)\n",
            "(64, 27)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 20)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 17)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 20)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 28)\n",
            "(64, 24)\n",
            "(64, 24)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 26)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 21)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 23)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 14)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 24)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 51)\n",
            "(64, 52)\n",
            "(64, 52)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 23)\n",
            "(64, 24)\n",
            "(64, 24)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 18)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 22)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 29)\n",
            "(64, 30)\n",
            "(64, 30)\n",
            "(64, 20)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 22)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 15)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 21)\n",
            "(64, 22)\n",
            "(64, 22)\n",
            "(64, 17)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 20)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 22)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 23)\n",
            "(64, 24)\n",
            "(64, 24)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 22)\n",
            "(64, 24)\n",
            "(64, 24)\n",
            "(64, 22)\n",
            "(64, 24)\n",
            "(64, 24)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 19)\n",
            "(64, 23)\n",
            "(64, 23)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 13)\n",
            "(64, 22)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 23)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 16)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 25)\n",
            "(64, 31)\n",
            "(64, 31)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 20)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 26)\n",
            "(64, 25)\n",
            "(64, 25)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 19)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 20)\n",
            "(64, 21)\n",
            "(64, 21)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 16)\n",
            "(64, 14)\n",
            "(64, 14)\n",
            "(64, 23)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 41)\n",
            "(64, 40)\n",
            "(64, 40)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 22)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 24)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 22)\n",
            "(64, 19)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 22)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 21)\n",
            "(64, 20)\n",
            "(64, 20)\n",
            "(64, 16)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 20)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 19)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(64, 18)\n",
            "(64, 15)\n",
            "(64, 15)\n",
            "(64, 17)\n",
            "(64, 16)\n",
            "(64, 16)\n",
            "(64, 20)\n",
            "(64, 17)\n",
            "(64, 17)\n",
            "(52, 23)\n",
            "(52, 26)\n",
            "(52, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator.evaluate(valid_ds,steps=20,return_dict=True)"
      ],
      "metadata": {
        "id": "rnIfBg-kKUze",
        "outputId": "903e979b-9ec9-43c3-e563-80b0102e1f36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 445,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-445-b78fdd38bfd5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filep67as5yu.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0mtotal_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file7_irrwf4.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_checker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_checker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch s units'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mencoder_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file5u6708na.py\u001b[0m in \u001b[0;36mtf____call__\u001b[0;34m(self, tensor, names, broadcast)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mnew_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'new_dim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mcontinue_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'continue_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'(name, new_dim)'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf____call__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file5u6708na.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     90\u001b[0m                         \u001b[0;32mnonlocal\u001b[0m \u001b[0mcontinue_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinue_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'self.shapes[name]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'continue_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0mold_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'old_dim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file5u6708na.py\u001b[0m in \u001b[0;36mif_body_4\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0melse_body_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                         \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinue_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0;32mdef\u001b[0m \u001b[0melse_body_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file5u6708na.py\u001b[0m in \u001b[0;36mif_body_3\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m                             \u001b[0;32mdef\u001b[0m \u001b[0melse_body_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                             \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0melse_body_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file5u6708na.py\u001b[0m in \u001b[0;36mif_body_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                             \u001b[0;32mdef\u001b[0m \u001b[0mif_body_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                                 \u001b[0;32mraise\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf\"SHAPE MISTMATCH FOR DIMENSION: '{ag__.ld(name)}' FOUND: {ag__.ld(new_dim)} EXPECTED: {ag__.ld(old_dim)}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                             \u001b[0;32mdef\u001b[0m \u001b[0melse_body_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1972, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1956, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1944, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1850, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filep67as5yu.py\", line 11, in tf__call\n        encoder_outputs = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(encoder_inputs),), None, fscope)\n    File \"/tmp/__autograph_generated_file7_irrwf4.py\", line 13, in tf__call\n        ag__.converted_call(ag__.ld(shape_checker), (ag__.ld(z), 'batch s units'), None, fscope)\n    File \"/tmp/__autograph_generated_file5u6708na.py\", line 97, in tf____call__\n        ag__.for_stmt(ag__.converted_call(ag__.ld(parsed).items, (), None, fscope), None, loop_body, get_state_5, set_state_5, (), {'iterate_names': '(name, new_dim)'})\n    File \"/tmp/__autograph_generated_file5u6708na.py\", line 92, in loop_body\n        ag__.if_stmt(ag__.not_(continue_), if_body_4, else_body_4, get_state_4, set_state_4, ('self.shapes[name]', 'continue_'), 1)\n    File \"/tmp/__autograph_generated_file5u6708na.py\", line 87, in if_body_4\n        ag__.if_stmt(ag__.not_(continue_), if_body_3, else_body_3, get_state_3, set_state_3, (), 0)\n    File \"/tmp/__autograph_generated_file5u6708na.py\", line 83, in if_body_3\n        ag__.if_stmt(ag__.ld(new_dim) != ag__.ld(old_dim), if_body_2, else_body_2, get_state_2, set_state_2, (), 0)\n    File \"/tmp/__autograph_generated_file5u6708na.py\", line 79, in if_body_2\n        raise ag__.converted_call(ag__.ld(ValueError), (f\"SHAPE MISTMATCH FOR DIMENSION: '{ag__.ld(name)}' FOUND: {ag__.ld(new_dim)} EXPECTED: {ag__.ld(old_dim)}\",), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'translator_6' (type Translator).\n    \n    in user code:\n    \n        File \"<ipython-input-406-b5d868797a19>\", line 20, in call  *\n            encoder_outputs = self.encoder(encoder_inputs)\n        File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/tmp/__autograph_generated_file7_irrwf4.py\", line 13, in tf__call\n            ag__.converted_call(ag__.ld(shape_checker), (ag__.ld(z), 'batch s units'), None, fscope)\n        File \"/tmp/__autograph_generated_file5u6708na.py\", line 97, in tf____call__\n            ag__.for_stmt(ag__.converted_call(ag__.ld(parsed).items, (), None, fscope), None, loop_body, get_state_5, set_state_5, (), {'iterate_names': '(name, new_dim)'})\n        File \"/tmp/__autograph_generated_file5u6708na.py\", line 92, in loop_body\n            ag__.if_stmt(ag__.not_(continue_), if_body_4, else_body_4, get_state_4, set_state_4, ('self.shapes[name]', 'continue_'), 1)\n        File \"/tmp/__autograph_generated_file5u6708na.py\", line 87, in if_body_4\n            ag__.if_stmt(ag__.not_(continue_), if_body_3, else_body_3, get_state_3, set_state_3, (), 0)\n        File \"/tmp/__autograph_generated_file5u6708na.py\", line 83, in if_body_3\n            ag__.if_stmt(ag__.ld(new_dim) != ag__.ld(old_dim), if_body_2, else_body_2, get_state_2, set_state_2, (), 0)\n        File \"/tmp/__autograph_generated_file5u6708na.py\", line 79, in if_body_2\n            raise ag__.converted_call(ag__.ld(ValueError), (f\"SHAPE MISTMATCH FOR DIMENSION: '{ag__.ld(name)}' FOUND: {ag__.ld(new_dim)} EXPECTED: {ag__.ld(old_dim)}\",), None, fscope)\n    \n        ValueError: Exception encountered when calling layer 'encoder_6' (type Encoder).\n        \n        in user code:\n        \n            File \"<ipython-input-389-cbc2b06f27ff>\", line 18, in call  *\n                shape_checker(z,\"batch s units\")\n            File \"<ipython-input-349-5b7e6fdfd84a>\", line 25, in __call__  *\n                raise ValueError(f\"SHAPE MISTMATCH FOR DIMENSION: '{name}' FOUND: {new_dim} EXPECTED: {old_dim}\")\n        \n            ValueError: SHAPE MISTMATCH FOR DIMENSION: 'batch' FOUND: Tensor(\"translator_6/encoder_6/strided_slice_2:0\", shape=(), dtype=int32) EXPECTED: Tensor(\"translator_6/encoder_6/strided_slice:0\", shape=(), dtype=int32)\n        \n        \n        Call arguments received by layer 'encoder_6' (type Encoder):\n          • inputs=tf.Tensor(shape=(None, None), dtype=int64)\n    \n    \n    Call arguments received by layer 'translator_6' (type Translator):\n      • inputs=('tf.Tensor(shape=(None, None), dtype=int64)', 'tf.Tensor(shape=(None, None), dtype=int64)')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}